{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building makemore: becoming a backprop ninja\n",
    "\n",
    "https://www.youtube.com/watch?v=q8SA3rM6ckI\n",
    "\n",
    "Before going to more complicated networks, one more lecture to really understand the backpropagation step. Can't just automatically stack together differentiable functions and expect it to work; can shoot ourselves in the foot if internal mechanisms aren't understood. Need to understand under the hood to debug it.\n",
    "\n",
    "Flat tails like tanh and sigmoid lead to gradient issues (vanishing gradients), dead neurons, and other problems we saw before. Can't really debug without understanding what `loss.backwards()` actually does.\n",
    "\n",
    "We covered autograd in the micrograd lecture; good exercise to redo in the language of tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some history\n",
    "\n",
    "Pre-2012 people wrote their own, but now that doesn't really happen anymore. 2010 package Andrej wrote for Matlab - created tensors and fit RBMs (restricted Boltzmann machines) and trained by estimating gradient, not backprop we're used to.\n",
    "\n",
    "2014 paper: defragmented embeddings. Code was in Python implementing cost function and backward pass manually, and backpropagation result compared to a \"gradient checker\" to see if numerically the results were close to the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there no change change in the first several cells from last lecture\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('makemore/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:\n",
    "\n",
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to check for correctness of our implementation versus the \"official\" Pytorch result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note biases are set to small random numbers; we're not using 0 because that would hide potential issues with how we're computing gradients and doing backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a single batch\n",
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3244, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "# Note how much longer this is than the F.cross_entropy() implementation\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This forward pass code is much longer than before. The cross-entropy part is expanded into many chunks, and the whole process is expanded with many more intermediate steps. That'll help calculate individual gradients at each step, bottom to top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "# Use cmp() functions to check the correctness at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to manually compute each of these derivatives. For example:\n",
    "\n",
    "$\\text{Loss} = \\sum_{i=1}^{n}\\frac{x_i}{n} $\n",
    "$\\implies$\n",
    "$\\frac{d\\text{Loss}}{dx_i} = \\frac{1}{n}$\n",
    "\n",
    "for each $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs) # Sets zeros in shape of logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going on to the other terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use result previously computed above\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n",
    "# logprobs = probs.log()\n",
    "# Log transformation; derivative of ln(x) is 1/x\n",
    "# Use the chain rule\n",
    "dprobs = (1 / probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)\n",
    "\n",
    "# probs = counts * counts_sum_inv\n",
    "# Derivative would just be counts\n",
    "# Try: dcounts_sum_inv = counts * dprobs\n",
    "# That doesn't work due to broadcasting of counts * counts_sum_inv, which have different dimensionality\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim = True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "# Compute dcounts_sum next, before moving on to dcounts\n",
    "# counts_sum_inv = counts_sum**-1\n",
    "# d/dx x^-1 = -x^-2\n",
    "dcounts_sum = (-1.0 / counts_sum**2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "# dcounts has two components\n",
    "# 1) probs = counts * counts_sum_inv\n",
    "# Similar to probs, but derivative is now counts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "# 2) counts_sum = counts.sum(1, keepdims=True)\n",
    "# Derivative \"flows\" equally to all components of the sum; need to account for shape of tensor\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum \n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "# counts = norm_logits.exp()\n",
    "# d/dx exp(x) = exp(x)\n",
    "# Shortcut: just reuse counts, which is defined as exp(norm_logits) already\n",
    "dnorm_logits = counts * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "# norm_logits = logits - logit_maxes\n",
    "# Subtraction: derivative is -1\n",
    "# Need to specify shape of tensor due to \"broadcasting\"\n",
    "dlogit_maxes = -dnorm_logits.sum(1, keepdim = True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "\n",
    "# dlogits has two components\n",
    "# 1) norm_logits = logits - logit_maxes\n",
    "# Addition; derivative is just 1; similar to dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "# 2) logit_maxes = logits.max(1, keepdim=True).values\n",
    "# Derivative of the max is 1 * (element pulled out); scattering max value into appropriate index\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes = logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: banching through logit_maxes, the values there shouldn't matter with respect to the final loss (gradient 0) which is by design. Add that term for numerical stability during the softmax transformation; just making sure we don't have overflow issues. Sure enough the values are extremely small (gradient near 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8626e-09],\n",
      "        [-9.3132e-10],\n",
      "        [ 1.8626e-09],\n",
      "        [-3.7253e-09],\n",
      "        [ 2.7940e-09],\n",
      "        [-2.3283e-09],\n",
      "        [ 4.6566e-10],\n",
      "        [ 4.6566e-09],\n",
      "        [-9.3132e-10],\n",
      "        [-5.3551e-09],\n",
      "        [ 0.0000e+00],\n",
      "        [ 9.3132e-10],\n",
      "        [ 3.2596e-09],\n",
      "        [-2.7940e-09],\n",
      "        [-1.8626e-09],\n",
      "        [-7.9162e-09],\n",
      "        [ 4.6566e-10],\n",
      "        [ 2.3283e-09],\n",
      "        [ 1.3970e-09],\n",
      "        [ 4.6566e-10],\n",
      "        [ 2.3283e-09],\n",
      "        [-1.8626e-09],\n",
      "        [ 4.6566e-09],\n",
      "        [-9.3132e-10],\n",
      "        [ 1.8626e-09],\n",
      "        [ 4.6566e-10],\n",
      "        [ 2.0955e-09],\n",
      "        [ 4.6566e-10],\n",
      "        [-1.8626e-09],\n",
      "        [ 3.0268e-09],\n",
      "        [-1.8626e-09],\n",
      "        [-2.3283e-09]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(dlogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = h @ W2 + b2\n",
    "# Note that @ is the matrix multiplication operation in Python\n",
    "# Rows of h times columns of W2: need to pull out corresponding elements and sum\n",
    "# Which can in and of itself be expressed as a matrix multiplication operation\n",
    "# Multiplication: d/dh logits = dL/dd @ t(b)\n",
    "# But in practice you can check the shape of the matrices and figure out what should be transposed\n",
    "dh = dlogits @ W2.T\n",
    "cmp('h', dh, h)\n",
    "\n",
    "# logits = h @ W2 + b2\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('W2', dW2, W2)\n",
    "\n",
    "# logits = h @ W2 + b2\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits: torch.Size([32, 27])\n",
      "h: torch.Size([32, 64])\n",
      "W2: torch.Size([64, 27])\n",
      "b2: torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print( \"dlogits: \" + str(dlogits.shape))\n",
    "print(\"h: \" + str(h.shape))\n",
    "print(\"W2: \" + str(W2.shape))\n",
    "print(\"b2: \" + str(b2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dimensions gives a hint about the correct matrix operation at each step.\n",
    "\n",
    "Continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# h = torch.tanh(hpreact)\n",
    "# Derivative for tanh from earlier lectures:\n",
    "# d/dx tanh(x) = 1 - tanh(x)^2\n",
    "dhpreact = (1 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "# Onto the batchnorm layers\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "# Just another multiplication backprop; need to fix shape\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim = True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "# Just another multiplication backprop\n",
    "dbnraw = (bngain * dhpreact)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "# Just another sum backprop\n",
    "dbnbias = dhpreact.sum(0, keepdim = True)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "\n",
    "# Some of the batchnorm terms have multiple components\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# Need to account for dimensions of tensor as before\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# Chain rule: d/dx x^a = a*x^(a-1)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
    "# Derivative of the summation is just 1; use the torch.ones_like\n",
    "# trick to make a tensor of 1 of the correct size\n",
    "dbndiff2 = (1/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the $(n-1)$ term in `dbndiff2`? This is Bessel's correction for computing the standard deviation. See https://math.oxford.emory.edu/site/math117/besselCorrection/\n",
    "\n",
    "(When using the estimate of the variance to estimate the mean a degree of freedom was used up; the estimated variance when using $n$ will be too low.)\n",
    "\n",
    "The paper this mini-batch approach is from was inconsistent, using the correction for estimating variance (when mean is unknown) in the results, but the biased version for training.\n",
    "\n",
    "Apparently Pytorch implemented this exactly for Batchnorm and the documentation is inconsistent. Andrej prefers using $(n-1)$ at both training and test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Two branches for bndiff\n",
    "# 1) bnraw = bndiff * bnvar_inv\n",
    "# This is just multiplication\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "# 2) bndiff2 = bndiff**2\n",
    "dbndiff += (2 * bndiff) * dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "# bndiff = hprebn - bnmeani\n",
    "# Just simple subtraction, easy derivative, then sum\n",
    "dbnmeani = (-dbndiff).sum(0, keepdim = True)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "\n",
    "# Two branches for hprebn\n",
    "# 1) bndiff = hprebn - bnmeani\n",
    "# Derivative of a sum is 1\n",
    "dhprebn = dbndiff.clone()\n",
    "# 2) bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# d/dx ax = a, and the sum uses the 1 trick\n",
    "dhprebn += 1/n * torch.ones_like(hprebn) * dbnmeani\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last linear layer, we can look at the shapes again to see what needs to be multiplied intuitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn: torch.Size([32, 64])\n",
      "embcat: torch.Size([32, 30])\n",
      "W1: torch.Size([30, 64])\n",
      "b1: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(\"hprebn: \" + str(hprebn.shape))\n",
    "print(\"embcat: \" + str(embcat.shape))\n",
    "print(\"W1: \" + str(W1.shape))\n",
    "print(\"b1: \" + str(b1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# hprebn = embcat @ W1 + b1\n",
    "# Multiplication: need dhprebn @ W1 in some arrangement\n",
    "# (32, 64) * t(30, 64)\n",
    "dembcat = dhprebn @ W1.T\n",
    "cmp('embcat', dembcat, embcat)\n",
    "\n",
    "# hprebn = embcat @ W1 + b1\n",
    "# Multiplication: embcat @ dhprebn\n",
    "# t(32, 30) * (32, 64)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "cmp('W1', dW1, W1)\n",
    "\n",
    "# hprebn = embcat @ W1 + b1\n",
    "# Summation\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('b1', db1, b1)\n",
    "\n",
    "# embcat = emb.view(emb.shape[0], -1)\n",
    "# Concatenates 3 vectors; we're just undoing this\n",
    "# Need to view it as orignal shape\n",
    "demb = dembcat.view(emb.shape)\n",
    "cmp('emb', demb, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step: need to unindex. Recall that initially we filled in character indices from the lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([27, 10]) torch.Size([32, 3])\n",
      "tensor([[ 1,  1,  4],\n",
      "        [18, 14,  1],\n",
      "        [11,  5,  9],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 15, 14]])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass: emb = C[Xb]\n",
    "print(emb.shape, C.shape, Xb.shape)\n",
    "print(Xb[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integers in Xb specify which row of C is used for the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# emb = C[Xb]\n",
    "# Route back through the indexing - this requires a for loop\n",
    "dC = torch.zeros_like(C)\n",
    "# Iterate over Xb and pull tensors for the indices\n",
    "for k in range(Xb.shape[0]): \n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k, j]\n",
    "# Check results\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of exercise 2 is to analytically derive the correct function, which is much faster than doing the individual steps as above. Not necessary to go step by step because analytically, a lot of the steps cancel and it simplifies.\n",
    "\n",
    "Can get dlogits directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3243653774261475 diff: -7.152557373046875e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the backward pass, after doing a bunch of arithmetic the components of the derivatives simplifies to either $p_i$ or $1 - p_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "dlogits = F.softmax(logits, 1)\n",
    "# subtract 1 at all the correct positions\n",
    "dlogits[range(n), Yb] -= 1\n",
    "# take the average, divide by n at all positions\n",
    "dlogits /= n\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially the same answer to rounding error.\n",
    "\n",
    "Let's get some intuition for what dlogits is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0728,  0.0895,  0.0197,  0.0487,  0.0198,  0.0845,  0.0251,  0.0369,\n",
       "        -0.9817,  0.0316,  0.0365,  0.0336,  0.0338,  0.0287,  0.0378,  0.0136,\n",
       "         0.0100,  0.0197,  0.0169,  0.0555,  0.0445,  0.0214,  0.0244,  0.0710,\n",
       "         0.0594,  0.0257,  0.0208], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element of dlogits\n",
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1742d2ffe80>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black squares are the positions of the correct indices: note that for 0th row the index at 9 is -1. Probability at incorrect characters is pulled down, probability at correct character is pushed up. Training the neural network is like pushing and pulling correctly on the vectors to get closer to the correct answer.\n",
    "\n",
    "Amount of \"force\" applied is proportional to the loss from the forward pass. A confident misprediction leads to everything but the correct answer being strongly pulled toward 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of exercise 3 is to do derivation through a batchnorm layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to take partial derivatives over each of the parameters from the paper.\n",
    "\n",
    "$ \\mu = \\frac{1}{n} \\sum{x_i} $\n",
    "\n",
    "$ \\sigma^2 = \\frac{1}{n-1}\\sum{(x_i - \\mu )^2} $\n",
    "\n",
    "$ \\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} $\n",
    "\n",
    "$ y_i = \\gamma_i \\hat{x}_i + \\beta $\n",
    "\n",
    "Lots of derivatives and substitutions and it all simplifies to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "# Tricky part of the code is everything has to \"broadcast\" with the correct shapes; non-trivial to prove\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step is pasting our own backprop code and get it training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.8312\n",
      "  10000/ 200000: 2.1709\n",
      "  20000/ 200000: 2.4078\n",
      "  30000/ 200000: 2.4702\n",
      "  40000/ 200000: 2.0049\n",
      "  50000/ 200000: 2.4405\n",
      "  60000/ 200000: 2.3187\n",
      "  70000/ 200000: 1.9989\n",
      "  80000/ 200000: 2.3290\n",
      "  90000/ 200000: 2.1815\n",
      " 100000/ 200000: 1.9603\n",
      " 110000/ 200000: 2.3461\n",
      " 120000/ 200000: 2.0194\n",
      " 130000/ 200000: 2.4891\n",
      " 140000/ 200000: 2.2673\n",
      " 150000/ 200000: 2.1853\n",
      " 160000/ 200000: 1.9678\n",
      " 170000/ 200000: 1.7846\n",
      " 180000/ 200000: 1.9524\n",
      " 190000/ 200000: 1.8605\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes quite a bit longer to run than using the built-in implementation, of course, but the loss is comparable to using Pytorch's backward pass.\n",
    "\n",
    "Each layer only takes a few lines of code to do the backward pass. Of course in practice you'd still use Pytorch's loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.068781852722168\n",
      "val 2.1075339317321777\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mona.\n",
      "mayah.\n",
      "see.\n",
      "madhayla.\n",
      "renyla.\n",
      "endraege.\n",
      "derronelin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "sana.\n",
      "arleigh.\n",
      "malaia.\n",
      "noshubergihiriel.\n",
      "kin.\n",
      "renlee.\n",
      "jose.\n",
      "casuna.\n",
      "geder.\n",
      "yarul.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see a couple real names there! Nice milestone for the Swole Doge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
