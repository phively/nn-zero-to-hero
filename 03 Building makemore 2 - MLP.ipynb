{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building makemore: Multi-layer perceptron\n",
    "\n",
    "https://www.youtube.com/watch?v=TCH_1BHY58I\n",
    "\n",
    "Last time: two models, the first using counts and normalizing them to generate the next character in a sequence. Problem: using more characters grows exponentially. With the stop character, $27^n$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benigo et al. approach\n",
    "\n",
    "Better approach: multi-layer perceptron to predict future characters. Scales much better. See: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
    "\n",
    "Goes from 17,000 feature vectors to a 30-dimension space (dimensionality reduction). Approach otherwise is as seen in the previous lecture.\n",
    "\n",
    "Intuitively, \"walking\" and \"running\" should be close to one another in the model space, so if the model's never seen \"The dog was running in the ___\" but it's seen \"The cat was walking in the bedroom\" it'll consider bedroom a likely word to fill in the blank. (Sounds like word embeddings.)\n",
    "\n",
    "Network architecture: embedded input layers, hidden layer (30 parameters), output layer (17,000 parameters). Use softmax to take most probable words when generating a sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "words = open('makemore/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary - same approach as last lecture, identical code\n",
    "# Put special . as 0 element, and shift the alphabet over by 1\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... --> e\n",
      "..e --> m\n",
      ".em --> m\n",
      "emm --> a\n",
      "mma --> .\n",
      "olivia\n",
      "... --> o\n",
      "..o --> l\n",
      ".ol --> i\n",
      "oli --> v\n",
      "liv --> i\n",
      "ivi --> a\n",
      "via --> .\n",
      "ava\n",
      "... --> a\n",
      "..a --> v\n",
      ".av --> a\n",
      "ava --> .\n",
      "isabella\n",
      "... --> i\n",
      "..i --> s\n",
      ".is --> a\n",
      "isa --> b\n",
      "sab --> e\n",
      "abe --> l\n",
      "bel --> l\n",
      "ell --> a\n",
      "lla --> .\n",
      "sophia\n",
      "... --> s\n",
      "..s --> o\n",
      ".so --> p\n",
      "sop --> h\n",
      "oph --> i\n",
      "phi --> a\n",
      "hia --> .\n"
     ]
    }
   ],
   "source": [
    "# Build dataset - new approach using block_size to use the previous n characters to predict the next\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], [] # input, and labels, to neural network\n",
    "\n",
    "for w in words[:5]: # Test on just first few names\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "# Save results\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 examples can be generated: the 4 letters and the stop character. Note that initially there is no previous character, then e, em, emm, mma. The block size is a rolling window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper had 17,000 words, while we have 27 characters (a-z and .) so we need a dimension <27, 2> lookup table.\n",
    "\n",
    "Conceptually, we use a one-hot encoded vector (indicator) to pull out the desired row from the lookup matrix as before. But this time it'll be indexed because this is faster to look up values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4713,  0.7868])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator = g)\n",
    "F.one_hot(torch.tensor(5), num_classes = 27).float() @ C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding a single integer: easy, just return e.g. `C[5]`. Works the same way for tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4713,  0.7868],\n",
       "        [-0.3284, -0.4330],\n",
       "        [ 1.3729,  2.9334],\n",
       "        [ 1.3729,  2.9334],\n",
       "        [ 1.3729,  2.9334]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[torch.tensor([5, 6, 7, 7, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0274, -1.1008])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][4,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden layer\n",
    "\n",
    "Weights are initialized randomly as usual; it'll be 3 * 2 = 6 inputs, due to 2-dimensional embeddings * 3 block size. The number of neurons is up to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100), generator = g)\n",
    "b1 = torch.randn(100, generator = g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`emb @ W1 + b1` doesn't work due to dimensionality of emb. Need to concatenate the 3, 2 into 6 to do matrix multiplication with `W1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2]), torch.Size([32, 2]), torch.Size([32, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.cat to concatenate the embeddings for each imput.\n",
    "emb[:, 0, :].shape, emb[:, 1, :].shape, emb[:, 2, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate on the 1st indexed dimension\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the correct dimensions; just needs to be updated to be generalizable based on the block size. Use `torch.unbind` to unwrap the tensor along a given dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done even more efficiently by recasting the dimensions of a tensor directly by using `view`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3, 3, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as the arguments multiply to 18 in this case, the sequence can be represented with the given dimensions without any additional memory being used. Very efficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674, -0.2373,  1.5674, -0.2373,  1.5674, -0.2373],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373, -0.4713,  0.7868],\n",
       "        [ 1.5674, -0.2373, -0.4713,  0.7868,  2.4448, -0.6701],\n",
       "        [-0.4713,  0.7868,  2.4448, -0.6701,  2.4448, -0.6701],\n",
       "        [ 2.4448, -0.6701,  2.4448, -0.6701, -0.0274, -1.1008],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373,  1.5674, -0.2373],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373, -1.0725,  0.7276],\n",
       "        [ 1.5674, -0.2373, -1.0725,  0.7276, -0.0707,  2.4968],\n",
       "        [-1.0725,  0.7276, -0.0707,  2.4968,  0.6772, -0.8404],\n",
       "        [-0.0707,  2.4968,  0.6772, -0.8404, -0.1158, -1.2078],\n",
       "        [ 0.6772, -0.8404, -0.1158, -1.2078,  0.6772, -0.8404],\n",
       "        [-0.1158, -1.2078,  0.6772, -0.8404, -0.0274, -1.1008],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373,  1.5674, -0.2373],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373, -0.0274, -1.1008],\n",
       "        [ 1.5674, -0.2373, -0.0274, -1.1008, -0.1158, -1.2078],\n",
       "        [-0.0274, -1.1008, -0.1158, -1.2078, -0.0274, -1.1008],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373,  1.5674, -0.2373],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373,  0.6772, -0.8404],\n",
       "        [ 1.5674, -0.2373,  0.6772, -0.8404,  0.1476, -1.0006],\n",
       "        [ 0.6772, -0.8404,  0.1476, -1.0006, -0.0274, -1.1008],\n",
       "        [ 0.1476, -1.0006, -0.0274, -1.1008,  0.2859, -0.0296],\n",
       "        [-0.0274, -1.1008,  0.2859, -0.0296, -0.4713,  0.7868],\n",
       "        [ 0.2859, -0.0296, -0.4713,  0.7868, -0.0707,  2.4968],\n",
       "        [-0.4713,  0.7868, -0.0707,  2.4968, -0.0707,  2.4968],\n",
       "        [-0.0707,  2.4968, -0.0707,  2.4968, -0.0274, -1.1008],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373,  1.5674, -0.2373],\n",
       "        [ 1.5674, -0.2373,  1.5674, -0.2373,  0.1476, -1.0006],\n",
       "        [ 1.5674, -0.2373,  0.1476, -1.0006, -1.0725,  0.7276],\n",
       "        [ 0.1476, -1.0006, -1.0725,  0.7276,  0.0511,  1.3095],\n",
       "        [-1.0725,  0.7276,  0.0511,  1.3095,  1.5618, -1.6261],\n",
       "        [ 0.0511,  1.3095,  1.5618, -1.6261,  0.6772, -0.8404],\n",
       "        [ 1.5618, -1.6261,  0.6772, -0.8404, -0.0274, -1.1008]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as concatenation before\n",
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6952e+00,  8.5502e+00,  1.6284e+00,  ...,  2.2642e+00,\n",
       "         -1.9505e-01,  1.8469e+00],\n",
       "        [ 2.8741e-01,  4.3343e+00,  1.0142e+00,  ...,  2.8221e+00,\n",
       "          3.9128e+00,  3.4733e+00],\n",
       "        [-3.1026e+00,  9.9601e+00, -1.3306e+00,  ..., -5.7069e-01,\n",
       "         -5.9107e+00, -6.9120e-03],\n",
       "        ...,\n",
       "        [-4.3248e+00,  7.4938e+00, -1.6386e+00,  ..., -5.1557e+00,\n",
       "         -3.3276e+00, -3.2464e+00],\n",
       "        [-1.4951e+00,  5.6195e+00,  2.5079e+00,  ..., -1.0607e+00,\n",
       "         -5.2543e-01,  3.4893e+00],\n",
       "        [-1.4982e+00,  8.5941e+00,  1.8897e+00,  ...,  2.4983e+00,\n",
       "          6.9596e+00,  2.6822e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32, 6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6952e+00,  8.5502e+00,  1.6284e+00,  ...,  2.2642e+00,\n",
       "         -1.9505e-01,  1.8469e+00],\n",
       "        [ 2.8741e-01,  4.3343e+00,  1.0142e+00,  ...,  2.8221e+00,\n",
       "          3.9128e+00,  3.4733e+00],\n",
       "        [-3.1026e+00,  9.9601e+00, -1.3306e+00,  ..., -5.7069e-01,\n",
       "         -5.9107e+00, -6.9120e-03],\n",
       "        ...,\n",
       "        [-4.3248e+00,  7.4938e+00, -1.6386e+00,  ..., -5.1557e+00,\n",
       "         -3.3276e+00, -3.2464e+00],\n",
       "        [-1.4951e+00,  5.6195e+00,  2.5079e+00,  ..., -1.0607e+00,\n",
       "         -5.2543e-01,  3.4893e+00],\n",
       "        [-1.4982e+00,  8.5941e+00,  1.8897e+00,  ...,  2.4983e+00,\n",
       "          6.9596e+00,  2.6822e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even better, have pytorch infer the dimensions\n",
    "emb.view(-1, 6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `+ b1` which is a constant bias term; due to Torch's internals even though b1 is a constant vector it will be copied down and added to all rows correctly; always worth checking this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer\n",
    "\n",
    "Input is 100 neurons, output is 27 possible characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27), generator = g)\n",
    "b2 = torch.randn(27, generator = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims = True) # Sum along first dimension\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows sum to 1.\n",
    "\n",
    "Still need to grab probabilities and index prob, and compare to Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5213e-14, 1.2830e-12, 1.9647e-08, 3.1758e-10, 5.6763e-12, 1.0823e-10,\n",
       "        1.8821e-14, 1.1087e-08, 1.6134e-09, 2.1917e-03, 5.3863e-08, 3.1970e-04,\n",
       "        2.0283e-10, 3.5710e-11, 6.2336e-07, 5.1704e-07, 1.4206e-01, 9.5657e-09,\n",
       "        2.0671e-09, 2.5181e-02, 7.6846e-05, 2.8706e-12, 1.6961e-09, 5.6464e-15,\n",
       "        4.4656e-03, 2.6851e-09, 3.5865e-05, 2.3389e-04, 1.6890e-09, 9.5614e-01,\n",
       "        9.7404e-10, 2.1230e-12])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative log likelihood is defined as before, and will be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned up code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator = g)\n",
    "W1 = torch.randn((6, 100), generator = g)\n",
    "b1 = torch.randn(100, generator = g)\n",
    "W2 = torch.randn((100, 27), generator = g)\n",
    "b2 = torch.randn(27, generator = g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # Total parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be the same as when we multiply out the tensor sizes\n",
    "27 * 2 + 6 * 100 + 100 + 100 * 27 + 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function with current parameters\n",
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims = True)\n",
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be further optimized with the `corss_entropy` function which takes the place of the `counts =`, `prob =`, `loss =`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function with current parameters\n",
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "#counts = logits.exp()\n",
    "#prob = counts / counts.sum(1, keepdims = True)\n",
    "#loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss # Should be same as above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always best to use the built-in operations like `cross_entropy` because intermediate steps aren't saved. It's also a better, more efficient implementation for the backward step. Can have a simpler expression when calculating the backpropagation gradients and updates.\n",
    "\n",
    "Additionally, `cross_entropy` can avoid various numerical issues. Consider what happens with extreme values when you roll your own implementation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 3.3311e-04, 6.6906e-03, 9.9298e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([-100, -3, 0, 5])\n",
    "counts = logits.exp()\n",
    "counts / counts.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works ok with lower values, but leads to numerical errors with large numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., nan])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([-100, -3, 0, 100]) # But large numbers lead to numerical errors\n",
    "counts = logits.exp() # ...due to exp() which blows up with large positive numbers\n",
    "counts / counts.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, Pytorch subtracts the maximum from the entire vector to ensure nothing is > 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Need a forward and a backward pass, same as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make the loop run\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.769710540771484\n",
      "13.656400680541992\n",
      "11.298768997192383\n",
      "9.452457427978516\n",
      "7.984262943267822\n",
      "6.891321182250977\n",
      "6.100014686584473\n",
      "5.452036380767822\n",
      "4.898152828216553\n",
      "4.414663791656494\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decreases very rapidly. If we go to ~1000 we'll get very good predictions on our 32 examples of the first words; overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.985849142074585\n",
      "3.6028308868408203\n",
      "3.2621419429779053\n",
      "2.961380958557129\n",
      "2.6982972621917725\n",
      "2.469712972640991\n",
      "2.271660327911377\n",
      "2.101283550262451\n",
      "1.9571770429611206\n",
      "1.837485909461975\n",
      "1.7380964756011963\n",
      "1.6535112857818604\n",
      "1.5790895223617554\n",
      "1.5117661952972412\n",
      "1.4496045112609863\n",
      "1.3913116455078125\n",
      "1.335992455482483\n",
      "1.2830525636672974\n",
      "1.232190728187561\n",
      "1.183381199836731\n",
      "1.1367985010147095\n",
      "1.0926637649536133\n",
      "1.0510920286178589\n",
      "1.0120267868041992\n",
      "0.9752705693244934\n",
      "0.9405564069747925\n",
      "0.9076123833656311\n",
      "0.876192033290863\n",
      "0.8460887670516968\n",
      "0.8171355724334717\n",
      "0.7891988158226013\n",
      "0.7621744275093079\n",
      "0.7359810471534729\n",
      "0.7105576992034912\n",
      "0.685860812664032\n",
      "0.6618651151657104\n",
      "0.6385656595230103\n",
      "0.6159816384315491\n",
      "0.5941658020019531\n",
      "0.5732104778289795\n",
      "0.5532562136650085\n",
      "0.5344880819320679\n",
      "0.5171165466308594\n",
      "0.5013311505317688\n",
      "0.48724257946014404\n",
      "0.47484031319618225\n",
      "0.4639976918697357\n",
      "0.4545140564441681\n",
      "0.44617074728012085\n",
      "0.4387663006782532\n",
      "0.43213313817977905\n",
      "0.4261387884616852\n",
      "0.42067983746528625\n",
      "0.41567522287368774\n",
      "0.41106146574020386\n",
      "0.40678706765174866\n",
      "0.402810662984848\n",
      "0.3990972936153412\n",
      "0.3956179618835449\n",
      "0.39234769344329834\n",
      "0.38926512002944946\n",
      "0.38635191321372986\n",
      "0.38359180092811584\n",
      "0.3809700906276703\n",
      "0.3784741461277008\n",
      "0.37609291076660156\n",
      "0.3738163113594055\n",
      "0.37163496017456055\n",
      "0.3695410192012787\n",
      "0.3675268888473511\n",
      "0.365585595369339\n",
      "0.3637114465236664\n",
      "0.3618983328342438\n",
      "0.3601417541503906\n",
      "0.35843613743782043\n",
      "0.35677799582481384\n",
      "0.35516270995140076\n",
      "0.353586882352829\n",
      "0.35204702615737915\n",
      "0.35053983330726624\n",
      "0.34906241297721863\n",
      "0.3476122319698334\n",
      "0.34618669748306274\n",
      "0.34478360414505005\n",
      "0.3434009850025177\n",
      "0.3420369029045105\n",
      "0.34069007635116577\n",
      "0.3393585979938507\n",
      "0.3380419611930847\n",
      "0.3367389142513275\n",
      "0.3354488015174866\n",
      "0.33417123556137085\n",
      "0.33290600776672363\n",
      "0.33165305852890015\n",
      "0.33041253685951233\n",
      "0.32918497920036316\n",
      "0.3279707133769989\n",
      "0.3267706036567688\n",
      "0.32558536529541016\n",
      "0.32441598176956177\n",
      "0.3232630789279938\n",
      "0.32212790846824646\n",
      "0.3210112452507019\n",
      "0.31991392374038696\n",
      "0.3188367784023285\n",
      "0.31778037548065186\n",
      "0.31674569845199585\n",
      "0.3157328963279724\n",
      "0.3147425651550293\n",
      "0.313774436712265\n",
      "0.31282925605773926\n",
      "0.31190672516822815\n",
      "0.311007022857666\n",
      "0.3101295530796051\n",
      "0.3092743158340454\n",
      "0.3084409832954407\n",
      "0.30762919783592224\n",
      "0.30683833360671997\n",
      "0.3060680627822876\n",
      "0.3053179383277893\n",
      "0.3045872449874878\n",
      "0.30387556552886963\n",
      "0.30318236351013184\n",
      "0.3025070130825043\n",
      "0.3018489480018616\n",
      "0.3012077212333679\n",
      "0.30058276653289795\n",
      "0.29997342824935913\n",
      "0.29937922954559326\n",
      "0.2987997829914093\n",
      "0.29823440313339233\n",
      "0.29768282175064087\n",
      "0.29714447259902954\n",
      "0.2966187596321106\n",
      "0.2961055338382721\n",
      "0.2956041693687439\n",
      "0.2951143682003021\n",
      "0.29463571310043335\n",
      "0.29416781663894653\n",
      "0.2937103509902954\n",
      "0.2932629883289337\n",
      "0.29282522201538086\n",
      "0.2923969328403473\n",
      "0.29197782278060913\n",
      "0.2915675640106201\n",
      "0.29116570949554443\n",
      "0.2907722294330597\n",
      "0.2903868556022644\n",
      "0.2900092303752899\n",
      "0.28963905572891235\n",
      "0.28927624225616455\n",
      "0.28892049193382263\n",
      "0.28857171535491943\n",
      "0.2882295250892639\n",
      "0.28789380192756653\n",
      "0.2875644862651825\n",
      "0.2872411906719208\n",
      "0.286923885345459\n",
      "0.2866123616695404\n",
      "0.28630632162094116\n",
      "0.2860059142112732\n",
      "0.28571078181266785\n",
      "0.2854207754135132\n",
      "0.2851358652114868\n",
      "0.28485575318336487\n",
      "0.28458043932914734\n",
      "0.2843098044395447\n",
      "0.28404369950294495\n",
      "0.2837819457054138\n",
      "0.2835245430469513\n",
      "0.28327128291130066\n",
      "0.2830221354961395\n",
      "0.28277695178985596\n",
      "0.2825356721878052\n",
      "0.28229820728302\n",
      "0.28206437826156616\n",
      "0.2818342447280884\n",
      "0.2816075384616852\n",
      "0.28138434886932373\n",
      "0.2811645269393921\n",
      "0.2809479534626007\n",
      "0.2807346284389496\n",
      "0.2805243730545044\n",
      "0.2803172469139099\n",
      "0.2801131010055542\n",
      "0.2799118757247925\n",
      "0.27971357107162476\n",
      "0.2795179784297943\n",
      "0.2793251872062683\n",
      "0.2791351079940796\n",
      "0.278947651386261\n",
      "0.27876272797584534\n",
      "0.27858033776283264\n",
      "0.2784004211425781\n",
      "0.278222918510437\n",
      "0.2780477702617645\n",
      "0.27787500619888306\n",
      "0.27770450711250305\n",
      "0.27753615379333496\n",
      "0.27737003564834595\n",
      "0.2772060036659241\n",
      "0.2770441472530365\n",
      "0.2768843472003937\n",
      "0.27672645449638367\n",
      "0.276570588350296\n",
      "0.27641671895980835\n",
      "0.2762646973133087\n",
      "0.2761145830154419\n",
      "0.27596625685691833\n",
      "0.27581968903541565\n",
      "0.2756750285625458\n",
      "0.27553194761276245\n",
      "0.2753906548023224\n",
      "0.27525097131729126\n",
      "0.27511298656463623\n",
      "0.27497658133506775\n",
      "0.2748417854309082\n",
      "0.2747085392475128\n",
      "0.2745768129825592\n",
      "0.274446576833725\n",
      "0.27431783080101013\n",
      "0.2741904556751251\n",
      "0.2740646004676819\n",
      "0.27394017577171326\n",
      "0.2738170623779297\n",
      "0.2736952602863312\n",
      "0.2735748291015625\n",
      "0.27345573902130127\n",
      "0.2733379006385803\n",
      "0.27322137355804443\n",
      "0.27310600876808167\n",
      "0.27299192547798157\n",
      "0.272879034280777\n",
      "0.2727673351764679\n",
      "0.27265676856040955\n",
      "0.2725474238395691\n",
      "0.27243921160697937\n",
      "0.2723320424556732\n",
      "0.2722260057926178\n",
      "0.27212104201316833\n",
      "0.27201712131500244\n",
      "0.2719142436981201\n",
      "0.27181240916252136\n",
      "0.27171164751052856\n",
      "0.2716118097305298\n",
      "0.2715129256248474\n",
      "0.2714150846004486\n",
      "0.2713181674480438\n",
      "0.27122217416763306\n",
      "0.2711271345615387\n",
      "0.27103301882743835\n",
      "0.27093979716300964\n",
      "0.2708474397659302\n",
      "0.2707560062408447\n",
      "0.27066537737846375\n",
      "0.2705755829811096\n",
      "0.2704866826534271\n",
      "0.27039864659309387\n",
      "0.2703113257884979\n",
      "0.27022483944892883\n",
      "0.2701391279697418\n",
      "0.27005428075790405\n",
      "0.2699701189994812\n",
      "0.26988673210144043\n",
      "0.26980409026145935\n",
      "0.26972222328186035\n",
      "0.26964104175567627\n",
      "0.26956063508987427\n",
      "0.2694808542728424\n",
      "0.2694018483161926\n",
      "0.26932352781295776\n",
      "0.26924583315849304\n",
      "0.26916882395744324\n",
      "0.26909253001213074\n",
      "0.2690168023109436\n",
      "0.26894184947013855\n",
      "0.26886746287345886\n",
      "0.2687937021255493\n",
      "0.26872050762176514\n",
      "0.2686479985713959\n",
      "0.26857611536979675\n",
      "0.268504798412323\n",
      "0.268434077501297\n",
      "0.26836395263671875\n",
      "0.2682943344116211\n",
      "0.26822543144226074\n",
      "0.2681569457054138\n",
      "0.26808905601501465\n",
      "0.26802176237106323\n",
      "0.2679549753665924\n",
      "0.2678886950016022\n",
      "0.2678229808807373\n",
      "0.2677578032016754\n",
      "0.26769310235977173\n",
      "0.26762890815734863\n",
      "0.2675653100013733\n",
      "0.2675021290779114\n",
      "0.26743942499160767\n",
      "0.26737719774246216\n",
      "0.267315536737442\n",
      "0.2672543227672577\n",
      "0.2671935260295868\n",
      "0.26713326573371887\n",
      "0.2670733630657196\n",
      "0.2670140266418457\n",
      "0.26695507764816284\n",
      "0.2668965458869934\n",
      "0.26683852076530457\n",
      "0.26678088307380676\n",
      "0.2667236924171448\n",
      "0.2666669189929962\n",
      "0.26661062240600586\n",
      "0.26655465364456177\n",
      "0.2664991617202759\n",
      "0.26644399762153625\n",
      "0.26638928055763245\n",
      "0.2663349509239197\n",
      "0.26628100872039795\n",
      "0.26622745394706726\n",
      "0.26617431640625\n",
      "0.2661215662956238\n",
      "0.2660691440105438\n",
      "0.2660171091556549\n",
      "0.26596543192863464\n",
      "0.2659141719341278\n",
      "0.26586323976516724\n",
      "0.26581263542175293\n",
      "0.26576241850852966\n",
      "0.2657124996185303\n",
      "0.26566293835639954\n",
      "0.26561373472213745\n",
      "0.265564888715744\n",
      "0.26551637053489685\n",
      "0.26546820998191833\n",
      "0.2654203772544861\n",
      "0.26537275314331055\n",
      "0.26532554626464844\n",
      "0.2652786374092102\n",
      "0.2652320861816406\n",
      "0.2651858329772949\n",
      "0.2651398181915283\n",
      "0.26509416103363037\n",
      "0.2650487720966339\n",
      "0.2650037407875061\n",
      "0.2649589776992798\n",
      "0.26491451263427734\n",
      "0.264870285987854\n",
      "0.2648264169692993\n",
      "0.26478278636932373\n",
      "0.264739453792572\n",
      "0.2646964192390442\n",
      "0.26465368270874023\n",
      "0.2646111249923706\n",
      "0.26456889510154724\n",
      "0.26452696323394775\n",
      "0.26448529958724976\n",
      "0.26444384455680847\n",
      "0.26440268754959106\n",
      "0.26436173915863037\n",
      "0.26432108879089355\n",
      "0.2642807066440582\n",
      "0.264240562915802\n",
      "0.2642006278038025\n",
      "0.26416099071502686\n",
      "0.26412156224250793\n",
      "0.2640824317932129\n",
      "0.26404353976249695\n",
      "0.26400482654571533\n",
      "0.2639663815498352\n",
      "0.2639281451702118\n",
      "0.26389017701148987\n",
      "0.26385238766670227\n",
      "0.26381486654281616\n",
      "0.26377761363983154\n",
      "0.2637404799461365\n",
      "0.2637036442756653\n",
      "0.2636669874191284\n",
      "0.26363056898117065\n",
      "0.2635943591594696\n",
      "0.26355838775634766\n",
      "0.2635226249694824\n",
      "0.2634870409965515\n",
      "0.2634516954421997\n",
      "0.2634165287017822\n",
      "0.26338157057762146\n",
      "0.2633468210697174\n",
      "0.26331230998039246\n",
      "0.26327797770500183\n",
      "0.2632438540458679\n",
      "0.26320990920066833\n",
      "0.2631761431694031\n",
      "0.2631426751613617\n",
      "0.26310932636260986\n",
      "0.26307615637779236\n",
      "0.26304325461387634\n",
      "0.26301050186157227\n",
      "0.2629779577255249\n",
      "0.26294562220573425\n",
      "0.26291346549987793\n",
      "0.26288145780563354\n",
      "0.26284974813461304\n",
      "0.26281824707984924\n",
      "0.2627869248390198\n",
      "0.26275578141212463\n",
      "0.262724906206131\n",
      "0.26269423961639404\n",
      "0.2626638412475586\n",
      "0.26263362169265747\n",
      "0.2626037299633026\n",
      "0.26257407665252686\n",
      "0.26254475116729736\n",
      "0.26251569390296936\n",
      "0.2624870538711548\n",
      "0.2624587118625641\n",
      "0.2624308466911316\n",
      "0.2624033987522125\n",
      "0.26237648725509644\n",
      "0.26235005259513855\n",
      "0.2623245120048523\n",
      "0.2622993588447571\n",
      "0.26227542757987976\n",
      "0.2622520923614502\n",
      "0.26223024725914\n",
      "0.26220929622650146\n",
      "0.26219040155410767\n",
      "0.26217254996299744\n",
      "0.26215770840644836\n",
      "0.2621440887451172\n",
      "0.26213470101356506\n",
      "0.2621266543865204\n",
      "0.2621248662471771\n",
      "0.26212432980537415\n",
      "0.2621331810951233\n",
      "0.2621425688266754\n",
      "0.2621656358242035\n",
      "0.2621878385543823\n",
      "0.26223039627075195\n",
      "0.2622687518596649\n",
      "0.2623368501663208\n",
      "0.2623941898345947\n",
      "0.26249486207962036\n",
      "0.2625730633735657\n",
      "0.2627132833003998\n",
      "0.2628110647201538\n",
      "0.26299595832824707\n",
      "0.2631071209907532\n",
      "0.26333755254745483\n",
      "0.2634488344192505\n",
      "0.26371893286705017\n",
      "0.2638107240200043\n",
      "0.2641075849533081\n",
      "0.2641575038433075\n",
      "0.26446303725242615\n",
      "0.26445266604423523\n",
      "0.26474955677986145\n",
      "0.2646702229976654\n",
      "0.26494571566581726\n",
      "0.2648007571697235\n",
      "0.26504984498023987\n",
      "0.26485154032707214\n",
      "0.2650747299194336\n",
      "0.2648385167121887\n",
      "0.26503971219062805\n",
      "0.26478031277656555\n",
      "0.264963835477829\n",
      "0.26469242572784424\n",
      "0.2648622691631317\n",
      "0.2645869553089142\n",
      "0.26474589109420776\n",
      "0.26447147130966187\n",
      "0.2646215558052063\n",
      "0.26435112953186035\n",
      "0.2644936740398407\n",
      "0.2642291486263275\n",
      "0.2643652558326721\n",
      "0.26410743594169617\n",
      "0.2642378807067871\n",
      "0.2639872431755066\n",
      "0.26411229372024536\n",
      "0.2638689875602722\n",
      "0.2639891803264618\n",
      "0.26375308632850647\n",
      "0.26386862993240356\n",
      "0.26363974809646606\n",
      "0.2637510895729065\n",
      "0.26352906227111816\n",
      "0.2636362314224243\n",
      "0.26342102885246277\n",
      "0.26352447271347046\n",
      "0.26331567764282227\n",
      "0.26341554522514343\n",
      "0.26321303844451904\n",
      "0.26330941915512085\n",
      "0.2631128430366516\n",
      "0.26320600509643555\n",
      "0.26301515102386475\n",
      "0.26310521364212036\n",
      "0.2629198133945465\n",
      "0.26300692558288574\n",
      "0.26282694935798645\n",
      "0.26291123032569885\n",
      "0.2627362906932831\n",
      "0.26281794905662537\n",
      "0.2626477777957916\n",
      "0.2627270221710205\n",
      "0.2625614404678345\n",
      "0.2626381814479828\n",
      "0.26247695088386536\n",
      "0.26255136728286743\n",
      "0.2623944878578186\n",
      "0.26246678829193115\n",
      "0.2623140215873718\n",
      "0.26238423585891724\n",
      "0.26223525404930115\n",
      "0.2623034417629242\n",
      "0.26215824484825134\n",
      "0.2622244656085968\n",
      "0.26208293437957764\n",
      "0.2621473968029022\n",
      "0.2620092034339905\n",
      "0.262071818113327\n",
      "0.2619370222091675\n",
      "0.2619980573654175\n",
      "0.26186642050743103\n",
      "0.26192590594291687\n",
      "0.2617972493171692\n",
      "0.26185521483421326\n",
      "0.26172956824302673\n",
      "0.2617860734462738\n",
      "0.2616632580757141\n",
      "0.2617182731628418\n",
      "0.2615981698036194\n",
      "0.26165199279785156\n",
      "0.26153451204299927\n",
      "0.26158687472343445\n",
      "0.2614719271659851\n",
      "0.26152312755584717\n",
      "0.26141053438186646\n",
      "0.2614606022834778\n",
      "0.2613503634929657\n",
      "0.26139935851097107\n",
      "0.26129141449928284\n",
      "0.2613392770290375\n",
      "0.2612334191799164\n",
      "0.2612803280353546\n",
      "0.26117652654647827\n",
      "0.26122239232063293\n",
      "0.26112064719200134\n",
      "0.2611656188964844\n",
      "0.261065810918808\n",
      "0.2611098885536194\n",
      "0.26101183891296387\n",
      "0.26105502247810364\n",
      "0.26095885038375854\n",
      "0.2610011696815491\n",
      "0.26090678572654724\n",
      "0.2609483599662781\n",
      "0.26085564494132996\n",
      "0.26089635491371155\n",
      "0.2608051896095276\n",
      "0.26084521412849426\n",
      "0.26075559854507446\n",
      "0.26079487800598145\n",
      "0.2607067823410034\n",
      "0.26074543595314026\n",
      "0.26065877079963684\n",
      "0.26069676876068115\n",
      "0.26061150431632996\n",
      "0.26064878702163696\n",
      "0.260564923286438\n",
      "0.26060163974761963\n",
      "0.2605191469192505\n",
      "0.26055529713630676\n",
      "0.2604740560054779\n",
      "0.2605096399784088\n",
      "0.26042959094047546\n",
      "0.26046469807624817\n",
      "0.26038578152656555\n",
      "0.2604203224182129\n",
      "0.26034262776374817\n",
      "0.2603766620159149\n",
      "0.26030004024505615\n",
      "0.2603335380554199\n",
      "0.2602580487728119\n",
      "0.26029109954833984\n",
      "0.26021671295166016\n",
      "0.2602492570877075\n",
      "0.26017582416534424\n",
      "0.26020804047584534\n",
      "0.2601356506347656\n",
      "0.2601673901081085\n",
      "0.26009586453437805\n",
      "0.2601272463798523\n",
      "0.2600567042827606\n",
      "0.26008766889572144\n",
      "0.2600179612636566\n",
      "0.2600485384464264\n",
      "0.25997981429100037\n",
      "0.26001009345054626\n",
      "0.25994208455085754\n",
      "0.2599720358848572\n",
      "0.2599048614501953\n",
      "0.2599344253540039\n",
      "0.2598680555820465\n",
      "0.25989729166030884\n",
      "0.2598316967487335\n",
      "0.2598605751991272\n",
      "0.25979575514793396\n",
      "0.25982433557510376\n",
      "0.2597602903842926\n",
      "0.2597885727882385\n",
      "0.2597251832485199\n",
      "0.2597532272338867\n",
      "0.259690523147583\n",
      "0.2597182095050812\n",
      "0.25965616106987\n",
      "0.25968360900878906\n",
      "0.2596222162246704\n",
      "0.2596493363380432\n",
      "0.2595885694026947\n",
      "0.2596154808998108\n",
      "0.2595554292201996\n",
      "0.2595821022987366\n",
      "0.2595226466655731\n",
      "0.25954899191856384\n",
      "0.25949013233184814\n",
      "0.25951626896858215\n",
      "0.25945794582366943\n",
      "0.25948387384414673\n",
      "0.25942614674568176\n",
      "0.25945186614990234\n",
      "0.25939467549324036\n",
      "0.25942015647888184\n",
      "0.25936347246170044\n",
      "0.2593887448310852\n",
      "0.2593326270580292\n",
      "0.2593576908111572\n",
      "0.259302020072937\n",
      "0.25932684540748596\n",
      "0.2592717409133911\n",
      "0.2592964768409729\n",
      "0.2592417597770691\n",
      "0.2592662572860718\n",
      "0.25921207666397095\n",
      "0.25923627614974976\n",
      "0.25918254256248474\n",
      "0.2592065632343292\n",
      "0.2591533660888672\n",
      "0.2591772675514221\n",
      "0.2591245770454407\n",
      "0.2591482698917389\n",
      "0.2590959668159485\n",
      "0.25911945104599\n",
      "0.2590675354003906\n",
      "0.2590909004211426\n",
      "0.2590394914150238\n",
      "0.25906261801719666\n",
      "0.25901156663894653\n",
      "0.25903457403182983\n",
      "0.25898391008377075\n",
      "0.2590067982673645\n",
      "0.25895658135414124\n",
      "0.25897926092147827\n",
      "0.25892943143844604\n",
      "0.25895199179649353\n",
      "0.25890251994132996\n",
      "0.25892484188079834\n",
      "0.2588757276535034\n",
      "0.25889796018600464\n",
      "0.25884923338890076\n",
      "0.25887125730514526\n",
      "0.2588229477405548\n",
      "0.2588448226451874\n",
      "0.2587968111038208\n",
      "0.2588185966014862\n",
      "0.2587709128856659\n",
      "0.2587924897670746\n",
      "0.2587451934814453\n",
      "0.25876665115356445\n",
      "0.25871971249580383\n",
      "0.2587410807609558\n",
      "0.25869446992874146\n",
      "0.25871559977531433\n",
      "0.25866928696632385\n",
      "0.25869035720825195\n",
      "0.25864431262016296\n",
      "0.2586652338504791\n",
      "0.2586195766925812\n",
      "0.2586404085159302\n",
      "0.2585950195789337\n",
      "0.2586156725883484\n",
      "0.25857070088386536\n",
      "0.2585912346839905\n",
      "0.25854650139808655\n",
      "0.2585669159889221\n",
      "0.2585224509239197\n",
      "0.2585427463054657\n",
      "0.25849854946136475\n",
      "0.2585187256336212\n",
      "0.25847485661506653\n",
      "0.25849485397338867\n",
      "0.25845128297805786\n",
      "0.25847122073173523\n",
      "0.2584279179573059\n",
      "0.25844764709472656\n",
      "0.2584047019481659\n",
      "0.258424311876297\n",
      "0.25838157534599304\n",
      "0.25840112566947937\n",
      "0.2583586871623993\n",
      "0.2583780884742737\n",
      "0.2583359479904175\n",
      "0.2583552598953247\n",
      "0.2583134174346924\n",
      "0.25833258032798767\n",
      "0.25829097628593445\n",
      "0.2583099901676178\n",
      "0.25826865434646606\n",
      "0.25828757882118225\n",
      "0.258246511220932\n",
      "0.25826531648635864\n",
      "0.2582244873046875\n",
      "0.25824323296546936\n",
      "0.25820258259773254\n",
      "0.25822120904922485\n",
      "0.2581808865070343\n",
      "0.25819942355155945\n",
      "0.258159339427948\n",
      "0.2581777274608612\n",
      "0.25813788175582886\n",
      "0.2581561505794525\n",
      "0.25811654329299927\n",
      "0.25813472270965576\n",
      "0.2580953538417816\n",
      "0.2581133544445038\n",
      "0.2580742835998535\n",
      "0.2580922544002533\n",
      "0.25805339217185974\n",
      "0.2580711841583252\n",
      "0.25803256034851074\n",
      "0.25805026292800903\n",
      "0.25801190733909607\n",
      "0.2580294907093048\n",
      "0.25799134373664856\n",
      "0.25800883769989014\n",
      "0.2579708695411682\n",
      "0.25798824429512024\n",
      "0.2579505443572998\n",
      "0.2579677700996399\n",
      "0.2579302191734314\n",
      "0.25794750452041626\n",
      "0.25791019201278687\n",
      "0.25792717933654785\n",
      "0.25789013504981995\n",
      "0.25790709257125854\n",
      "0.25787028670310974\n",
      "0.2578870952129364\n",
      "0.25785043835639954\n",
      "0.2578672170639038\n",
      "0.2578308582305908\n",
      "0.25784748792648315\n",
      "0.2578112483024597\n",
      "0.2578276991844177\n",
      "0.25779178738594055\n",
      "0.25780820846557617\n",
      "0.25777241587638855\n",
      "0.2577887773513794\n",
      "0.25775325298309326\n",
      "0.25776946544647217\n",
      "0.25773411989212036\n",
      "0.2577502131462097\n",
      "0.2577151656150818\n",
      "0.257731169462204\n",
      "0.257696270942688\n",
      "0.25771212577819824\n",
      "0.25767743587493896\n",
      "0.2576932907104492\n",
      "0.25765883922576904\n",
      "0.25767451524734497\n",
      "0.2576403021812439\n",
      "0.25765588879585266\n",
      "0.2576218247413635\n",
      "0.2576373517513275\n",
      "0.2576035261154175\n",
      "0.25761890411376953\n",
      "0.2575852572917938\n",
      "0.2576005756855011\n",
      "0.2575671076774597\n",
      "0.25758233666419983\n",
      "0.25754910707473755\n",
      "0.2575641870498657\n",
      "0.2575311064720154\n",
      "0.25754621624946594\n",
      "0.2575133442878723\n",
      "0.25752827525138855\n",
      "0.25749558210372925\n",
      "0.25751039385795593\n",
      "0.25747787952423096\n",
      "0.2574925720691681\n",
      "0.25746023654937744\n",
      "0.2574748694896698\n",
      "0.25744277238845825\n",
      "0.2574573755264282\n",
      "0.25742536783218384\n",
      "0.25743982195854187\n",
      "0.2574080228805542\n",
      "0.25742247700691223\n",
      "0.25739091634750366\n",
      "0.257405161857605\n",
      "0.2573738098144531\n",
      "0.25738799571990967\n",
      "0.25735679268836975\n",
      "0.2573709189891815\n",
      "0.25733986496925354\n",
      "0.25735384225845337\n",
      "0.2573230266571045\n",
      "0.25733691453933716\n",
      "0.2573062479496002\n",
      "0.25732001662254333\n",
      "0.2572895586490631\n",
      "0.25730329751968384\n",
      "0.25727301836013794\n",
      "0.2572866380214691\n",
      "0.25725647807121277\n",
      "0.25727009773254395\n",
      "0.2572401463985443\n",
      "0.2572535574436188\n",
      "0.25722378492355347\n",
      "0.2572370767593384\n",
      "0.257207453250885\n",
      "0.25722065567970276\n",
      "0.2571912407875061\n",
      "0.2572043538093567\n",
      "0.257175087928772\n",
      "0.2571881115436554\n",
      "0.25715911388397217\n",
      "0.2571720778942108\n",
      "0.25714319944381714\n",
      "0.2571561336517334\n",
      "0.25712743401527405\n",
      "0.25714021921157837\n",
      "0.25711172819137573\n",
      "0.2571244239807129\n",
      "0.2570960223674774\n",
      "0.2571086883544922\n",
      "0.25708043575286865\n",
      "0.25709301233291626\n",
      "0.2570649981498718\n",
      "0.2570773959159851\n",
      "0.2570495009422302\n",
      "0.2570619285106659\n",
      "0.25703418254852295\n",
      "0.25704652070999146\n",
      "0.25701895356178284\n",
      "0.25703123211860657\n",
      "0.2570038437843323\n",
      "0.25701597332954407\n",
      "0.2569887042045593\n",
      "0.25700074434280396\n",
      "0.25697365403175354\n",
      "0.256985604763031\n",
      "0.25695866346359253\n",
      "0.25697052478790283\n",
      "0.2569436728954315\n",
      "0.2569555342197418\n",
      "0.25692883133888245\n",
      "0.256940633058548\n",
      "0.2569141387939453\n",
      "0.2569257915019989\n",
      "0.25689947605133057\n",
      "0.25691109895706177\n",
      "0.2568848729133606\n",
      "0.25689631700515747\n",
      "0.2568702697753906\n",
      "0.2568816840648651\n",
      "0.25685587525367737\n",
      "0.2568672299385071\n",
      "0.2568414807319641\n",
      "0.25685280561447144\n",
      "0.2568272352218628\n",
      "0.25683844089508057\n",
      "0.2568129897117615\n",
      "0.2568241059780121\n",
      "0.2567988634109497\n",
      "0.25680989027023315\n",
      "0.2567847669124603\n",
      "0.2567957043647766\n",
      "0.2567707300186157\n",
      "0.256781667470932\n",
      "0.25675684213638306\n",
      "0.256767600774765\n",
      "0.2567428946495056\n",
      "0.2567536532878876\n",
      "0.2567290961742401\n",
      "0.2567397654056549\n",
      "0.2567153573036194\n",
      "0.2567259669303894\n",
      "0.25670167803764343\n",
      "0.2567121982574463\n",
      "0.25668802857398987\n",
      "0.2566984295845032\n",
      "0.2566744089126587\n",
      "0.256684809923172\n",
      "0.25666096806526184\n",
      "0.2566712498664856\n",
      "0.2566475570201874\n",
      "0.25665780901908875\n",
      "0.25663426518440247\n",
      "0.2566443979740143\n",
      "0.25662094354629517\n",
      "0.2566310167312622\n",
      "0.25660771131515503\n",
      "0.2566177546977997\n",
      "0.25659459829330444\n",
      "0.2566045820713043\n",
      "0.25658154487609863\n",
      "0.25659146904945374\n",
      "0.25656858086586\n",
      "0.25657835602760315\n",
      "0.25655555725097656\n",
      "0.25656527280807495\n",
      "0.2565426826477051\n",
      "0.2565523684024811\n",
      "0.2565298080444336\n",
      "0.25653937458992004\n",
      "0.2565169930458069\n",
      "0.25652649998664856\n",
      "0.25650423765182495\n",
      "0.25651365518569946\n",
      "0.2564915418624878\n",
      "0.2565009295940399\n",
      "0.2564789354801178\n",
      "0.25648829340934753\n",
      "0.25646641850471497\n",
      "0.25647562742233276\n",
      "0.25645390152931213\n",
      "0.25646311044692993\n",
      "0.25644150376319885\n",
      "0.2564506530761719\n",
      "0.25642913579940796\n",
      "0.2564382553100586\n",
      "0.25641685724258423\n",
      "0.2564258873462677\n",
      "0.2564046382904053\n",
      "0.25641360878944397\n",
      "0.2563924789428711\n",
      "0.2564014494419098\n",
      "0.2563803791999817\n",
      "0.2563892900943756\n",
      "0.25636839866638184\n",
      "0.256377249956131\n",
      "0.2563563585281372\n",
      "0.2563650608062744\n",
      "0.2563444674015045\n",
      "0.25635313987731934\n",
      "0.2563326060771942\n",
      "0.25634121894836426\n",
      "0.2563207149505615\n",
      "0.25632935762405396\n",
      "0.2563089430332184\n",
      "0.2563174068927765\n",
      "0.25629723072052\n",
      "0.25630566477775574\n",
      "0.25628557801246643\n",
      "0.25629398226737976\n",
      "0.25627392530441284\n",
      "0.25628232955932617\n",
      "0.2562623620033264\n",
      "0.2562706470489502\n",
      "0.25625088810920715\n",
      "0.25625908374786377\n",
      "0.2562394142150879\n",
      "0.2562475800514221\n",
      "0.2562280297279358\n",
      "0.25623613595962524\n",
      "0.25621670484542847\n",
      "0.25622478127479553\n",
      "0.2562054395675659\n",
      "0.2562134861946106\n",
      "0.25619420409202576\n",
      "0.25620222091674805\n",
      "0.25618308782577515\n",
      "0.2561909854412079\n",
      "0.2561720013618469\n",
      "0.25617992877960205\n",
      "0.2561609745025635\n",
      "0.25616878271102905\n",
      "0.25614991784095764\n",
      "0.25615769624710083\n",
      "0.25613895058631897\n",
      "0.2561466097831726\n",
      "0.2561279833316803\n",
      "0.2561357021331787\n",
      "0.2561171054840088\n",
      "0.25612473487854004\n",
      "0.25610628724098206\n",
      "0.25611379742622375\n",
      "0.25609540939331055\n",
      "0.25610291957855225\n",
      "0.25608471035957336\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can never get down to 0 with a perfect fit because e.g. the first index ... is equally likely to return e, a, o, ..., but the other characters have a unique input leading to a unique output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset - new approach using block_size to use the previous n characters to predict the next\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], [] # input, and labels, to neural network\n",
    "\n",
    "for w in words: # Test on just first few names\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "# Save results\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try rerunning the model with the same initialization, parameter dimensions but much more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parameters(seed = 2147483647):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    C = torch.randn((27, 2), generator = g)\n",
    "    W1 = torch.randn((6, 100), generator = g)\n",
    "    b1 = torch.randn(100, generator = g)\n",
    "    W2 = torch.randn((100, 27), generator = g)\n",
    "    b2 = torch.randn(27, generator = g)\n",
    "    parameters = [C, W1, b1, W2, b2]\n",
    "    # Needed to make the loop run\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "    return g, C, W1, b1, W2, b2, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, C, W1, b1, W2, b2, parameters = make_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.505229949951172\n",
      "17.084495544433594\n",
      "15.776534080505371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.833340644836426\n",
      "14.002596855163574\n",
      "13.253252029418945\n",
      "12.579911231994629\n",
      "11.9830961227417\n",
      "11.470492362976074\n",
      "11.051856994628906\n",
      "10.709589004516602\n",
      "10.407635688781738\n",
      "10.127811431884766\n",
      "9.86436939239502\n",
      "9.614506721496582\n",
      "9.376442909240723\n",
      "9.148948669433594\n",
      "8.93111515045166\n",
      "8.722233772277832\n",
      "8.521753311157227\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is noticeably slower than before; 4.2 seconds to run because it's inefficiently going through all 200k+ training examples.\n",
    "\n",
    "For efficiency: randomly sample the data in batches and update the parameters only on those batches. Should lead to about as good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 2, 3, 2, 3, 4, 0, 3, 2, 4, 2, 1, 4, 0, 0, 4, 3, 2, 0, 1, 4, 3, 1,\n",
       "        0, 4, 1, 2, 0, 3, 0, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 5, (32, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([102433,   9814,  91652,  51207, 129639, 123320,  72096,  51467,  79361,\n",
       "         93954, 176150, 152800, 102726, 109179,  99546, 208112, 123029, 108657,\n",
       "          3087, 121127, 208060,  64160,  84980, 109857, 207379,  61445, 226424,\n",
       "         86717, 168980, 225231, 128624,  73666])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generalized version\n",
    "torch.randint(0, X.shape[0], (32, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.926772594451904\n",
      "10.532811164855957\n",
      "9.693974494934082\n",
      "7.263444423675537\n",
      "7.875650405883789\n",
      "8.556546211242676\n",
      "7.139679908752441\n",
      "8.364435195922852\n",
      "6.461527347564697\n",
      "6.858159065246582\n",
      "7.073001861572266\n",
      "8.071428298950195\n",
      "6.570007801055908\n",
      "6.08051872253418\n",
      "7.6064043045043945\n",
      "6.5457611083984375\n",
      "6.351294040679932\n",
      "5.201539993286133\n",
      "6.356577396392822\n",
      "4.916750431060791\n",
      "6.040419101715088\n",
      "5.464047431945801\n",
      "4.966925621032715\n",
      "6.679656028747559\n",
      "5.945621490478516\n",
      "6.347047805786133\n",
      "6.545732498168945\n",
      "5.953789234161377\n",
      "5.367094993591309\n",
      "6.516734600067139\n",
      "6.078299522399902\n",
      "5.878421783447266\n",
      "4.802438259124756\n",
      "4.641851425170898\n",
      "5.384029865264893\n",
      "4.875652313232422\n",
      "4.538542747497559\n",
      "3.1303696632385254\n",
      "3.6793572902679443\n",
      "4.666067600250244\n",
      "4.753857135772705\n",
      "4.604435920715332\n",
      "5.7665252685546875\n",
      "4.33361291885376\n",
      "6.130228042602539\n",
      "5.403964996337891\n",
      "4.546337127685547\n",
      "3.6594834327697754\n",
      "4.319334506988525\n",
      "4.124264717102051\n",
      "4.182192802429199\n",
      "4.577882289886475\n",
      "4.0338263511657715\n",
      "5.238301753997803\n",
      "4.648142337799072\n",
      "3.042616605758667\n",
      "3.788773775100708\n",
      "5.0143046379089355\n",
      "4.556661128997803\n",
      "3.9710938930511475\n",
      "3.6094768047332764\n",
      "4.114524841308594\n",
      "3.6414387226104736\n",
      "4.675875186920166\n",
      "4.068011283874512\n",
      "4.380452632904053\n",
      "4.079992294311523\n",
      "4.122673988342285\n",
      "2.8682026863098145\n",
      "3.833632707595825\n",
      "3.467823028564453\n",
      "4.025428771972656\n",
      "4.205712795257568\n",
      "4.009342670440674\n",
      "3.677985429763794\n",
      "3.725602388381958\n",
      "4.447585582733154\n",
      "3.468484401702881\n",
      "4.026710033416748\n",
      "3.7141776084899902\n",
      "3.2891461849212646\n",
      "3.5191409587860107\n",
      "3.6535985469818115\n",
      "3.034412384033203\n",
      "4.177343845367432\n",
      "3.472872734069824\n",
      "3.2394256591796875\n",
      "3.358289957046509\n",
      "3.612712860107422\n",
      "3.407054901123047\n",
      "3.504183530807495\n",
      "3.7486915588378906\n",
      "4.0680012702941895\n",
      "2.79386043548584\n",
      "4.14104700088501\n",
      "5.343163967132568\n",
      "3.0424463748931885\n",
      "4.2947869300842285\n",
      "4.059526443481445\n",
      "3.5770821571350098\n",
      "3.140979528427124\n",
      "3.472686529159546\n",
      "3.0548534393310547\n",
      "2.9902536869049072\n",
      "3.2125959396362305\n",
      "3.922471284866333\n",
      "3.163485288619995\n",
      "3.522257089614868\n",
      "4.133536338806152\n",
      "4.270916938781738\n",
      "3.3549649715423584\n",
      "3.4769582748413086\n",
      "3.4263832569122314\n",
      "3.8060483932495117\n",
      "3.191084384918213\n",
      "3.5525028705596924\n",
      "3.9711341857910156\n",
      "3.500699043273926\n",
      "3.2346560955047607\n",
      "3.1929585933685303\n",
      "3.5301947593688965\n",
      "3.3081092834472656\n",
      "3.058474540710449\n",
      "3.038804531097412\n",
      "3.367093801498413\n",
      "2.8250372409820557\n",
      "3.589380979537964\n",
      "2.49475359916687\n",
      "3.38917875289917\n",
      "3.496934175491333\n",
      "3.2697548866271973\n",
      "3.328110694885254\n",
      "3.375699043273926\n",
      "2.5639634132385254\n",
      "2.244398593902588\n",
      "2.9145498275756836\n",
      "3.1920461654663086\n",
      "2.570620536804199\n",
      "3.8869991302490234\n",
      "3.6016485691070557\n",
      "3.1969785690307617\n",
      "3.1042799949645996\n",
      "3.097943067550659\n",
      "3.38114333152771\n",
      "3.695786476135254\n",
      "3.144437074661255\n",
      "3.1483983993530273\n",
      "2.5751707553863525\n",
      "2.834014654159546\n",
      "3.7994556427001953\n",
      "3.2648236751556396\n",
      "4.30381965637207\n",
      "3.1494557857513428\n",
      "2.666942834854126\n",
      "3.3844125270843506\n",
      "2.860370635986328\n",
      "3.0583205223083496\n",
      "3.3701059818267822\n",
      "3.87567400932312\n",
      "3.873317241668701\n",
      "3.610915422439575\n",
      "3.1563758850097656\n",
      "3.248953104019165\n",
      "2.95190167427063\n",
      "3.567457675933838\n",
      "3.3005623817443848\n",
      "3.148353338241577\n",
      "3.917670965194702\n",
      "3.508226156234741\n",
      "2.9488346576690674\n",
      "2.7190561294555664\n",
      "3.2898101806640625\n",
      "2.850179672241211\n",
      "3.228419780731201\n",
      "3.306962728500366\n",
      "2.7125513553619385\n",
      "3.521763801574707\n",
      "3.16617488861084\n",
      "3.069108009338379\n",
      "2.9159178733825684\n",
      "2.9571993350982666\n",
      "3.5191566944122314\n",
      "3.41062593460083\n",
      "3.0247347354888916\n",
      "3.6874773502349854\n",
      "2.4159247875213623\n",
      "2.755079507827759\n",
      "3.2352399826049805\n",
      "3.5318596363067627\n",
      "2.9129831790924072\n",
      "2.8763463497161865\n",
      "3.062195062637329\n",
      "2.7328903675079346\n",
      "3.2618303298950195\n",
      "3.0207858085632324\n",
      "2.6279444694519043\n",
      "3.4931178092956543\n",
      "2.7960221767425537\n",
      "3.4102330207824707\n",
      "2.826756238937378\n",
      "3.365262269973755\n",
      "2.979294538497925\n",
      "2.8200106620788574\n",
      "2.9651026725769043\n",
      "3.7477822303771973\n",
      "2.552873373031616\n",
      "3.2210209369659424\n",
      "3.2364182472229004\n",
      "3.342690944671631\n",
      "2.644984006881714\n",
      "2.998076915740967\n",
      "3.4820151329040527\n",
      "3.3555567264556885\n",
      "2.74943208694458\n",
      "3.3094351291656494\n",
      "2.842254161834717\n",
      "2.861935615539551\n",
      "2.9412930011749268\n",
      "3.4884016513824463\n",
      "2.8317177295684814\n",
      "2.8629660606384277\n",
      "2.9840023517608643\n",
      "3.1330764293670654\n",
      "2.968627691268921\n",
      "3.1085519790649414\n",
      "3.0592215061187744\n",
      "3.240539073944092\n",
      "2.687546730041504\n",
      "2.5009498596191406\n",
      "3.166421890258789\n",
      "2.9628689289093018\n",
      "2.6782610416412354\n",
      "2.948054552078247\n",
      "2.9787092208862305\n",
      "3.1752429008483887\n",
      "3.0576605796813965\n",
      "2.6938869953155518\n",
      "2.6311371326446533\n",
      "2.8051483631134033\n",
      "2.9168474674224854\n",
      "3.3130991458892822\n",
      "3.02528715133667\n",
      "3.061556339263916\n",
      "3.6481924057006836\n",
      "2.922591209411621\n",
      "3.2368288040161133\n",
      "3.013218641281128\n",
      "3.2057182788848877\n",
      "3.5754053592681885\n",
      "2.7503879070281982\n",
      "2.8483083248138428\n",
      "3.333155393600464\n",
      "2.9165918827056885\n",
      "2.3594412803649902\n",
      "3.0240440368652344\n",
      "3.0502920150756836\n",
      "3.307065010070801\n",
      "2.3825201988220215\n",
      "2.5054266452789307\n",
      "3.3442306518554688\n",
      "2.713481903076172\n",
      "3.2367684841156006\n",
      "2.849459171295166\n",
      "3.3409504890441895\n",
      "2.767878770828247\n",
      "2.854177236557007\n",
      "3.386272668838501\n",
      "2.624171018600464\n",
      "3.068507194519043\n",
      "2.7872416973114014\n",
      "2.6588990688323975\n",
      "3.1801769733428955\n",
      "2.351755380630493\n",
      "3.310513734817505\n",
      "2.6761159896850586\n",
      "2.557880163192749\n",
      "3.152433156967163\n",
      "2.831183671951294\n",
      "2.836331605911255\n",
      "2.8602218627929688\n",
      "3.2116687297821045\n",
      "3.449267864227295\n",
      "2.9676287174224854\n",
      "2.6720378398895264\n",
      "2.9426722526550293\n",
      "2.805375099182129\n",
      "3.7151777744293213\n",
      "2.616328239440918\n",
      "3.2268319129943848\n",
      "3.148081064224243\n",
      "3.217270851135254\n",
      "2.702582836151123\n",
      "2.681894063949585\n",
      "2.6430306434631348\n",
      "3.097564935684204\n",
      "3.1799213886260986\n",
      "2.8824057579040527\n",
      "2.907665967941284\n",
      "2.53995943069458\n",
      "2.625767946243286\n",
      "2.7534849643707275\n",
      "2.808194637298584\n",
      "2.7297589778900146\n",
      "3.295988082885742\n",
      "2.961873769760132\n",
      "2.630882740020752\n",
      "3.12571120262146\n",
      "2.9421634674072266\n",
      "3.2027909755706787\n",
      "2.8337292671203613\n",
      "3.003511905670166\n",
      "2.874044179916382\n",
      "2.9799323081970215\n",
      "2.4424214363098145\n",
      "2.5100436210632324\n",
      "3.0689175128936768\n",
      "2.7782859802246094\n",
      "3.3265151977539062\n",
      "2.8451132774353027\n",
      "2.5226593017578125\n",
      "2.842515230178833\n",
      "2.7998905181884766\n",
      "2.6446733474731445\n",
      "2.8223512172698975\n",
      "2.701371669769287\n",
      "2.8870084285736084\n",
      "2.926562547683716\n",
      "3.2226614952087402\n",
      "2.8707640171051025\n",
      "2.7443315982818604\n",
      "2.7340619564056396\n",
      "3.179858922958374\n",
      "2.8249285221099854\n",
      "2.5337765216827393\n",
      "3.350423812866211\n",
      "2.961397409439087\n",
      "3.0335004329681396\n",
      "2.8436474800109863\n",
      "3.1123979091644287\n",
      "3.0606091022491455\n",
      "2.562680244445801\n",
      "3.3029696941375732\n",
      "3.459829330444336\n",
      "2.806105375289917\n",
      "2.7215492725372314\n",
      "3.2449254989624023\n",
      "3.0582218170166016\n",
      "2.81997013092041\n",
      "2.5717735290527344\n",
      "2.8292322158813477\n",
      "2.5757062435150146\n",
      "2.7190616130828857\n",
      "2.430614709854126\n",
      "3.04443621635437\n",
      "3.00894832611084\n",
      "3.3561534881591797\n",
      "3.1412386894226074\n",
      "3.1894450187683105\n",
      "2.7373321056365967\n",
      "3.2015140056610107\n",
      "2.707824945449829\n",
      "2.631389856338501\n",
      "2.4091269969940186\n",
      "3.144444704055786\n",
      "2.9948408603668213\n",
      "2.9702324867248535\n",
      "2.5699048042297363\n",
      "2.9978930950164795\n",
      "2.8224549293518066\n",
      "2.866711378097534\n",
      "3.031341791152954\n",
      "3.1409621238708496\n",
      "2.7800469398498535\n",
      "2.558450222015381\n",
      "2.633641481399536\n",
      "3.1656205654144287\n",
      "2.811245918273926\n",
      "3.079601287841797\n",
      "3.515089988708496\n",
      "2.5682716369628906\n",
      "2.558863401412964\n",
      "2.44100284576416\n",
      "3.048449993133545\n",
      "3.225836753845215\n",
      "2.761611223220825\n",
      "2.931657314300537\n",
      "3.262205123901367\n",
      "2.8641557693481445\n",
      "3.021484851837158\n",
      "3.1849617958068848\n",
      "2.94217586517334\n",
      "2.7735657691955566\n",
      "3.0357182025909424\n",
      "2.9950506687164307\n",
      "2.865879535675049\n",
      "3.042833089828491\n",
      "2.7285208702087402\n",
      "2.7884862422943115\n",
      "3.3939390182495117\n",
      "2.6581380367279053\n",
      "2.5222983360290527\n",
      "3.5759222507476807\n",
      "2.973808765411377\n",
      "2.534562110900879\n",
      "2.921109437942505\n",
      "2.8460848331451416\n",
      "2.8354532718658447\n",
      "2.74637770652771\n",
      "2.844677686691284\n",
      "2.7152750492095947\n",
      "2.8453166484832764\n",
      "2.757368803024292\n",
      "2.5184483528137207\n",
      "2.9801716804504395\n",
      "2.46501088142395\n",
      "2.7782182693481445\n",
      "2.597290515899658\n",
      "3.051252603530884\n",
      "2.805713415145874\n",
      "2.6036345958709717\n",
      "3.041459798812866\n",
      "3.0329971313476562\n",
      "2.8626046180725098\n",
      "2.972790479660034\n",
      "2.5874240398406982\n",
      "2.666043758392334\n",
      "3.06172513961792\n",
      "2.9223287105560303\n",
      "3.0687203407287598\n",
      "2.6479265689849854\n",
      "2.921564817428589\n",
      "2.774264097213745\n",
      "2.612088203430176\n",
      "2.83122181892395\n",
      "3.011549949645996\n",
      "2.7613775730133057\n",
      "3.0536251068115234\n",
      "2.7943103313446045\n",
      "3.3891663551330566\n",
      "2.796489715576172\n",
      "2.980031967163086\n",
      "2.800082206726074\n",
      "3.0154919624328613\n",
      "2.679007053375244\n",
      "2.784475803375244\n",
      "3.099515914916992\n",
      "2.6900217533111572\n",
      "2.8771657943725586\n",
      "2.360786199569702\n",
      "2.8789186477661133\n",
      "2.932847023010254\n",
      "3.0037074089050293\n",
      "2.420236349105835\n",
      "2.9249303340911865\n",
      "3.170499563217163\n",
      "2.8655433654785156\n",
      "2.9851787090301514\n",
      "2.7227983474731445\n",
      "2.7989840507507324\n",
      "2.5273075103759766\n",
      "3.16733980178833\n",
      "2.739689588546753\n",
      "3.0195701122283936\n",
      "2.6287431716918945\n",
      "2.905336856842041\n",
      "3.051144599914551\n",
      "3.430271863937378\n",
      "2.485049247741699\n",
      "3.035722255706787\n",
      "3.2053985595703125\n",
      "2.830962896347046\n",
      "2.4737205505371094\n",
      "2.8334994316101074\n",
      "2.5440454483032227\n",
      "2.494108200073242\n",
      "2.4847617149353027\n",
      "2.802446126937866\n",
      "2.774019956588745\n",
      "2.730827808380127\n",
      "2.4399654865264893\n",
      "2.855138063430786\n",
      "3.609062671661377\n",
      "2.3733925819396973\n",
      "2.500886917114258\n",
      "2.5024755001068115\n",
      "2.4713010787963867\n",
      "2.62056827545166\n",
      "3.1166751384735107\n",
      "3.1765973567962646\n",
      "2.692970037460327\n",
      "2.8690319061279297\n",
      "2.6945183277130127\n",
      "2.682378053665161\n",
      "3.103775978088379\n",
      "2.570286273956299\n",
      "2.847637176513672\n",
      "2.751101016998291\n",
      "2.6871631145477295\n",
      "3.078200101852417\n",
      "2.4194555282592773\n",
      "2.697016954421997\n",
      "2.8708386421203613\n",
      "2.951162338256836\n",
      "2.736713409423828\n",
      "2.5670409202575684\n",
      "2.991981267929077\n",
      "3.818190336227417\n",
      "2.525804281234741\n",
      "2.8589861392974854\n",
      "2.804271936416626\n",
      "3.011861562728882\n",
      "2.8916165828704834\n",
      "3.1065118312835693\n",
      "2.8971309661865234\n",
      "2.7949447631835938\n",
      "2.8225457668304443\n",
      "2.204564094543457\n",
      "2.735219955444336\n",
      "2.933244466781616\n",
      "2.8436026573181152\n",
      "2.6534066200256348\n",
      "2.9081997871398926\n",
      "2.898838520050049\n",
      "2.8823959827423096\n",
      "2.6081058979034424\n",
      "2.8826611042022705\n",
      "2.7824110984802246\n",
      "2.9724066257476807\n",
      "2.954071283340454\n",
      "3.054442882537842\n",
      "2.8242852687835693\n",
      "3.391223430633545\n",
      "2.503453016281128\n",
      "2.635608196258545\n",
      "2.9476494789123535\n",
      "2.605259418487549\n",
      "2.8224596977233887\n",
      "2.7394752502441406\n",
      "2.8015427589416504\n",
      "3.2197978496551514\n",
      "2.470625400543213\n",
      "2.9450936317443848\n",
      "2.8339040279388428\n",
      "2.5798823833465576\n",
      "2.9878718852996826\n",
      "3.1659188270568848\n",
      "2.658687114715576\n",
      "2.627336263656616\n",
      "2.5938405990600586\n",
      "2.7618541717529297\n",
      "2.7062933444976807\n",
      "2.8311007022857666\n",
      "2.4227750301361084\n",
      "2.7290573120117188\n",
      "3.1041431427001953\n",
      "2.382751941680908\n",
      "2.4523487091064453\n",
      "3.340988874435425\n",
      "2.4157817363739014\n",
      "2.820158004760742\n",
      "2.2129173278808594\n",
      "2.9725189208984375\n",
      "2.6255030632019043\n",
      "2.6911540031433105\n",
      "2.7210488319396973\n",
      "2.5393147468566895\n",
      "2.6249775886535645\n",
      "3.188966751098633\n",
      "3.0334792137145996\n",
      "2.4276185035705566\n",
      "2.483724355697632\n",
      "2.7660207748413086\n",
      "2.7698044776916504\n",
      "2.679375171661377\n",
      "3.0679280757904053\n",
      "2.858626127243042\n",
      "2.741065740585327\n",
      "2.6420485973358154\n",
      "3.183966636657715\n",
      "2.435352087020874\n",
      "2.503079652786255\n",
      "2.886748790740967\n",
      "2.933117628097534\n",
      "2.5976264476776123\n",
      "2.954038381576538\n",
      "2.732372283935547\n",
      "3.0558817386627197\n",
      "2.8825364112854004\n",
      "2.4890544414520264\n",
      "2.868185043334961\n",
      "2.440521001815796\n",
      "2.496784210205078\n",
      "2.911106824874878\n",
      "2.7043521404266357\n",
      "2.7431883811950684\n",
      "2.622063636779785\n",
      "2.9205214977264404\n",
      "2.6711385250091553\n",
      "3.301910161972046\n",
      "2.729531764984131\n",
      "2.439570188522339\n",
      "2.701537847518921\n",
      "3.176177978515625\n",
      "2.6169867515563965\n",
      "2.8271265029907227\n",
      "2.2721567153930664\n",
      "2.4067013263702393\n",
      "2.7400519847869873\n",
      "2.746701717376709\n",
      "3.1576626300811768\n",
      "2.3712780475616455\n",
      "2.8988454341888428\n",
      "2.7059953212738037\n",
      "2.2919533252716064\n",
      "2.4599828720092773\n",
      "3.105518341064453\n",
      "2.5947532653808594\n",
      "2.7750344276428223\n",
      "3.17069149017334\n",
      "2.531280517578125\n",
      "2.685683250427246\n",
      "2.760868787765503\n",
      "2.9725818634033203\n",
      "2.805183172225952\n",
      "3.1804468631744385\n",
      "2.7937979698181152\n",
      "2.644488573074341\n",
      "2.373868465423584\n",
      "2.8808531761169434\n",
      "2.7454967498779297\n",
      "2.763843059539795\n",
      "2.833134889602661\n",
      "2.885056495666504\n",
      "2.648646116256714\n",
      "2.7632110118865967\n",
      "3.203336715698242\n",
      "2.7621681690216064\n",
      "2.7495193481445312\n",
      "3.0325794219970703\n",
      "2.8674938678741455\n",
      "2.5446763038635254\n",
      "3.0545411109924316\n",
      "2.8671116828918457\n",
      "2.52078914642334\n",
      "3.1297130584716797\n",
      "2.7671289443969727\n",
      "2.6979942321777344\n",
      "2.809007167816162\n",
      "2.687596082687378\n",
      "2.3038594722747803\n",
      "2.4563753604888916\n",
      "2.732435703277588\n",
      "2.474170446395874\n",
      "3.10092830657959\n",
      "2.6512560844421387\n",
      "2.4274709224700928\n",
      "2.8401706218719482\n",
      "2.8179233074188232\n",
      "3.0861947536468506\n",
      "2.6472971439361572\n",
      "3.036588191986084\n",
      "2.4534003734588623\n",
      "2.4579904079437256\n",
      "3.057009220123291\n",
      "2.949688673019409\n",
      "2.685774087905884\n",
      "2.8871910572052\n",
      "2.708634614944458\n",
      "2.6391496658325195\n",
      "2.986304998397827\n",
      "2.967794418334961\n",
      "2.5300471782684326\n",
      "2.6650171279907227\n",
      "2.8505659103393555\n",
      "2.3696889877319336\n",
      "2.6745426654815674\n",
      "2.8102188110351562\n",
      "2.714022159576416\n",
      "2.7316863536834717\n",
      "2.760930061340332\n",
      "2.559831380844116\n",
      "2.9663357734680176\n",
      "3.0351929664611816\n",
      "3.1531872749328613\n",
      "2.6486921310424805\n",
      "2.830706834793091\n",
      "2.2719664573669434\n",
      "2.6768295764923096\n",
      "2.541511058807373\n",
      "2.804344415664673\n",
      "2.67769455909729\n",
      "2.9361443519592285\n",
      "2.980288028717041\n",
      "2.9040687084198\n",
      "2.840777635574341\n",
      "2.4406237602233887\n",
      "2.5067529678344727\n",
      "3.0493030548095703\n",
      "2.8565237522125244\n",
      "2.610063076019287\n",
      "2.642800807952881\n",
      "2.62031888961792\n",
      "2.7829647064208984\n",
      "2.830352544784546\n",
      "3.011479377746582\n",
      "2.7096362113952637\n",
      "2.9746193885803223\n",
      "2.8670654296875\n",
      "2.701272964477539\n",
      "2.5656187534332275\n",
      "2.630406141281128\n",
      "2.663969039916992\n",
      "2.728590488433838\n",
      "2.389369249343872\n",
      "2.7060155868530273\n",
      "2.3921871185302734\n",
      "2.670877695083618\n",
      "2.937809944152832\n",
      "2.520921468734741\n",
      "2.3796823024749756\n",
      "2.8847923278808594\n",
      "3.1358115673065186\n",
      "2.79975962638855\n",
      "2.597411632537842\n",
      "2.8022971153259277\n",
      "2.3987979888916016\n",
      "2.735246419906616\n",
      "2.73349666595459\n",
      "2.6914823055267334\n",
      "2.3623123168945312\n",
      "2.7220168113708496\n",
      "2.5144104957580566\n",
      "2.826059341430664\n",
      "2.5177195072174072\n",
      "2.6055517196655273\n",
      "2.6121466159820557\n",
      "2.688290596008301\n",
      "2.7077558040618896\n",
      "2.9616706371307373\n",
      "2.8313469886779785\n",
      "2.886319637298584\n",
      "2.5277445316314697\n",
      "3.1745452880859375\n",
      "3.05413556098938\n",
      "2.8330554962158203\n",
      "2.647209405899048\n",
      "2.9463319778442383\n",
      "2.7983412742614746\n",
      "2.447786331176758\n",
      "2.6949870586395264\n",
      "2.898465633392334\n",
      "2.8091187477111816\n",
      "2.588454484939575\n",
      "2.786334991455078\n",
      "3.16560959815979\n",
      "2.9844071865081787\n",
      "2.4705045223236084\n",
      "2.623805284500122\n",
      "2.8318445682525635\n",
      "2.3477494716644287\n",
      "3.1303746700286865\n",
      "2.4148452281951904\n",
      "3.0209035873413086\n",
      "2.7400686740875244\n",
      "2.6176435947418213\n",
      "2.6108040809631348\n",
      "2.9136064052581787\n",
      "2.9814155101776123\n",
      "3.3876240253448486\n",
      "2.590679407119751\n",
      "2.980015516281128\n",
      "2.6907904148101807\n",
      "2.33223295211792\n",
      "2.689314126968384\n",
      "2.5986435413360596\n",
      "2.4752018451690674\n",
      "2.629546642303467\n",
      "2.939889907836914\n",
      "2.3468053340911865\n",
      "2.674213409423828\n",
      "2.9655137062072754\n",
      "2.6737051010131836\n",
      "3.042262315750122\n",
      "2.215653419494629\n",
      "2.662884473800659\n",
      "2.6214447021484375\n",
      "2.8640594482421875\n",
      "3.0317769050598145\n",
      "2.6395998001098633\n",
      "2.6878511905670166\n",
      "2.5449869632720947\n",
      "2.386603593826294\n",
      "3.082359790802002\n",
      "3.41422176361084\n",
      "3.1640913486480713\n",
      "2.7247283458709717\n",
      "2.644036293029785\n",
      "2.598743438720703\n",
      "3.4517781734466553\n",
      "2.930145502090454\n",
      "2.289011001586914\n",
      "2.4473447799682617\n",
      "2.5871005058288574\n",
      "2.644763469696045\n",
      "2.561345338821411\n",
      "2.4591028690338135\n",
      "3.0432546138763428\n",
      "2.678133487701416\n",
      "2.6120309829711914\n",
      "2.39269757270813\n",
      "2.939619541168213\n",
      "2.508361339569092\n",
      "2.718851089477539\n",
      "2.448444366455078\n",
      "2.5997560024261475\n",
      "2.8878393173217773\n",
      "2.4926486015319824\n",
      "2.7060930728912354\n",
      "2.9425055980682373\n",
      "3.166456937789917\n",
      "2.8637337684631348\n",
      "2.736894369125366\n",
      "2.936777114868164\n",
      "2.6318650245666504\n",
      "2.70926833152771\n",
      "2.610994815826416\n",
      "2.6018779277801514\n",
      "2.7519209384918213\n",
      "2.597886085510254\n",
      "2.4350411891937256\n",
      "2.6929941177368164\n",
      "2.754978895187378\n",
      "2.866546154022217\n",
      "2.5945444107055664\n",
      "2.625438690185547\n",
      "2.663425922393799\n",
      "2.839956760406494\n",
      "3.191974401473999\n",
      "2.347367763519287\n",
      "2.73905611038208\n",
      "2.6668131351470947\n",
      "2.3867239952087402\n",
      "2.5779242515563965\n",
      "2.845374822616577\n",
      "3.200650691986084\n",
      "2.4598541259765625\n",
      "2.464024305343628\n",
      "2.9348151683807373\n",
      "2.6873977184295654\n",
      "2.4722726345062256\n",
      "2.6207170486450195\n",
      "2.9052393436431885\n",
      "2.4260149002075195\n",
      "2.7254199981689453\n",
      "2.6521899700164795\n",
      "2.7412843704223633\n",
      "3.1733644008636475\n",
      "2.377549171447754\n",
      "2.5346906185150146\n",
      "2.631833553314209\n",
      "2.8401591777801514\n",
      "3.3156545162200928\n",
      "2.7792532444000244\n",
      "2.6097497940063477\n",
      "2.757181406021118\n",
      "2.7671146392822266\n",
      "2.4952375888824463\n",
      "3.0375051498413086\n",
      "3.186582565307617\n",
      "2.7466490268707275\n",
      "2.6006486415863037\n",
      "2.7173357009887695\n",
      "3.1718358993530273\n",
      "2.7266876697540283\n",
      "2.6975300312042236\n",
      "2.5341076850891113\n",
      "2.4861233234405518\n",
      "2.2869393825531006\n",
      "3.1850244998931885\n",
      "2.736220598220825\n",
      "3.2696526050567627\n",
      "2.6457574367523193\n",
      "2.677640676498413\n",
      "3.1197171211242676\n",
      "2.8618006706237793\n",
      "2.8115923404693604\n",
      "2.847923994064331\n",
      "2.5301966667175293\n",
      "2.2049760818481445\n",
      "3.0206212997436523\n",
      "3.062994956970215\n",
      "2.8308768272399902\n",
      "2.803582191467285\n",
      "2.6364622116088867\n",
      "2.994302272796631\n",
      "2.620786666870117\n",
      "2.549065351486206\n",
      "2.594674825668335\n",
      "2.66076922416687\n",
      "2.7685163021087646\n",
      "2.5148651599884033\n",
      "2.54453444480896\n",
      "3.171445369720459\n",
      "2.2409980297088623\n",
      "2.71943736076355\n",
      "3.030388832092285\n",
      "2.955077648162842\n",
      "3.093754768371582\n",
      "3.0843279361724854\n",
      "2.6039443016052246\n",
      "2.813091278076172\n",
      "2.754765510559082\n",
      "2.495248794555664\n",
      "2.1918580532073975\n",
      "2.3878862857818604\n",
      "2.546168327331543\n",
      "2.8928332328796387\n",
      "2.1971473693847656\n",
      "2.763658285140991\n",
      "2.5414822101593018\n",
      "2.567535400390625\n",
      "2.495257616043091\n",
      "2.7273776531219482\n",
      "2.795236110687256\n",
      "2.659137487411499\n",
      "2.3455886840820312\n",
      "2.6627306938171387\n",
      "2.481937885284424\n",
      "3.2950425148010254\n",
      "2.355417251586914\n",
      "2.7455642223358154\n",
      "2.339940071105957\n",
      "2.779391050338745\n",
      "2.3485031127929688\n",
      "2.6752097606658936\n",
      "2.575247049331665\n",
      "2.816896438598633\n",
      "2.4620399475097656\n",
      "2.5135183334350586\n",
      "2.479796886444092\n",
      "2.3094563484191895\n",
      "2.7633345127105713\n",
      "2.926945209503174\n",
      "2.4123032093048096\n",
      "2.856851577758789\n",
      "2.803986072540283\n",
      "2.611464262008667\n",
      "2.5284619331359863\n",
      "2.6154375076293945\n",
      "2.980264186859131\n",
      "2.543658971786499\n",
      "2.5221927165985107\n",
      "2.691470146179199\n",
      "2.896836042404175\n",
      "2.4205210208892822\n",
      "2.5143144130706787\n",
      "2.8818986415863037\n",
      "2.6061153411865234\n",
      "3.212315082550049\n",
      "2.594169855117798\n",
      "2.8842272758483887\n",
      "2.7616639137268066\n",
      "2.5007147789001465\n",
      "2.786850690841675\n",
      "2.886579990386963\n",
      "2.7907941341400146\n",
      "3.058602809906006\n",
      "2.6000008583068848\n",
      "3.008721113204956\n",
      "3.001243829727173\n",
      "2.987182378768921\n",
      "2.9202585220336914\n",
      "2.560633897781372\n",
      "2.813882350921631\n",
      "2.7579009532928467\n",
      "2.652836561203003\n",
      "2.9169819355010986\n",
      "2.9917798042297363\n",
      "2.7333498001098633\n",
      "2.9717962741851807\n",
      "2.211657762527466\n",
      "2.6759305000305176\n",
      "2.7032272815704346\n",
      "2.584118366241455\n",
      "2.5316669940948486\n",
      "2.750082492828369\n",
      "2.8342437744140625\n",
      "2.615480422973633\n",
      "2.5469260215759277\n",
      "3.082125425338745\n",
      "2.6664600372314453\n",
      "2.5737335681915283\n",
      "3.1144490242004395\n",
      "2.383819818496704\n",
      "2.367269515991211\n",
      "2.8412554264068604\n",
      "2.531614065170288\n",
      "2.8374855518341064\n",
      "2.3382203578948975\n",
      "2.4825592041015625\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but since we're sampling the gradient is not as reliable; note that the function moves down overall but individual steps can have higher loss than before. Good enough to be useful.\n",
    "\n",
    "This is standard practice: better to evaluate an approximation of the gradient with many steps, instead of a few steps with the exact gradient.\n",
    "\n",
    "To double check, look at the exact loss function, not just on the mini batch of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printExactLoss():\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7534122467041016\n"
     ]
    }
   ],
   "source": [
    "printExactLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a learning rate\n",
    "\n",
    "Additional optimization: what is the right learning speed hyperparameter? -0.1 was arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.689495086669922\n",
      "21.639951705932617\n",
      "20.025785446166992\n",
      "18.13319969177246\n",
      "16.47211456298828\n",
      "19.666629791259766\n",
      "17.735702514648438\n",
      "18.66973114013672\n",
      "18.780397415161133\n",
      "19.551769256591797\n",
      "18.92703628540039\n",
      "20.391281127929688\n",
      "21.357391357421875\n",
      "22.67078399658203\n",
      "20.105663299560547\n",
      "18.19432830810547\n",
      "23.07483673095703\n",
      "18.152408599853516\n",
      "19.764619827270508\n",
      "19.147438049316406\n",
      "20.010087966918945\n",
      "17.14966583251953\n",
      "19.315690994262695\n",
      "22.354372024536133\n",
      "18.4157772064209\n",
      "21.69523048400879\n",
      "18.506877899169922\n",
      "19.736034393310547\n",
      "18.12925148010254\n",
      "17.299036026000977\n",
      "18.12759780883789\n",
      "18.38648796081543\n",
      "18.137983322143555\n",
      "19.12024688720703\n",
      "19.335350036621094\n",
      "21.507802963256836\n",
      "18.716259002685547\n",
      "21.506765365600586\n",
      "23.75618553161621\n",
      "19.45638084411621\n",
      "17.411945343017578\n",
      "20.49051284790039\n",
      "18.941701889038086\n",
      "17.577369689941406\n",
      "19.177032470703125\n",
      "19.697166442871094\n",
      "17.7371768951416\n",
      "19.567644119262695\n",
      "18.331640243530273\n",
      "19.90231704711914\n",
      "19.66337776184082\n",
      "19.804950714111328\n",
      "18.488784790039062\n",
      "17.403549194335938\n",
      "21.218307495117188\n",
      "21.496074676513672\n",
      "18.998563766479492\n",
      "17.488479614257812\n",
      "18.384735107421875\n",
      "19.049753189086914\n",
      "21.298677444458008\n",
      "21.55328941345215\n",
      "18.081655502319336\n",
      "19.534650802612305\n",
      "16.92205810546875\n",
      "18.24738883972168\n",
      "18.177526473999023\n",
      "19.30656623840332\n",
      "17.26398468017578\n",
      "21.24924087524414\n",
      "21.162776947021484\n",
      "20.404827117919922\n",
      "21.865802764892578\n",
      "18.817697525024414\n",
      "20.700050354003906\n",
      "19.215919494628906\n",
      "21.140880584716797\n",
      "18.81499671936035\n",
      "21.455568313598633\n",
      "18.484758377075195\n",
      "20.28045654296875\n",
      "18.71720314025879\n",
      "19.204198837280273\n",
      "22.62091827392578\n",
      "18.411760330200195\n",
      "17.237716674804688\n",
      "21.02712631225586\n",
      "18.3450870513916\n",
      "20.054439544677734\n",
      "21.16216468811035\n",
      "20.461254119873047\n",
      "17.828575134277344\n",
      "19.2579345703125\n",
      "20.35072135925293\n",
      "18.84978675842285\n",
      "20.334558486938477\n",
      "19.4913330078125\n",
      "18.983854293823242\n",
      "21.360565185546875\n",
      "22.555377960205078\n"
     ]
    }
   ],
   "source": [
    "# Reset parameters\n",
    "g, C, W1, b1, W2, b2, parameters = make_parameters()\n",
    "learningrate = .0001 # Too low\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -learningrate * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate barely decreasing at all; this is clearly not sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.258596420288086\n",
      "20.328990936279297\n",
      "19.864408493041992\n",
      "19.601987838745117\n",
      "17.57638168334961\n",
      "16.71140480041504\n",
      "18.59832000732422\n",
      "18.077180862426758\n",
      "19.59163475036621\n",
      "22.58440589904785\n",
      "17.370468139648438\n",
      "19.761919021606445\n",
      "18.986431121826172\n",
      "19.15898323059082\n",
      "20.18491554260254\n",
      "18.5126953125\n",
      "19.532976150512695\n",
      "18.921619415283203\n",
      "18.146549224853516\n",
      "17.363239288330078\n",
      "17.963258743286133\n",
      "19.898181915283203\n",
      "18.980623245239258\n",
      "14.753584861755371\n",
      "20.10309600830078\n",
      "19.957252502441406\n",
      "16.725582122802734\n",
      "16.98567771911621\n",
      "20.99211311340332\n",
      "16.571216583251953\n",
      "16.01493263244629\n",
      "18.944032669067383\n",
      "17.959253311157227\n",
      "19.065093994140625\n",
      "16.307710647583008\n",
      "21.09596061706543\n",
      "17.986534118652344\n",
      "20.893285751342773\n",
      "19.016658782958984\n",
      "16.440876007080078\n",
      "16.197364807128906\n",
      "17.000925064086914\n",
      "19.544063568115234\n",
      "15.856797218322754\n",
      "16.570117950439453\n",
      "18.905473709106445\n",
      "19.37773895263672\n",
      "18.498981475830078\n",
      "17.721193313598633\n",
      "19.121732711791992\n",
      "19.828052520751953\n",
      "16.16739273071289\n",
      "18.79453468322754\n",
      "19.42710304260254\n",
      "19.74783706665039\n",
      "21.208370208740234\n",
      "20.716299057006836\n",
      "19.44261360168457\n",
      "17.82410430908203\n",
      "19.46687126159668\n",
      "18.987131118774414\n",
      "18.963699340820312\n",
      "17.78025245666504\n",
      "20.58118438720703\n",
      "19.522546768188477\n",
      "17.423908233642578\n",
      "17.61915397644043\n",
      "17.184011459350586\n",
      "16.56383514404297\n",
      "21.492809295654297\n",
      "18.5842342376709\n",
      "15.681278228759766\n",
      "19.006427764892578\n",
      "17.28268814086914\n",
      "19.719676971435547\n",
      "16.37074089050293\n",
      "15.833979606628418\n",
      "18.414094924926758\n",
      "17.66632652282715\n",
      "17.00370979309082\n",
      "17.074195861816406\n",
      "16.612415313720703\n",
      "18.796125411987305\n",
      "19.488340377807617\n",
      "18.508350372314453\n",
      "17.432758331298828\n",
      "17.752296447753906\n",
      "18.58906364440918\n",
      "17.797698974609375\n",
      "16.336515426635742\n",
      "17.000337600708008\n",
      "18.033723831176758\n",
      "17.182575225830078\n",
      "15.433876037597656\n",
      "17.185779571533203\n",
      "17.899564743041992\n",
      "18.409807205200195\n",
      "18.45722770690918\n",
      "18.961305618286133\n",
      "15.965049743652344\n"
     ]
    }
   ],
   "source": [
    "# Reset parameters\n",
    "g, C, W1, b1, W2, b2, parameters = make_parameters()\n",
    "learningrate = .001 # Pretty low\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -learningrate * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly decreasing over time; this would be a suitable range.\n",
    "\n",
    "If the loss function is too big, the function will \"explode\" - no consistent behavior, overshooting each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.19137191772461\n",
      "38.56006622314453\n",
      "79.71997833251953\n",
      "73.02641296386719\n",
      "65.33867645263672\n",
      "62.07798385620117\n",
      "76.64058685302734\n",
      "47.060020446777344\n",
      "58.74861526489258\n",
      "69.1828384399414\n",
      "97.53173065185547\n",
      "57.3383674621582\n",
      "51.46820068359375\n",
      "75.11175537109375\n",
      "93.74197387695312\n",
      "71.24820709228516\n",
      "100.69364166259766\n",
      "88.56722259521484\n",
      "81.03475952148438\n",
      "72.85397338867188\n",
      "129.0100555419922\n",
      "120.06587219238281\n",
      "122.50243377685547\n",
      "81.39966583251953\n",
      "74.82206726074219\n",
      "79.32843780517578\n",
      "94.40128326416016\n",
      "94.83612060546875\n",
      "88.52925109863281\n",
      "94.87078094482422\n",
      "68.30113983154297\n",
      "89.38113403320312\n",
      "65.24756622314453\n",
      "80.03022003173828\n",
      "84.6998519897461\n",
      "64.5587158203125\n",
      "89.71086120605469\n",
      "77.8179931640625\n",
      "73.19364166259766\n",
      "81.76777648925781\n",
      "70.92098236083984\n",
      "69.97529602050781\n",
      "55.27585983276367\n",
      "65.10738372802734\n",
      "77.96126556396484\n",
      "93.21357727050781\n",
      "74.26749420166016\n",
      "67.88654327392578\n",
      "81.990966796875\n",
      "81.76969909667969\n",
      "53.68246841430664\n",
      "84.71563720703125\n",
      "60.383628845214844\n",
      "44.364593505859375\n",
      "84.88764953613281\n",
      "95.02046203613281\n",
      "96.3844223022461\n",
      "76.52787780761719\n",
      "69.59642791748047\n",
      "64.68922424316406\n",
      "76.83488464355469\n",
      "71.2334976196289\n",
      "77.86634826660156\n",
      "83.77307891845703\n",
      "84.39573669433594\n",
      "64.09251403808594\n",
      "55.01575469970703\n",
      "88.29924774169922\n",
      "76.72972106933594\n",
      "109.45729064941406\n",
      "82.33216094970703\n",
      "92.3593521118164\n",
      "76.38348388671875\n",
      "62.64449691772461\n",
      "86.34757232666016\n",
      "88.9294204711914\n",
      "71.03822326660156\n",
      "66.67424774169922\n",
      "70.83280181884766\n",
      "119.00126647949219\n",
      "71.5926284790039\n",
      "87.47168731689453\n",
      "69.4266357421875\n",
      "52.04607391357422\n",
      "69.55857849121094\n",
      "64.27786254882812\n",
      "68.38766479492188\n",
      "61.86063003540039\n",
      "64.83784484863281\n",
      "60.54724884033203\n",
      "48.27714157104492\n",
      "64.33242797851562\n",
      "82.62911987304688\n",
      "51.4284553527832\n",
      "51.471805572509766\n",
      "65.15907287597656\n",
      "61.46902084350586\n",
      "76.41490936279297\n",
      "102.21680450439453\n",
      "64.79718017578125\n"
     ]
    }
   ],
   "source": [
    "# Reset parameters\n",
    "g, C, W1, b1, W2, b2, parameters = make_parameters()\n",
    "learningrate = 10 # Way too high\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -learningrate * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right learning rate is probably somewhere between -0.001 and 1 based on the above. Let's try a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013,\n",
       "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0014,\n",
       "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016,\n",
       "        0.0016, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017,\n",
       "        0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019,\n",
       "        0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0020, 0.0020,\n",
       "        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021, 0.0021, 0.0021, 0.0021,\n",
       "        0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
       "        0.0022, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024,\n",
       "        0.0024, 0.0024, 0.0024, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
       "        0.0025, 0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027,\n",
       "        0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028, 0.0029,\n",
       "        0.0029, 0.0029, 0.0029, 0.0029, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
       "        0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032,\n",
       "        0.0033, 0.0033, 0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
       "        0.0035, 0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
       "        0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039,\n",
       "        0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042,\n",
       "        0.0042, 0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044, 0.0044,\n",
       "        0.0045, 0.0045, 0.0045, 0.0045, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047,\n",
       "        0.0047, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0050, 0.0050,\n",
       "        0.0050, 0.0051, 0.0051, 0.0051, 0.0052, 0.0052, 0.0053, 0.0053, 0.0053,\n",
       "        0.0054, 0.0054, 0.0054, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0057,\n",
       "        0.0057, 0.0058, 0.0058, 0.0058, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
       "        0.0061, 0.0061, 0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0064, 0.0064,\n",
       "        0.0065, 0.0065, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0068, 0.0068,\n",
       "        0.0069, 0.0069, 0.0070, 0.0070, 0.0071, 0.0071, 0.0072, 0.0072, 0.0073,\n",
       "        0.0073, 0.0074, 0.0074, 0.0075, 0.0075, 0.0076, 0.0076, 0.0077, 0.0077,\n",
       "        0.0078, 0.0079, 0.0079, 0.0080, 0.0080, 0.0081, 0.0081, 0.0082, 0.0082,\n",
       "        0.0083, 0.0084, 0.0084, 0.0085, 0.0085, 0.0086, 0.0086, 0.0087, 0.0088,\n",
       "        0.0088, 0.0089, 0.0090, 0.0090, 0.0091, 0.0091, 0.0092, 0.0093, 0.0093,\n",
       "        0.0094, 0.0095, 0.0095, 0.0096, 0.0097, 0.0097, 0.0098, 0.0099, 0.0099,\n",
       "        0.0100, 0.0101, 0.0101, 0.0102, 0.0103, 0.0104, 0.0104, 0.0105, 0.0106,\n",
       "        0.0106, 0.0107, 0.0108, 0.0109, 0.0109, 0.0110, 0.0111, 0.0112, 0.0112,\n",
       "        0.0113, 0.0114, 0.0115, 0.0116, 0.0116, 0.0117, 0.0118, 0.0119, 0.0120,\n",
       "        0.0121, 0.0121, 0.0122, 0.0123, 0.0124, 0.0125, 0.0126, 0.0127, 0.0127,\n",
       "        0.0128, 0.0129, 0.0130, 0.0131, 0.0132, 0.0133, 0.0134, 0.0135, 0.0136,\n",
       "        0.0137, 0.0137, 0.0138, 0.0139, 0.0140, 0.0141, 0.0142, 0.0143, 0.0144,\n",
       "        0.0145, 0.0146, 0.0147, 0.0148, 0.0149, 0.0150, 0.0151, 0.0152, 0.0154,\n",
       "        0.0155, 0.0156, 0.0157, 0.0158, 0.0159, 0.0160, 0.0161, 0.0162, 0.0163,\n",
       "        0.0165, 0.0166, 0.0167, 0.0168, 0.0169, 0.0170, 0.0171, 0.0173, 0.0174,\n",
       "        0.0175, 0.0176, 0.0178, 0.0179, 0.0180, 0.0181, 0.0182, 0.0184, 0.0185,\n",
       "        0.0186, 0.0188, 0.0189, 0.0190, 0.0192, 0.0193, 0.0194, 0.0196, 0.0197,\n",
       "        0.0198, 0.0200, 0.0201, 0.0202, 0.0204, 0.0205, 0.0207, 0.0208, 0.0210,\n",
       "        0.0211, 0.0212, 0.0214, 0.0215, 0.0217, 0.0218, 0.0220, 0.0221, 0.0223,\n",
       "        0.0225, 0.0226, 0.0228, 0.0229, 0.0231, 0.0232, 0.0234, 0.0236, 0.0237,\n",
       "        0.0239, 0.0241, 0.0242, 0.0244, 0.0246, 0.0247, 0.0249, 0.0251, 0.0253,\n",
       "        0.0254, 0.0256, 0.0258, 0.0260, 0.0261, 0.0263, 0.0265, 0.0267, 0.0269,\n",
       "        0.0271, 0.0273, 0.0274, 0.0276, 0.0278, 0.0280, 0.0282, 0.0284, 0.0286,\n",
       "        0.0288, 0.0290, 0.0292, 0.0294, 0.0296, 0.0298, 0.0300, 0.0302, 0.0304,\n",
       "        0.0307, 0.0309, 0.0311, 0.0313, 0.0315, 0.0317, 0.0320, 0.0322, 0.0324,\n",
       "        0.0326, 0.0328, 0.0331, 0.0333, 0.0335, 0.0338, 0.0340, 0.0342, 0.0345,\n",
       "        0.0347, 0.0350, 0.0352, 0.0354, 0.0357, 0.0359, 0.0362, 0.0364, 0.0367,\n",
       "        0.0369, 0.0372, 0.0375, 0.0377, 0.0380, 0.0382, 0.0385, 0.0388, 0.0390,\n",
       "        0.0393, 0.0396, 0.0399, 0.0401, 0.0404, 0.0407, 0.0410, 0.0413, 0.0416,\n",
       "        0.0418, 0.0421, 0.0424, 0.0427, 0.0430, 0.0433, 0.0436, 0.0439, 0.0442,\n",
       "        0.0445, 0.0448, 0.0451, 0.0455, 0.0458, 0.0461, 0.0464, 0.0467, 0.0471,\n",
       "        0.0474, 0.0477, 0.0480, 0.0484, 0.0487, 0.0491, 0.0494, 0.0497, 0.0501,\n",
       "        0.0504, 0.0508, 0.0511, 0.0515, 0.0518, 0.0522, 0.0526, 0.0529, 0.0533,\n",
       "        0.0537, 0.0540, 0.0544, 0.0548, 0.0552, 0.0556, 0.0559, 0.0563, 0.0567,\n",
       "        0.0571, 0.0575, 0.0579, 0.0583, 0.0587, 0.0591, 0.0595, 0.0599, 0.0604,\n",
       "        0.0608, 0.0612, 0.0616, 0.0621, 0.0625, 0.0629, 0.0634, 0.0638, 0.0642,\n",
       "        0.0647, 0.0651, 0.0656, 0.0660, 0.0665, 0.0670, 0.0674, 0.0679, 0.0684,\n",
       "        0.0688, 0.0693, 0.0698, 0.0703, 0.0708, 0.0713, 0.0718, 0.0723, 0.0728,\n",
       "        0.0733, 0.0738, 0.0743, 0.0748, 0.0753, 0.0758, 0.0764, 0.0769, 0.0774,\n",
       "        0.0780, 0.0785, 0.0790, 0.0796, 0.0802, 0.0807, 0.0813, 0.0818, 0.0824,\n",
       "        0.0830, 0.0835, 0.0841, 0.0847, 0.0853, 0.0859, 0.0865, 0.0871, 0.0877,\n",
       "        0.0883, 0.0889, 0.0895, 0.0901, 0.0908, 0.0914, 0.0920, 0.0927, 0.0933,\n",
       "        0.0940, 0.0946, 0.0953, 0.0959, 0.0966, 0.0973, 0.0979, 0.0986, 0.0993,\n",
       "        0.1000, 0.1007, 0.1014, 0.1021, 0.1028, 0.1035, 0.1042, 0.1050, 0.1057,\n",
       "        0.1064, 0.1072, 0.1079, 0.1087, 0.1094, 0.1102, 0.1109, 0.1117, 0.1125,\n",
       "        0.1133, 0.1140, 0.1148, 0.1156, 0.1164, 0.1172, 0.1181, 0.1189, 0.1197,\n",
       "        0.1205, 0.1214, 0.1222, 0.1231, 0.1239, 0.1248, 0.1256, 0.1265, 0.1274,\n",
       "        0.1283, 0.1292, 0.1301, 0.1310, 0.1319, 0.1328, 0.1337, 0.1346, 0.1356,\n",
       "        0.1365, 0.1374, 0.1384, 0.1394, 0.1403, 0.1413, 0.1423, 0.1433, 0.1443,\n",
       "        0.1453, 0.1463, 0.1473, 0.1483, 0.1493, 0.1504, 0.1514, 0.1525, 0.1535,\n",
       "        0.1546, 0.1557, 0.1567, 0.1578, 0.1589, 0.1600, 0.1611, 0.1623, 0.1634,\n",
       "        0.1645, 0.1657, 0.1668, 0.1680, 0.1691, 0.1703, 0.1715, 0.1727, 0.1739,\n",
       "        0.1751, 0.1763, 0.1775, 0.1788, 0.1800, 0.1812, 0.1825, 0.1838, 0.1850,\n",
       "        0.1863, 0.1876, 0.1889, 0.1902, 0.1916, 0.1929, 0.1942, 0.1956, 0.1969,\n",
       "        0.1983, 0.1997, 0.2010, 0.2024, 0.2038, 0.2053, 0.2067, 0.2081, 0.2096,\n",
       "        0.2110, 0.2125, 0.2140, 0.2154, 0.2169, 0.2184, 0.2200, 0.2215, 0.2230,\n",
       "        0.2246, 0.2261, 0.2277, 0.2293, 0.2309, 0.2325, 0.2341, 0.2357, 0.2373,\n",
       "        0.2390, 0.2406, 0.2423, 0.2440, 0.2457, 0.2474, 0.2491, 0.2508, 0.2526,\n",
       "        0.2543, 0.2561, 0.2579, 0.2597, 0.2615, 0.2633, 0.2651, 0.2669, 0.2688,\n",
       "        0.2707, 0.2725, 0.2744, 0.2763, 0.2783, 0.2802, 0.2821, 0.2841, 0.2861,\n",
       "        0.2880, 0.2900, 0.2921, 0.2941, 0.2961, 0.2982, 0.3002, 0.3023, 0.3044,\n",
       "        0.3065, 0.3087, 0.3108, 0.3130, 0.3151, 0.3173, 0.3195, 0.3217, 0.3240,\n",
       "        0.3262, 0.3285, 0.3308, 0.3331, 0.3354, 0.3377, 0.3400, 0.3424, 0.3448,\n",
       "        0.3472, 0.3496, 0.3520, 0.3544, 0.3569, 0.3594, 0.3619, 0.3644, 0.3669,\n",
       "        0.3695, 0.3720, 0.3746, 0.3772, 0.3798, 0.3825, 0.3851, 0.3878, 0.3905,\n",
       "        0.3932, 0.3959, 0.3987, 0.4014, 0.4042, 0.4070, 0.4098, 0.4127, 0.4155,\n",
       "        0.4184, 0.4213, 0.4243, 0.4272, 0.4302, 0.4331, 0.4362, 0.4392, 0.4422,\n",
       "        0.4453, 0.4484, 0.4515, 0.4546, 0.4578, 0.4610, 0.4642, 0.4674, 0.4706,\n",
       "        0.4739, 0.4772, 0.4805, 0.4838, 0.4872, 0.4906, 0.4940, 0.4974, 0.5008,\n",
       "        0.5043, 0.5078, 0.5113, 0.5149, 0.5185, 0.5221, 0.5257, 0.5293, 0.5330,\n",
       "        0.5367, 0.5404, 0.5442, 0.5479, 0.5517, 0.5556, 0.5594, 0.5633, 0.5672,\n",
       "        0.5712, 0.5751, 0.5791, 0.5831, 0.5872, 0.5913, 0.5954, 0.5995, 0.6036,\n",
       "        0.6078, 0.6120, 0.6163, 0.6206, 0.6249, 0.6292, 0.6336, 0.6380, 0.6424,\n",
       "        0.6469, 0.6513, 0.6559, 0.6604, 0.6650, 0.6696, 0.6743, 0.6789, 0.6837,\n",
       "        0.6884, 0.6932, 0.6980, 0.7028, 0.7077, 0.7126, 0.7176, 0.7225, 0.7275,\n",
       "        0.7326, 0.7377, 0.7428, 0.7480, 0.7531, 0.7584, 0.7636, 0.7689, 0.7743,\n",
       "        0.7796, 0.7850, 0.7905, 0.7960, 0.8015, 0.8071, 0.8127, 0.8183, 0.8240,\n",
       "        0.8297, 0.8355, 0.8412, 0.8471, 0.8530, 0.8589, 0.8648, 0.8708, 0.8769,\n",
       "        0.8830, 0.8891, 0.8953, 0.9015, 0.9077, 0.9140, 0.9204, 0.9268, 0.9332,\n",
       "        0.9397, 0.9462, 0.9528, 0.9594, 0.9660, 0.9727, 0.9795, 0.9863, 0.9931,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre\n",
    "lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 1000 possible learning rates that can be evaluated empirically (basically a grid search type approach, on this single parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.132490158081055\n",
      "19.455129623413086\n",
      "20.588970184326172\n",
      "24.09821128845215\n",
      "21.223533630371094\n",
      "19.29668426513672\n",
      "19.168479919433594\n",
      "20.842010498046875\n",
      "16.70177459716797\n",
      "18.323076248168945\n",
      "20.424617767333984\n",
      "18.597681045532227\n",
      "20.67469596862793\n",
      "17.563135147094727\n",
      "20.723798751831055\n",
      "16.76476287841797\n",
      "15.883875846862793\n",
      "16.99184799194336\n",
      "17.91368865966797\n",
      "19.987173080444336\n",
      "17.34787940979004\n",
      "17.463735580444336\n",
      "19.872007369995117\n",
      "18.67708396911621\n",
      "18.186656951904297\n",
      "21.251771926879883\n",
      "13.531333923339844\n",
      "19.398515701293945\n",
      "17.969327926635742\n",
      "22.386938095092773\n",
      "20.27665138244629\n",
      "13.615514755249023\n",
      "18.392223358154297\n",
      "20.45591926574707\n",
      "21.547542572021484\n",
      "18.939067840576172\n",
      "20.572460174560547\n",
      "21.110401153564453\n",
      "19.020118713378906\n",
      "17.107799530029297\n",
      "16.90305519104004\n",
      "18.861623764038086\n",
      "18.272930145263672\n",
      "19.198801040649414\n",
      "18.612844467163086\n",
      "20.476350784301758\n",
      "18.630727767944336\n",
      "19.54012680053711\n",
      "19.61669158935547\n",
      "18.115493774414062\n",
      "19.542621612548828\n",
      "14.696014404296875\n",
      "19.827133178710938\n",
      "17.5306396484375\n",
      "16.713911056518555\n",
      "14.56466293334961\n",
      "19.05781364440918\n",
      "18.33622169494629\n",
      "16.551837921142578\n",
      "18.622251510620117\n",
      "17.50185203552246\n",
      "16.821834564208984\n",
      "20.502986907958984\n",
      "17.601417541503906\n",
      "20.351167678833008\n",
      "20.04986572265625\n",
      "16.137731552124023\n",
      "17.692659378051758\n",
      "16.837642669677734\n",
      "16.76569938659668\n",
      "19.488786697387695\n",
      "16.856306076049805\n",
      "17.413738250732422\n",
      "17.95929718017578\n",
      "16.210033416748047\n",
      "16.794801712036133\n",
      "16.644344329833984\n",
      "16.563121795654297\n",
      "15.357355117797852\n",
      "13.689282417297363\n",
      "17.482540130615234\n",
      "15.623385429382324\n",
      "18.064903259277344\n",
      "17.58242416381836\n",
      "17.811264038085938\n",
      "17.105121612548828\n",
      "13.00058650970459\n",
      "18.31590461730957\n",
      "18.141273498535156\n",
      "15.88654613494873\n",
      "15.996142387390137\n",
      "15.71163272857666\n",
      "18.350160598754883\n",
      "15.14455795288086\n",
      "14.334141731262207\n",
      "16.236064910888672\n",
      "16.703153610229492\n",
      "16.40894317626953\n",
      "16.430500030517578\n",
      "15.559473037719727\n",
      "15.31513786315918\n",
      "17.69357681274414\n",
      "15.302441596984863\n",
      "17.498821258544922\n",
      "15.233936309814453\n",
      "19.336685180664062\n",
      "18.038978576660156\n",
      "20.314668655395508\n",
      "17.076807022094727\n",
      "18.000110626220703\n",
      "17.945104598999023\n",
      "16.034862518310547\n",
      "13.509908676147461\n",
      "14.58922004699707\n",
      "15.646283149719238\n",
      "19.289371490478516\n",
      "16.140533447265625\n",
      "16.038496017456055\n",
      "17.891420364379883\n",
      "15.944722175598145\n",
      "15.296817779541016\n",
      "15.194212913513184\n",
      "12.468503952026367\n",
      "15.445867538452148\n",
      "16.088125228881836\n",
      "16.124591827392578\n",
      "13.772862434387207\n",
      "15.878196716308594\n",
      "15.200521469116211\n",
      "17.178482055664062\n",
      "15.377654075622559\n",
      "16.54128074645996\n",
      "16.477632522583008\n",
      "16.938446044921875\n",
      "15.918998718261719\n",
      "17.05189323425293\n",
      "15.937183380126953\n",
      "16.954299926757812\n",
      "16.54984474182129\n",
      "17.391489028930664\n",
      "16.402568817138672\n",
      "14.58359146118164\n",
      "14.920186042785645\n",
      "17.409896850585938\n",
      "13.117721557617188\n",
      "14.981297492980957\n",
      "15.0437650680542\n",
      "14.527831077575684\n",
      "15.076554298400879\n",
      "16.144975662231445\n",
      "15.292393684387207\n",
      "16.417640686035156\n",
      "14.274158477783203\n",
      "15.163939476013184\n",
      "13.845110893249512\n",
      "17.427427291870117\n",
      "14.504229545593262\n",
      "15.775262832641602\n",
      "15.272618293762207\n",
      "14.530503273010254\n",
      "15.974637031555176\n",
      "14.568397521972656\n",
      "14.379183769226074\n",
      "15.307602882385254\n",
      "15.844200134277344\n",
      "14.853316307067871\n",
      "12.88680648803711\n",
      "14.06057071685791\n",
      "13.137635231018066\n",
      "15.397912979125977\n",
      "14.779504776000977\n",
      "13.617555618286133\n",
      "14.119189262390137\n",
      "17.59820556640625\n",
      "16.022417068481445\n",
      "15.957818984985352\n",
      "11.380125045776367\n",
      "15.519730567932129\n",
      "15.475730895996094\n",
      "12.787066459655762\n",
      "15.078784942626953\n",
      "14.131255149841309\n",
      "17.464624404907227\n",
      "13.500998497009277\n",
      "14.897455215454102\n",
      "16.82135772705078\n",
      "15.17410945892334\n",
      "13.030088424682617\n",
      "15.34363842010498\n",
      "12.583070755004883\n",
      "12.789913177490234\n",
      "11.34628677368164\n",
      "14.01325511932373\n",
      "11.97503662109375\n",
      "13.627181053161621\n",
      "12.803062438964844\n",
      "13.902852058410645\n",
      "13.237710952758789\n",
      "13.725232124328613\n",
      "13.669929504394531\n",
      "14.011752128601074\n",
      "14.902517318725586\n",
      "14.315690040588379\n",
      "13.410940170288086\n",
      "11.991414070129395\n",
      "14.597786903381348\n",
      "13.001816749572754\n",
      "13.26447582244873\n",
      "12.247842788696289\n",
      "13.329658508300781\n",
      "13.75744342803955\n",
      "12.677885055541992\n",
      "11.355167388916016\n",
      "12.062735557556152\n",
      "13.69709300994873\n",
      "13.964605331420898\n",
      "12.798715591430664\n",
      "12.82076644897461\n",
      "16.247264862060547\n",
      "14.290685653686523\n",
      "13.047125816345215\n",
      "12.082304954528809\n",
      "14.789909362792969\n",
      "12.092637062072754\n",
      "13.055174827575684\n",
      "13.01766300201416\n",
      "11.620546340942383\n",
      "12.397997856140137\n",
      "12.967574119567871\n",
      "10.589057922363281\n",
      "12.316831588745117\n",
      "13.99384593963623\n",
      "11.817371368408203\n",
      "13.139304161071777\n",
      "11.57709789276123\n",
      "12.374560356140137\n",
      "13.530112266540527\n",
      "13.647297859191895\n",
      "13.779568672180176\n",
      "12.348518371582031\n",
      "14.710354804992676\n",
      "13.270950317382812\n",
      "13.709996223449707\n",
      "13.504637718200684\n",
      "13.367903709411621\n",
      "12.65674877166748\n",
      "9.328238487243652\n",
      "11.044881820678711\n",
      "12.970749855041504\n",
      "13.507049560546875\n",
      "11.772552490234375\n",
      "14.225874900817871\n",
      "9.595802307128906\n",
      "11.803011894226074\n",
      "10.722625732421875\n",
      "14.529180526733398\n",
      "10.040411949157715\n",
      "11.12325668334961\n",
      "11.63557243347168\n",
      "12.06622314453125\n",
      "13.001080513000488\n",
      "13.672011375427246\n",
      "11.972638130187988\n",
      "12.584056854248047\n",
      "11.272848129272461\n",
      "13.52401065826416\n",
      "8.339812278747559\n",
      "10.688465118408203\n",
      "12.703482627868652\n",
      "10.750876426696777\n",
      "12.720239639282227\n",
      "12.365944862365723\n",
      "11.052083969116211\n",
      "12.574091911315918\n",
      "11.010723114013672\n",
      "10.445670127868652\n",
      "9.72819995880127\n",
      "9.869593620300293\n",
      "12.219192504882812\n",
      "12.441657066345215\n",
      "11.025525093078613\n",
      "13.512055397033691\n",
      "14.852083206176758\n",
      "9.683977127075195\n",
      "9.560380935668945\n",
      "11.567670822143555\n",
      "9.807703971862793\n",
      "9.115797996520996\n",
      "9.376955032348633\n",
      "10.706170082092285\n",
      "12.261934280395508\n",
      "10.612014770507812\n",
      "8.423534393310547\n",
      "11.208026885986328\n",
      "12.378683090209961\n",
      "9.512556076049805\n",
      "12.390385627746582\n",
      "12.347444534301758\n",
      "9.553678512573242\n",
      "8.377942085266113\n",
      "11.440235137939453\n",
      "10.696402549743652\n",
      "9.734536170959473\n",
      "11.452102661132812\n",
      "9.510259628295898\n",
      "13.642117500305176\n",
      "10.941490173339844\n",
      "12.099352836608887\n",
      "12.114554405212402\n",
      "10.018155097961426\n",
      "12.293739318847656\n",
      "10.320762634277344\n",
      "8.741617202758789\n",
      "11.718688011169434\n",
      "9.915624618530273\n",
      "10.296518325805664\n",
      "9.372111320495605\n",
      "11.244935989379883\n",
      "10.582097053527832\n",
      "9.9180908203125\n",
      "10.831069946289062\n",
      "10.772356033325195\n",
      "9.9727201461792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.167119979858398\n",
      "10.24587345123291\n",
      "10.502156257629395\n",
      "12.514373779296875\n",
      "9.23038101196289\n",
      "11.842397689819336\n",
      "10.035550117492676\n",
      "11.670866012573242\n",
      "10.344599723815918\n",
      "10.818347930908203\n",
      "9.844173431396484\n",
      "8.784342765808105\n",
      "11.543109893798828\n",
      "9.467310905456543\n",
      "9.141812324523926\n",
      "10.33803939819336\n",
      "9.307416915893555\n",
      "8.079180717468262\n",
      "9.205039978027344\n",
      "11.127792358398438\n",
      "9.38379955291748\n",
      "8.650656700134277\n",
      "11.119937896728516\n",
      "9.041364669799805\n",
      "9.647001266479492\n",
      "9.371312141418457\n",
      "9.700767517089844\n",
      "10.818371772766113\n",
      "9.2669095993042\n",
      "8.50308609008789\n",
      "10.899491310119629\n",
      "8.674166679382324\n",
      "10.9971923828125\n",
      "7.954708099365234\n",
      "7.131963729858398\n",
      "10.66605281829834\n",
      "9.22916030883789\n",
      "10.726546287536621\n",
      "9.896520614624023\n",
      "9.675370216369629\n",
      "11.392810821533203\n",
      "10.243154525756836\n",
      "8.755273818969727\n",
      "9.082051277160645\n",
      "10.5385160446167\n",
      "7.8172221183776855\n",
      "9.871452331542969\n",
      "8.081914901733398\n",
      "9.208235740661621\n",
      "6.8119401931762695\n",
      "8.677042007446289\n",
      "8.805434226989746\n",
      "8.591714859008789\n",
      "5.741908073425293\n",
      "8.773880958557129\n",
      "9.145313262939453\n",
      "9.20401668548584\n",
      "9.078997611999512\n",
      "8.969520568847656\n",
      "7.7267045974731445\n",
      "8.429483413696289\n",
      "7.6335320472717285\n",
      "9.306965827941895\n",
      "7.956182956695557\n",
      "8.65000057220459\n",
      "9.673110008239746\n",
      "8.8236665725708\n",
      "9.496373176574707\n",
      "9.008516311645508\n",
      "9.5204496383667\n",
      "8.94967269897461\n",
      "9.132207870483398\n",
      "8.191932678222656\n",
      "7.780456066131592\n",
      "10.008769989013672\n",
      "7.180186748504639\n",
      "8.430201530456543\n",
      "10.870777130126953\n",
      "7.085538387298584\n",
      "5.648420333862305\n",
      "7.505825042724609\n",
      "7.445592880249023\n",
      "8.71756649017334\n",
      "8.09780216217041\n",
      "7.342031478881836\n",
      "9.375462532043457\n",
      "8.129571914672852\n",
      "7.682036876678467\n",
      "7.882672309875488\n",
      "7.06658411026001\n",
      "8.004149436950684\n",
      "8.506542205810547\n",
      "7.887234210968018\n",
      "6.193055152893066\n",
      "8.493854522705078\n",
      "7.174742698669434\n",
      "8.771726608276367\n",
      "6.276937961578369\n",
      "5.259372711181641\n",
      "8.342813491821289\n",
      "6.12701416015625\n",
      "5.405364036560059\n",
      "8.147387504577637\n",
      "5.737122058868408\n",
      "8.246159553527832\n",
      "6.91049861907959\n",
      "8.31281852722168\n",
      "7.725521564483643\n",
      "7.034533500671387\n",
      "5.46491003036499\n",
      "8.032164573669434\n",
      "5.8821845054626465\n",
      "6.529744625091553\n",
      "6.356865882873535\n",
      "6.209556579589844\n",
      "5.815375328063965\n",
      "6.427091598510742\n",
      "5.8978471755981445\n",
      "7.5050201416015625\n",
      "7.587297439575195\n",
      "7.398850917816162\n",
      "5.878087520599365\n",
      "6.872308254241943\n",
      "6.827439308166504\n",
      "5.210024833679199\n",
      "8.767097473144531\n",
      "5.861992835998535\n",
      "7.37545919418335\n",
      "6.9479146003723145\n",
      "5.849642753601074\n",
      "8.135380744934082\n",
      "5.469715118408203\n",
      "4.801877021789551\n",
      "7.0773186683654785\n",
      "6.753082752227783\n",
      "5.607227802276611\n",
      "4.329445838928223\n",
      "5.841750144958496\n",
      "7.851880073547363\n",
      "6.389108657836914\n",
      "8.035021781921387\n",
      "5.648529052734375\n",
      "5.438662052154541\n",
      "6.27253532409668\n",
      "7.738596439361572\n",
      "5.632200241088867\n",
      "6.057602405548096\n",
      "4.871301651000977\n",
      "7.094237327575684\n",
      "7.469230651855469\n",
      "7.037267684936523\n",
      "4.795905113220215\n",
      "5.238358974456787\n",
      "4.309842109680176\n",
      "6.506463527679443\n",
      "3.946533679962158\n",
      "5.279661178588867\n",
      "6.373805046081543\n",
      "6.228960037231445\n",
      "5.135851860046387\n",
      "5.325632572174072\n",
      "5.561316013336182\n",
      "5.605049133300781\n",
      "4.701125621795654\n",
      "6.176255702972412\n",
      "6.689675807952881\n",
      "6.269148826599121\n",
      "5.7222747802734375\n",
      "5.065167427062988\n",
      "5.3497185707092285\n",
      "6.693536758422852\n",
      "6.09831428527832\n",
      "5.837696075439453\n",
      "5.334157943725586\n",
      "6.351208209991455\n",
      "4.878905296325684\n",
      "5.267146587371826\n",
      "4.230229377746582\n",
      "6.041386604309082\n",
      "7.98325777053833\n",
      "5.823855876922607\n",
      "4.586864471435547\n",
      "4.810234069824219\n",
      "5.688712120056152\n",
      "4.767161846160889\n",
      "5.583338737487793\n",
      "5.803422927856445\n",
      "5.218969345092773\n",
      "5.520360946655273\n",
      "5.2870893478393555\n",
      "5.205761432647705\n",
      "6.443995475769043\n",
      "6.0168609619140625\n",
      "4.26993989944458\n",
      "5.908262252807617\n",
      "5.401586055755615\n",
      "5.943283557891846\n",
      "4.939054489135742\n",
      "4.6497721672058105\n",
      "4.0965704917907715\n",
      "4.092958450317383\n",
      "5.923981189727783\n",
      "4.80779504776001\n",
      "4.865788459777832\n",
      "4.877690315246582\n",
      "5.159274101257324\n",
      "5.009476184844971\n",
      "5.59832763671875\n",
      "4.035839080810547\n",
      "4.967278957366943\n",
      "5.4175872802734375\n",
      "4.617633819580078\n",
      "4.289353847503662\n",
      "4.661950588226318\n",
      "3.2459259033203125\n",
      "4.1289544105529785\n",
      "4.9158806800842285\n",
      "4.982282638549805\n",
      "5.499758720397949\n",
      "3.3511388301849365\n",
      "4.562009334564209\n",
      "4.190085411071777\n",
      "4.578579425811768\n",
      "4.724956035614014\n",
      "4.615002632141113\n",
      "5.13020133972168\n",
      "3.662822961807251\n",
      "3.474741220474243\n",
      "5.327791213989258\n",
      "5.09473991394043\n",
      "4.798892498016357\n",
      "4.1928839683532715\n",
      "6.676084518432617\n",
      "3.9097163677215576\n",
      "3.7936010360717773\n",
      "4.081352233886719\n",
      "4.681498050689697\n",
      "4.550058841705322\n",
      "4.218234062194824\n",
      "4.321529865264893\n",
      "2.72446608543396\n",
      "3.785437822341919\n",
      "3.8830838203430176\n",
      "4.715386867523193\n",
      "4.2288713455200195\n",
      "4.321904182434082\n",
      "3.6947622299194336\n",
      "3.7954158782958984\n",
      "5.47357177734375\n",
      "4.489317417144775\n",
      "3.560910224914551\n",
      "4.615758419036865\n",
      "3.7760558128356934\n",
      "3.4219305515289307\n",
      "3.8849570751190186\n",
      "3.141104221343994\n",
      "5.0576605796813965\n",
      "4.970973491668701\n",
      "4.064356803894043\n",
      "3.5793087482452393\n",
      "3.476285457611084\n",
      "3.643786668777466\n",
      "4.330363750457764\n",
      "3.903496265411377\n",
      "4.789430618286133\n",
      "4.174556732177734\n",
      "3.5586888790130615\n",
      "2.9768309593200684\n",
      "3.978609323501587\n",
      "4.3332319259643555\n",
      "3.4706156253814697\n",
      "3.613846778869629\n",
      "4.114100933074951\n",
      "3.201343536376953\n",
      "4.499466896057129\n",
      "4.1026763916015625\n",
      "3.698335886001587\n",
      "4.109897613525391\n",
      "3.521817922592163\n",
      "3.686795234680176\n",
      "2.580570936203003\n",
      "3.8466200828552246\n",
      "3.730158805847168\n",
      "4.141066074371338\n",
      "3.9757730960845947\n",
      "2.9854893684387207\n",
      "2.983234405517578\n",
      "2.7581465244293213\n",
      "3.3740246295928955\n",
      "3.8677401542663574\n",
      "3.332221031188965\n",
      "3.382601022720337\n",
      "3.634398937225342\n",
      "3.088930130004883\n",
      "3.1350815296173096\n",
      "4.381445407867432\n",
      "3.3901493549346924\n",
      "4.345114231109619\n",
      "3.267735242843628\n",
      "3.583721399307251\n",
      "3.0568642616271973\n",
      "3.62327241897583\n",
      "3.0920286178588867\n",
      "3.4672136306762695\n",
      "3.1080098152160645\n",
      "2.6876227855682373\n",
      "2.9760382175445557\n",
      "3.3605175018310547\n",
      "3.0349607467651367\n",
      "3.0755319595336914\n",
      "3.254112958908081\n",
      "3.996580123901367\n",
      "3.4371564388275146\n",
      "3.6331770420074463\n",
      "3.0578181743621826\n",
      "3.9073688983917236\n",
      "3.1346940994262695\n",
      "4.057934761047363\n",
      "4.630615234375\n",
      "3.8821091651916504\n",
      "3.2046847343444824\n",
      "2.997044324874878\n",
      "3.2335071563720703\n",
      "3.2991890907287598\n",
      "3.2294445037841797\n",
      "4.179348468780518\n",
      "3.496333360671997\n",
      "3.4740054607391357\n",
      "3.299142360687256\n",
      "3.685131788253784\n",
      "3.1115520000457764\n",
      "2.9911131858825684\n",
      "4.673068046569824\n",
      "3.7990875244140625\n",
      "3.850370168685913\n",
      "2.8567323684692383\n",
      "2.673707962036133\n",
      "3.2035324573516846\n",
      "3.5720856189727783\n",
      "2.845797061920166\n",
      "4.207042217254639\n",
      "3.4901654720306396\n",
      "3.8508994579315186\n",
      "3.535832166671753\n",
      "3.384979248046875\n",
      "3.2431585788726807\n",
      "3.1891720294952393\n",
      "3.832050085067749\n",
      "3.690690755844116\n",
      "2.9838483333587646\n",
      "3.1760332584381104\n",
      "3.7737209796905518\n",
      "3.416358232498169\n",
      "3.210822105407715\n",
      "3.4958837032318115\n",
      "2.655032157897949\n",
      "3.8240489959716797\n",
      "3.2179250717163086\n",
      "4.3306355476379395\n",
      "2.779855489730835\n",
      "3.2382235527038574\n",
      "3.10758900642395\n",
      "2.7638192176818848\n",
      "3.6214370727539062\n",
      "3.1119351387023926\n",
      "2.8800036907196045\n",
      "3.483983278274536\n",
      "3.332423686981201\n",
      "3.211878538131714\n",
      "2.5892996788024902\n",
      "3.3191380500793457\n",
      "3.3587863445281982\n",
      "3.238867998123169\n",
      "3.649665117263794\n",
      "4.030635833740234\n",
      "3.2478630542755127\n",
      "4.047393321990967\n",
      "3.197376251220703\n",
      "2.6204049587249756\n",
      "2.601076126098633\n",
      "2.4473254680633545\n",
      "2.8599586486816406\n",
      "3.021616220474243\n",
      "3.34295392036438\n",
      "3.0585649013519287\n",
      "3.7435667514801025\n",
      "2.933467388153076\n",
      "3.2419233322143555\n",
      "2.413949728012085\n",
      "2.740201711654663\n",
      "2.904038667678833\n",
      "3.1548538208007812\n",
      "3.596656322479248\n",
      "3.1542022228240967\n",
      "3.157545566558838\n",
      "3.1207964420318604\n",
      "2.387578010559082\n",
      "3.5846292972564697\n",
      "3.1800365447998047\n",
      "3.7766852378845215\n",
      "3.261465072631836\n",
      "4.719677925109863\n",
      "2.5664117336273193\n",
      "2.6107563972473145\n",
      "3.85166597366333\n",
      "2.5429582595825195\n",
      "3.6483561992645264\n",
      "3.3247673511505127\n",
      "2.7074790000915527\n",
      "3.857365846633911\n",
      "3.0158843994140625\n",
      "2.6778364181518555\n",
      "2.6954121589660645\n",
      "3.333143472671509\n",
      "2.880089521408081\n",
      "3.7697153091430664\n",
      "3.07643461227417\n",
      "3.5813143253326416\n",
      "3.220449924468994\n",
      "3.600316286087036\n",
      "2.9028542041778564\n",
      "3.6512043476104736\n",
      "2.979259729385376\n",
      "2.979912519454956\n",
      "3.4808008670806885\n",
      "3.4181926250457764\n",
      "3.2395026683807373\n",
      "3.1326026916503906\n",
      "3.2481446266174316\n",
      "2.885270357131958\n",
      "2.9500014781951904\n",
      "3.763082504272461\n",
      "3.5789191722869873\n",
      "2.9890902042388916\n",
      "2.894652843475342\n",
      "3.226426839828491\n",
      "3.6127336025238037\n",
      "2.964656352996826\n",
      "3.2122926712036133\n",
      "2.889296531677246\n",
      "2.429844617843628\n",
      "3.857481002807617\n",
      "3.394993543624878\n",
      "3.2768843173980713\n",
      "3.0727615356445312\n",
      "2.550886392593384\n",
      "3.4377036094665527\n",
      "2.702747106552124\n",
      "3.376065731048584\n",
      "3.3317930698394775\n",
      "3.5123496055603027\n",
      "3.485995054244995\n",
      "3.277012825012207\n",
      "2.8595802783966064\n",
      "3.566235303878784\n",
      "2.9971656799316406\n",
      "4.098523139953613\n",
      "3.143247127532959\n",
      "4.195586681365967\n",
      "3.66219425201416\n",
      "2.7857770919799805\n",
      "3.323700189590454\n",
      "3.2114923000335693\n",
      "3.121351480484009\n",
      "3.3757615089416504\n",
      "3.522407054901123\n",
      "3.5518336296081543\n",
      "3.6424360275268555\n",
      "3.3982796669006348\n",
      "3.4251766204833984\n",
      "3.0989935398101807\n",
      "2.8774869441986084\n",
      "3.038386344909668\n",
      "2.9856324195861816\n",
      "2.9987781047821045\n",
      "3.29237961769104\n",
      "3.522430181503296\n",
      "2.8683230876922607\n",
      "3.492112636566162\n",
      "4.165689468383789\n",
      "3.810606002807617\n",
      "3.036465883255005\n",
      "3.0699572563171387\n",
      "2.815969467163086\n",
      "3.341183662414551\n",
      "4.275912761688232\n",
      "4.5901103019714355\n",
      "3.568575859069824\n",
      "3.0313773155212402\n",
      "3.4677209854125977\n",
      "3.9933857917785645\n",
      "3.213700771331787\n",
      "3.2930409908294678\n",
      "3.2716124057769775\n",
      "3.7436985969543457\n",
      "3.674250602722168\n",
      "3.0266246795654297\n",
      "3.349200963973999\n",
      "2.7530839443206787\n",
      "3.5542685985565186\n",
      "3.2357964515686035\n",
      "3.237581729888916\n",
      "3.8153674602508545\n",
      "4.046353816986084\n",
      "3.9186651706695557\n",
      "2.9617414474487305\n",
      "2.7235732078552246\n",
      "2.843087673187256\n",
      "3.970838785171509\n",
      "4.288972854614258\n",
      "3.7277350425720215\n",
      "2.496743679046631\n",
      "3.7359681129455566\n",
      "4.377801418304443\n",
      "3.8160085678100586\n",
      "3.625701904296875\n",
      "3.8531901836395264\n",
      "4.14823055267334\n",
      "4.590888977050781\n",
      "3.135085105895996\n",
      "3.119882822036743\n",
      "3.542898178100586\n",
      "4.271937370300293\n",
      "4.7723917961120605\n",
      "5.339153289794922\n",
      "4.553448677062988\n",
      "3.8304595947265625\n",
      "3.5698604583740234\n",
      "4.117340564727783\n",
      "3.539276123046875\n",
      "4.67774772644043\n",
      "4.362566947937012\n",
      "3.7093193531036377\n",
      "3.8428568840026855\n",
      "5.7385969161987305\n",
      "3.492190361022949\n",
      "3.2173550128936768\n",
      "3.5763297080993652\n",
      "3.351921319961548\n",
      "3.574251413345337\n",
      "4.09259557723999\n",
      "3.2524683475494385\n",
      "4.628551006317139\n",
      "5.539977550506592\n",
      "3.9293293952941895\n",
      "5.007954120635986\n",
      "4.6066718101501465\n",
      "3.7272322177886963\n",
      "4.545659065246582\n",
      "4.193020343780518\n",
      "3.7387101650238037\n",
      "5.32428503036499\n",
      "7.209348201751709\n",
      "4.2513017654418945\n",
      "5.094964027404785\n",
      "4.40957498550415\n",
      "4.603163242340088\n",
      "5.2721710205078125\n",
      "4.00746488571167\n",
      "3.7169370651245117\n",
      "4.378387928009033\n",
      "3.8797852993011475\n",
      "5.149848937988281\n",
      "5.570501804351807\n",
      "5.489105701446533\n",
      "6.113797187805176\n",
      "6.637075424194336\n",
      "5.247461795806885\n",
      "6.233287811279297\n",
      "6.020593643188477\n",
      "5.440432071685791\n",
      "6.188941478729248\n",
      "7.032732009887695\n",
      "5.23071813583374\n",
      "6.115254878997803\n",
      "4.947145462036133\n",
      "5.447942733764648\n",
      "4.863147258758545\n",
      "5.820651054382324\n",
      "7.131837844848633\n",
      "5.54157018661499\n",
      "5.0511555671691895\n",
      "5.5920281410217285\n",
      "4.330563545227051\n",
      "4.39447021484375\n",
      "4.74337911605835\n",
      "6.0357208251953125\n",
      "5.328451633453369\n",
      "5.377631187438965\n",
      "4.403299331665039\n",
      "5.2916669845581055\n",
      "6.60187292098999\n",
      "4.8391313552856445\n",
      "5.389324188232422\n",
      "5.062037467956543\n",
      "5.274045944213867\n",
      "6.373068809509277\n",
      "6.345359802246094\n",
      "6.861196517944336\n",
      "5.634059429168701\n",
      "4.621230125427246\n",
      "4.841504096984863\n",
      "4.82784366607666\n",
      "4.654125213623047\n",
      "5.613120079040527\n",
      "6.549143314361572\n",
      "5.20872688293457\n",
      "5.504469871520996\n",
      "6.862957954406738\n",
      "6.418359279632568\n",
      "7.95380973815918\n",
      "7.185046672821045\n",
      "6.131503582000732\n",
      "8.823500633239746\n",
      "7.523109436035156\n",
      "5.653733253479004\n",
      "4.746186256408691\n",
      "5.131612300872803\n",
      "5.319092750549316\n",
      "5.16484260559082\n",
      "5.548619270324707\n",
      "4.1260199546813965\n",
      "6.306112766265869\n",
      "5.552933692932129\n",
      "8.158403396606445\n",
      "7.093297958374023\n",
      "7.416223049163818\n",
      "5.1005167961120605\n",
      "6.519681930541992\n",
      "7.770383834838867\n",
      "4.927614688873291\n",
      "6.546329975128174\n",
      "7.225534915924072\n",
      "6.945928573608398\n",
      "5.389883041381836\n",
      "4.875976085662842\n",
      "6.294128894805908\n",
      "5.949131488800049\n",
      "7.735033988952637\n",
      "4.498910903930664\n",
      "7.11105489730835\n",
      "6.735255718231201\n",
      "6.651374340057373\n",
      "7.420413494110107\n",
      "5.707772254943848\n",
      "4.127137184143066\n",
      "6.080265522003174\n",
      "9.48153018951416\n",
      "8.985024452209473\n",
      "8.543900489807129\n",
      "7.177389144897461\n",
      "8.64666748046875\n",
      "7.933012008666992\n",
      "5.311490058898926\n",
      "8.065509796142578\n",
      "7.476244926452637\n",
      "6.117537975311279\n",
      "5.18220853805542\n",
      "8.437074661254883\n",
      "7.9815673828125\n",
      "7.435151100158691\n",
      "8.077960014343262\n",
      "8.173690795898438\n",
      "5.8137431144714355\n",
      "5.759644508361816\n",
      "7.038625717163086\n",
      "6.448541641235352\n",
      "7.8535308837890625\n",
      "5.656162261962891\n",
      "7.5444464683532715\n",
      "6.756327152252197\n",
      "12.95439338684082\n",
      "9.492276191711426\n",
      "11.628511428833008\n",
      "12.962934494018555\n",
      "7.761214256286621\n",
      "10.806317329406738\n"
     ]
    }
   ],
   "source": [
    "# Reset parameters\n",
    "g, C, W1, b1, W2, b2, parameters = make_parameters()\n",
    "learningrate = 10 # Way too high\n",
    "\n",
    "# Track learning rates and losses\n",
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "# Loop through learning rates\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    lr = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # Track stats\n",
    "    lri.append(lr)\n",
    "    lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just plot the learning rates and losses and see if there's a local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e6cc60fcd0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGfCAYAAAD/BbCUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnIUlEQVR4nO3deXxcdbk/8M+ZPXuaPWnTfadQSguFsrQFWqgIsqggXgWv+gPZL6KCeC/lqqCoiIigF2VTNllFWSvQBQqFlraUbnRJ23RJ0uyTZfbz+2Pme+acM2fWTGaSzOf9euVFM5nlZBJynvM8z/f5SrIsyyAiIiLKEFO2D4CIiIhyC4MPIiIiyigGH0RERJRRDD6IiIgooxh8EBERUUYx+CAiIqKMYvBBREREGcXgg4iIiDKKwQcRERFlFIMPIiIiyihLMne+++678eKLL2LHjh3Iy8vDggUL8Mtf/hLTpk1T7nPllVfi8ccf1zxu/vz5+PDDDxN6jUAggMOHD6OoqAiSJCVzeERERJQlsizD6XSirq4OJlPs3EZSwceqVatw7bXX4sQTT4TP58Ptt9+OpUuXYtu2bSgoKFDud+655+LRRx9VPrfZbAm/xuHDh1FfX5/MYREREdEQ0djYiDFjxsS8T1LBxxtvvKH5/NFHH0VVVRU2bNiAM844Q7ndbrejpqYmmadWFBUVAQgefHFxcUrPQURERJnV3d2N+vp65TweS1LBh15XVxcAoKysTHP7ypUrUVVVhdLSUixcuBA///nPUVVVZfgcbrcbbrdb+dzpdAIAiouLGXwQERENM4m0TEiyLMupPLksy/jSl76Ejo4OrFmzRrn92WefRWFhIcaNG4eGhgb893//N3w+HzZs2AC73R7xPMuXL8edd94ZcXtXVxeDDyIiomGiu7sbJSUlCZ2/Uw4+rr32Wrz66qt47733YtZ2jhw5gnHjxuGZZ57BxRdfHPF1feZDpG0YfBAREQ0fyQQfKZVdrr/+erzyyitYvXp13KaS2tpajBs3Drt27TL8ut1uN8yIEBER0ciUVPAhyzKuv/56vPTSS1i5ciUmTJgQ9zFtbW1obGxEbW1tygdJREREI0dSQ8auvfZa/O1vf8NTTz2FoqIiNDU1oampCf39/QCAnp4e3HLLLfjggw+wb98+rFy5Eueffz4qKipw0UUXDco3QERERMNLUj0f0TpYH330UVx55ZXo7+/HhRdeiI0bN6KzsxO1tbVYvHgxfvrTnyY8uyOZmhERERENDYPW8xEvTsnLy8Obb76ZzFMSERFRjuHeLkRERJRRDD6IiIgooxh8EBERUUYx+CAiIqKMYvBBREREGZVTwceKbc149dMj2T4MIiKinDagXW2HE68/gO8+sR4AcPLEs1FeyJHuRERE2ZAzmQ9/IDyjpMfty+KREBER5bacCT6IiIhoaGDwQURERBnF4IOIiIgyisEHERERZRSDDyIiIsooBh9ERESUUTkZfMhy/PsQERHR4MjJ4IOIiIiyh8EHERERZRSDDyIiIsooBh9ERESUUQw+iIiIKKMYfBAREVFGMfggIiKijMrJ4INjPoiIiLInZ4IPScr2ERARERGQQ8EHERERDQ0MPoiIiCijGHwQERFRRjH4ICIiooxi8EFEREQZxeCDiIiIMipngg8JXGtLREQ0FORM8KEmyxwzRkRElC05GXwQERFR9jD4ICIiooxi8EFEREQZxeCDiIiIMorBBxEREWUUgw8iIiLKqJwJPiSO+SAiIhoScib4UOOUDyIiouzJyeCDiIiIsofBBxEREWUUgw8iIiLKqJwMPth7SkRElD05GXwQERFR9uRk8OF0+bJ9CERERDkrJ4OPt3e0ZPsQiIiIclZOBh+QOemDiIgoW3Iy+GDoQURElD25GXww+iAiIsqa3Aw+mPsgIiLKmpwMPoiIiCh7cjL4YNmFiIgoe3Iz+Mj2ARAREeWwnAw+iIiIKHtyMvhg2YWIiCh7cjP4YOGFiIgoa3Iy+GDsQURElD05GXww9iAiIsqenAw+iIiIKHtyJvhQN5nK7DglIiLKmpwJPtTae73ZPgQiIqKclZPBxwufHMz2IRAREeWsnAw+iIiIKHsYfBAREVFGMfggIiKijEoq+Lj77rtx4oknoqioCFVVVbjwwguxc+dOzX1kWcby5ctRV1eHvLw8LFq0CFu3bk3rQRMREdHwlVTwsWrVKlx77bX48MMPsWLFCvh8PixduhS9vb3Kfe655x7ce++9eOCBB/Dxxx+jpqYGS5YsgdPpTPvBExER0fBjSebOb7zxhubzRx99FFVVVdiwYQPOOOMMyLKM++67D7fffjsuvvhiAMDjjz+O6upqPPXUU7jqqqvSd+REREQ0LA2o56OrqwsAUFZWBgBoaGhAU1MTli5dqtzHbrdj4cKFWLt2reFzuN1udHd3az6IiIho5Eo5+JBlGTfffDNOO+00zJo1CwDQ1NQEAKiurtbct7q6Wvma3t13342SkhLlo76+PtVDIiIiomEg5eDjuuuuw6effoqnn3464muSJGk+l2U54jbhtttuQ1dXl/LR2NiY6iERERHRMJBUz4dw/fXX45VXXsHq1asxZswY5faamhoAwQxIbW2tcntLS0tENkSw2+2w2+2pHAYRERENQ0llPmRZxnXXXYcXX3wR77zzDiZMmKD5+oQJE1BTU4MVK1Yot3k8HqxatQoLFixIzxETERHRsJZU5uPaa6/FU089hX/84x8oKipS+jhKSkqQl5cHSZJw00034a677sKUKVMwZcoU3HXXXcjPz8fll18+KN8AERERDS9JBR8PPfQQAGDRokWa2x999FFceeWVAIAf/vCH6O/vxzXXXIOOjg7Mnz8fb731FoqKitJywERERDS8JRV8yLIc9z6SJGH58uVYvnx5qsdEREREIxj3diEiIqKMYvBBREREGcXgg4iIiDKKwQcRERFlFIMPIiIiyigGH0RERJRRDD6IiIgooxh8EBERUUYx+CAiIqKMYvBBREREGcXgg4iIiDKKwQcRERFlFIMPIiIiyigGH0RERJRRDD6IiIgooxh8EBERUUYx+CAiIqKMYvBBREREGcXgg4iIiDKKwQcRERFlFIMPIiIiyigGH0RERJRRDD6IiIgooxh8EBERUUYx+CAiIqKMYvBBREREGcXgg4iIiDKKwQcRERFlFIMPIiIiyqicDT4CATnbh0BERJSTcjb42HakO9uHQERElJNyNvjw+APZPgQiIqKclLPBx2ufHsn2IRAREeWknA0+mPkgIiLKjpwNPoiIiCg7GHwQERFRRuVs8CFzpS0REVFW5GzwQURERNmRM8GHxSRpPpekKHckIiKiQZUzwYfJxGiDiIhoKMiZ4IOIiIiGBgYfRERElFEMPoiIiCijcjb4YAcIERFRduRu8MHlLkRERFmRs8EHERERZUfOBh9MfBAREWVH7gYf7PogIiLKipwNPoiIiCg7cjb4YNmFiIgoO3I2+Hhy3f5sHwIREVFOytngw+UNZPsQiIiIclLOBh9ERESUHQw+iIiIKKMYfBAREVFGMfggIiKijGLwQURERBnF4IOIiIgyisEHERERZRSDDyIiIsooBh9ERESUUQw+iIiIKKMYfBAREVFGMfggIiKijGLwQURERBnF4IOIiIgyisEHERERZVTSwcfq1atx/vnno66uDpIk4eWXX9Z8/corr4QkSZqPk08+OV3HS0RERMNc0sFHb28vZs+ejQceeCDqfc4991wcOXJE+XjttdcGdJBEREQ0cliSfcCyZcuwbNmymPex2+2oqalJ6PncbjfcbrfyeXd3d7KHRERERMPIoPR8rFy5ElVVVZg6dSq++93voqWlJep97777bpSUlCgf9fX1g3FIRERENESkPfhYtmwZnnzySbzzzjv4zW9+g48//hhnnnmmJruhdtttt6Grq0v5aGxsTPchRXWgrS9jr0VERERBSZdd4rn00kuVf8+aNQvz5s3DuHHj8Oqrr+Liiy+OuL/dbofdbk/3YSTkjF+9i32/OC8rr01ERJSrBn2pbW1tLcaNG4ddu3YN9ksRERHRMDDowUdbWxsaGxtRW1s72C9FREREw0DSZZeenh7s3r1b+byhoQGbNm1CWVkZysrKsHz5clxyySWora3Fvn378OMf/xgVFRW46KKL0nrgRERENDwlHXysX78eixcvVj6/+eabAQBXXHEFHnroIWzZsgVPPPEEOjs7UVtbi8WLF+PZZ59FUVFR+o6aiIiIhq2kg49FixZBluWoX3/zzTcHdEBEREQ0snFvFyIiIsooBh9ERESUUQw+iIiIKKMYfBAREVFGMfggIiKijGLwQURERBnF4IOIiIgyisEHERERZRSDDyIiIsooBh9ERESUUQw+iIiIKKMYfBAREVFG5Xzw0eP2ZfsQiIiIckrOBx+/f3tXtg+BiIgop+R88HGosz/bh0BERJRTcj74kLN9AERERDkm54MPRh9ERESZxeCDiIiIMirngw+ZqQ8iIqKMYvDB2IOIiCijGHww+CAiIsooBh8suxAREWVUzgcfREREw43b5497n4MdffD4Ahk4muTlfPDBsgsREQ0na3e34tg73sLja/dFvc9nh7pw2i/fxY9e+DRzB5aEnAo+rGYp24dAREQ0IBsbO+HxB/BRQ3vU+3y8L/i13S09mTqspORU8FFXmhdxGxMfREQ0nLhDpRRnjI1RG1p7AQD93vjlmWzIqeDDKO/BsgsREQ0not/D6fJGvY8IPlwMPoYqRh9ERDR8uL3BzEePK3rmY+9RBh9DGjMfREQ0nIiyS0+UsovL68fhruCO7f0eBh9DUmd/9LQVERHRUBMuuxgHH/vb+pQL636vH/IQvMrO+eBjw/6ObB8CERFRwtSZj0AgMrBoaA2vcAnIgMc/9GZ95FTwsWhaVbYPgYiIaEBEzwcA9Hgisx97Q82mgsvD4COrfnTu9GwfAhER0YCop5saNZ02HNUFHwlMQ820nAo+8mzmbB8CERHRgLhVI9ON+j4adJmPodh0mlPBBxER0XCnDj563JGLJiKCjyG43JbBBxER0TDiVgUT3brMR1efF229HgBAeYENAIMPIiIiGiD1TrX6no+GtmDWo7rYjvLCYPDhYtmFiIiIBiJWz4dYZjuhogB51mCfIzMfRERENCDqken6ng+x0mVCRSEcoeDD5eVSWyIiIhoAd4yyi5jxMbGiQAk+mPkgIiKiAVHP+dA3nIqVLiy7EBERUVr4AzK8/vBIdfXmcrIsh4OPygJlthUbTomIiChl6pUuAOB0hXs+mrvd6PP4YTZJqB+Vz7ILERERDZxbNypdnfnYG1rpUj8qDzaLSSm7uBh8EBERUarcEZmPcPBxoK0PADCuvAAA4LAGT/HMfAxRBzv6sn0IREREcbl1y2bVq12OOt0AgJpiBwAw8zHUrdvbnu1DICIiiktfdlGvdjnaEww+KoqCk01Fwyk3lhuivv/cZnj9Q28ICxERkZq+7KIeMtYaCj4qC+0AwIbT4WDVzqPZPgQiIqKYROajJM8KIDi9VFw8i7JLZZG27NLPCadDly8w9H44REREaqLnQ+xYC4T7Plp7grvZVhRqyy7s+RgCvn3ahGwfAhERUUpE2aXAblEyG2K5bTjzIcouwVM8gw8iIiJKmSi72C0mFDosAIBulxf9Hr8ShFQU6Xo+2HBKREREqRKZD7vVhKJQ8NHj8inNpnaLCUX24O3c22UIkeXkbiciIhoqRM+H3WJWggyny4cWVclFkiQAQ7vnw5LtA8g0GYwyiIhoeFKXXYocwRUvPW4f/KEr6IrQMltAlflg2WXo+t6Tn+D5DQezfRhERERRKWUXiwmFSubDG9FsCqgmnPoCkIdYep/Bh8otz23O9iEQERFFFQ4+zErPh9Md7vlQZz7soeDDH5Dh9QeDj84+D06+622ce99q+APZC0hyruxCREQ0XLlD/Rt2qwlmU7C3w+nyobs/OOnUKPMBBJtObRYTOvu8aOp2wenyKo/PhpzLfAyxzBMREVHC1GUX0XDa4/KFyy6F4eFjVrOkBBii6bQrFKSICanZknPBBxER0XClLbuEG06VfV1UmQ9JkiKaTkXwUczgI7OmVBdm+xCIiIhSYjRkzOnyKjvaqoMPIDxozOVj8JFVX5lbn+1DICIiSoky50M1ZKzb5UOrU+zrog8+gqd5feaDZZcMy2aDDRER0UCoyy5iqW1zt0uZYqoPPvRTTrtdDD6IiIgoCUZDxhrb+wAA+TYzCuzaRaz6KafMfBAREVFSjPZ2EeM69P0egHpzueDjuhl8EBERUTI0e7s4tFmOysLI4ENfdhm2mY/Vq1fj/PPPR11dHSRJwssvv6z5uizLWL58Oerq6pCXl4dFixZh69at6TpeIiKinKVZ7aIrsej7PQDViPXhHnz09vZi9uzZeOCBBwy/fs899+Dee+/FAw88gI8//hg1NTVYsmQJnE7ngA+WiIgol6kbTgtsFkiqNRTGZZfgaX6oBR9Jj1dftmwZli1bZvg1WZZx33334fbbb8fFF18MAHj88cdRXV2Np556ClddddXAjjYNuNaFiIiGK3XPh8kkodBmgdPtAxAl82HLgSFjDQ0NaGpqwtKlS5Xb7HY7Fi5ciLVr1xo+xu12o7u7W/NBREREkZS9XSzB03ehqu8jZsOpyHz0DY3MR1qDj6amJgBAdXW15vbq6mrla3p33303SkpKlI/6eg4BIyIiMqIuuwDQNJ1WqPZ1EdQNp4GArGRJivOyu6/soKx2kSRtcUOW5YjbhNtuuw1dXV3KR2Nj42AcEhER0bCn3lgOgKbp1CjzoW44dbp9yuaq2c58pDX0qampARDMgNTW1iq3t7S0RGRDBLvdDrs98g0jIiIiLWW1S6iRVAwaA6IEH8qQsYAy48NhNSmZk2xJa+ZjwoQJqKmpwYoVK5TbPB4PVq1ahQULFqTzpYiIiHKKPyDD6w+mLkTwUKgpu0QGH3bVrrZDZaULkELmo6enB7t371Y+b2howKZNm1BWVoaxY8fipptuwl133YUpU6ZgypQpuOuuu5Cfn4/LL788rQdORESUSzyhkgsQLrsUh4KPIodFaS5VU/d8DOvgY/369Vi8eLHy+c033wwAuOKKK/DYY4/hhz/8Ifr7+3HNNdego6MD8+fPx1tvvYWioqL0HfUAyNk+ACIiohSIkgsQ2fNhNN0UGEHBx6JFiyDL0U/hkiRh+fLlWL58+UCOi4iISGN3Sw/ybWbUleZl+1CyQjSbmk0SLGZtz0eFQb8HAOTZwkPGhlLwwb1diIhoyOvq8+KCB97DJQ+t1ZQfckl4X5fwqVv0eYyJEpA5DHo+sj1gDEjzapeRINayYCIiyo5mpwt9Hj/6PH6s3dOKRdOqsn1IGafe10W44Pg6dPV7cd6xtYaPEcGHy8fMx5C2cufRbB8CERHp9ISGYwHAq58eyeKRZI8ou6gbSwvtFnxv0SSMLc83fIzS8+EJL7Vl8JEFpjhJjdYed2YOhIiIEtbnDjdbvrWtOSdLL0aZj3jUQ8aUsouDwUfGsaRCRDT89HrCmY+ufi/e39OaxaPJjnDPR+IDwpSN5dhwSkRElJxeVdkFAF7LwdKLekfbRIkSjT8go63HA4DBx5DEOSBERENPb2hLeLG6482tTTlXehlI2QUAmrtdAICSfAYfREREcYnMx+lTKlBRaEe3y5dzpRf9jraJsJolpdexrZeZDyIiooT1hYKPIocFXzg2uInpPzYeyuYhZZzRnI94JEnSZD8ABh9ERDmrI3QVSokRZZd8mwUXzRkNAHj9syZ0u7zZPKyM0u9omyjRdCow+BiCWnvc+OxQF7z+3KolElHmvLL5MOb8dAX++sG+bB/KsCHKLgU2M46vL8XkqkK4fYGcmvmRStkF0M4FsVlMhhvQZRqDD5173tiJL/7+Pdzy3OZsHwoRjVCfHeoCAGzY35HlIxk+ROajwG6BJEn4ytwxAIDn1jdm87AyKhx8JJn5UAUbQyHrATD4iOofmw5n+xCIaIQSV/HN3RxqmCjR81FgD55IL5ozGmaThE8OdGLP0R7NfZu6XFj1+cibVu32Jr/aBdBmPhh8EBHlKCX4cLqyfCTDhxivnm8LbklWVezAwqmVAIDnNxzU3Pf2l7bgikc+GnEBSHjOR3JlE3Xmo9gxNLZ0Y/BBRJRhooTQwsxHwvpC71mhPXzyFKWXFz85CH8gPKVpR5MTALB6pAYfyWY+bMx8EBHlvL7QqPAety9icicZ61UyH+ET6VkzquGwmtDc7cb+tl4AwUmeTaFhWh/vax/w63p8gSGzosaVYtklT7U6hsEHEVGO6lFtktbiZPYjEWJvlwJV5sNmMWHMqOBuroc6+wEALU6XkgXZerh7wMHd5Q9/iMW/WomW7uyXyFJd7cKGUyIiUpongfDIa4pN7GqrDj4AYMyoPADAoY5g8HE4FIQAwSzIJwdSX1EkyzI2H+xEW68Hz+n6SrIhHXM+GHxk0fH1pdk+BCLKYb0MPpIiy3I486EbmDW6NBR8dIrgQ/t+ftSQeunF7QvA6w9mUZ79uBGBQHZ3/0plwmnw/qqGUwYf2fPEt0/CX66Yl+3DIKIcJRpOATadJsLlDUCc9/WZj9GhzMdBXebDZg6e3gYSfPSogsQD7X34YG9bzPvLsqz0ZQyGlMsuzHwMDcUOK86aUZ3twyCiHCUaToFgj0I67Tnag4sffB9vb29O6/NmU6/q/dLvU6L0fISCjyNdwfdz0bTgMtxNjZ1KuSJZPS5tv8gzHxsPNJNlGW981oSlv12N2Xe+hc+bnSm9Xjyp7GoLsOeDiCjnuX1+JZUPpH/Q2L+3NeOTA514ct2BtD5vNqlXupjEFq0h+rKL+O9pUypQXmCD2xdQJsoKBzv68N6u+DviisyHJfSab37WhHbdnjyN7X248A/v4+q/bcCulh64fQF8erAr4rnSITzng8HHiPb3UJTr8QW4HI6I0qLPrb0KT3fPhzhhNrb3pfV5s6k3SrMpANSHyi5Huvrh9QdwpCsYfIwuzcO88aMAAB81aJtOf/TCp/iPv6zD+7tjByDOUOZjfEUBjqkrhscfwEu6nXR/9eZObD7YhXybWQmEOvsGZ9PAcM9Hknu7qMsu+Qw+su6nF86K+fUfvvApAGDhr97FMXe8CecQWetNRMNDY3sffvDcZk0aXl1CANK/1FacMA+090GWs9sgmS59UZpNAaCi0A6b2YSAHByrLhpOa0vycOL4MgCR8z72twUDszc+a4r5uiKQK7RbcNlJYwGEL0qB4Gqa1buCg8weufJELJkZLOfrsyPpko6yS7GDwUfWVRXZE7qfqCFuGaRUGhGNTH9f34jnNhzEw6v3Krf16jIf6Z4fIbK0bl8AR0fIDJEed+SMD8FkkpSm091He5QTf12pQwk+NjV2ah7T3R+8kHxnR0vMAK3HHbxfkcOCC2bXwWqWsLPZiV2hYPLTg53o7POiyGHBvHGjUFZgAwB0pJD56Or3xg0WU9/VlkPGhhQp/l2IiFImTv5GmY/y0Imq1+PXrKoYKP0KjZFAjFYvsBnvSyLKHRv2Bcsr+TYzSvKsygyQ9l6PMngsEJDhDL1Hhzr78Xlzj8EzBomG00K7BSV5Vpw+JdjE+tqWYMZE7B1z+pQKWMwmjAr9TJPNfGw52IU5//sW7vzntpj3G2jPh8UkaSbEZlNOBx9ERIOptSd4EtrV0qPMiBA9H5VFdhSFruTT2feRTPDR0u3CV/64Fv/YdCjm/ZIRCMjYsL8D/Z70LTlVNpWzG584RZDxUai8UlvigCRJmpkWomze4/FBnWB4Z0dL1Nd1qsouALBsVg0A4PXPjgAIBx9ig7uy/FDmoze5Ev26hjYEZGBjnIFoqe5qK4KPkjwrJGloXHYz+Igj20NliGj4au8NZj76PH4cDjVC9qhWblQVB0u/6Qw+nK7Eg49/b2/Bx/s68FQaV8a8ta0Zlzy0Fr94fXvanrMvRtkFCGc+RHmlLvS51WxSrvS7QqUWUXIR3tkRfUmyyHyI110ysxoWk4QdTU5s2N+BzaHXOyMUfIwKNXO2J1l2ET8nEaxGk2rZRbwf4ysKknrcYGLwEQdDDyJKlTr9viuU3u9T7VFSXewAkN5BY71JZD7EQC59E+xAiH6I/Wks+fQqZRfjk67o+fCETs51JXnK10SPQ3e/T/NfWyh7sGF/R9TVKSJQLAptQ1+ab8OpkysAAP/98mcIyMC06iLUhl5PlF06kiy7hIMPd9S+D58/AF/oYjjZzMf4igK8dM0CPPT1E5J63GDK6eBjqKSfiGhkalOdhETfR6+qf0E0vadz0Ji67BJvua3IxuibYAdCfM/6JcUD0Rsn8yEGjQniSh8IBx9K5iNUfqkflYdp1UUIyOHyiZ6650P4wrHB0su2I90AgIWhYWYANA2nyWTND4RW37h9Ac3020BAxtrdrej3+OHxB5Tbk+35AIA5Y0ehKhTsDgU5HXwkYqQsVSOizHL7/JoSiGhs7FX1L4jMR1NX+jIfPUmUXUTmI50Nr609we8lndmUuA2no/I0n9eWhk+yYmmpvuxSnGfFmTOqAABvbzfu+1B6Phzh110yswZm1aCzRVPDwUdpqOwSkMNBTjz+gKyMhgeAtp7w78I/Pz2My/+8Dne/vl2Z8QGER8cPZ8P/Oxhkr245ku1DIKJhSN90uLslmPnoUzUxVhQGMx+pLM00EgjI6FGd9Ju73XB5/dilWh6qJmZi6MeID0RbqG8hmcGMK7Y1xxxJ3hun4bS6yK5MIQXCPSBAeCO1cOYj+FzFDivOnB4MPtbsOmp4oWmU+SgrsOGUieXB47GZMTc0yAwI9mKI+ya64qW526XJaqj7PkR25e3tLUq/h8UkwcLgY+S7/+1d2T4EIhqG2kLNpqK6K1a8iLR6vs2iTJtM10TMPq9fWckheho+2d+BCx54H1/50wdKTwQQDFTENNB+r19ZijpQ4vvuTXC1y7bD3fjuE+tx7ZOfRL2PyKIURim7WMwm1JSEsx21qn9HlF1UmY9jR5cAADr6vOjsi8xU6Hs+hAvnjAYALJ5WFdH8OarAGnrOxH6mYuCZoM58iF6gQ5392Hs0mDlLtt9jqBoZ38UgUgfDLMAQUaLEle/EigJYzRL6PH4c6uxXruIL7WaUhk6Mnf3pmZ4snttskjCpshAAcNfr29Hv9aOzz6ucgAGgtdet2WMmXWUSceXel2DmY/3+4PLY/TEmsoqelPwoZRcgvNwW0PZ8FOcFHyPKIOK/xQ4LHFYzKkN9N40dkSWq8IRT7WCuS04Yjce+dSJ+flHklOxkl9vq+3LUfULqVVCrQ3vR2K1DY07HQDH4iMPPng8aAVxeP7cHyDARfFQVOTCxIhgI7G7p0WQ+SkMnqi6Dq+5UiB6TApsZ48qCTZifHepWvq7uQxAlF0FfJnF5/Xhl8+Gk5nX4/AHlir/X40+o6XJzY3BytMcXUEoiekrDaYwBWaNLg99vWYENDoON1MKZj1DZJXS72BumsT3cdyE4DcouQHCxwqJpVcrPT00ZNJZg5kPfl9OqmkqrCT5CTbHMfIwAiax1SVcqkiibvvTA+1j0q5VwedO3AoFiExmA8kIbplQHg4/Pm52qlRtmpUExXZmPcJnAirHl+RFfV8+4EM2mgj74eHj1Xtzw9Eb8KLTHVSI6+ryabHF/Ar9vnx7sVP4dbRy8skIoStkFCGc+6kq1KzqirXYRjaj1oSDNOPMRHq+eqHDmI8GySyj4ECPQ1ZkP9RJs0f/B4CNHqCN3Lsyl4cjnD2BnsxNtvR5lJcJQ8sxHB3DK3W9jR1N3/DsPI2LAWHmBTSmBNLT2apaNKmWXJJdmRqNukBQnVTV1ZkEffDh1WYcP9rYBAF7ZfDhiS/poRL+HIEo5B9r68LN/bYtYUtzj9mH30fB482jBR3g2SvTMx4zaIgDA1Koize3hOR/6no9gQFEfWqarL3/4/AG4QitMovWaGEk183HcmFIA4dVCfR6fstpGLdkBY0NVTgcfCyaXx70Pyy403PWprj7VDYeDqavPi5c2HlROGrG89lkTjnS5sHZ3WwaOLHNE2aWswK5clR/q7NcsGxWp/4AMwxNNsnpUS0PHhzIfhXYLjqkrBgBN6S2y7BL+PfEHZGV6JwDc8+bOhF6/TTehUzznI+834M/vNeCuV7VTT7cc7NJkSo5GCY7jzfkAgktgH73yRPz3F2dqbhcZju6omY9Q2aVDnwkKvx+xXlevLM6gsX9uPowN+8Nj1A+09QIAThgbXDUj3kOR9ci3mZWfH5DajI+haGR8FymK1bwksOxCw5162JM7Q8HHg6t247+e3ZzQ2G7xR7orTaWHoUKcRMoKbcoQrIMd4YbTfJsZDqtZ2XcjHX0f6i3gF0yqwPcWTcLvLjtemcAp+h2AyMyHetbHrhYnej1+OKwmWM0SVn9+FGv3tMZ9fX1mTXyvopTw6pYjmuyGuuQCxCi7uGPP+QCCTbaLp1cpmQdBrCiK1vOh/Gx0mQ9nqORit5iUlUOJGJUvNpeL/HnubunB9U9vxLce/SjU4+JFR+jnPmdsKYBw9kj0e1QXOzB/QvhCmWWXHMHEBw136uxDpjIfe1qCqfSmrviTO9tHaPAhvq+KApsm8+HUXcWH+z4Gvty2J3RVX2i3wGyS8KNzp+OsGdURKz6A8HRTsRRY3fOx6UAnAGBO/Sh87aSxABIbO6DPfIgsj8i4eP0ynvkoHJBuDgUfYmiWUfDhD8hK70gqO7JG7/nQll0OdvRrSl/RltnGUxZjqe3OJmfoGHxYu6dVKfWUF9gwLpSpEu9hc+i9qCqy46QJZcpzsOySIxh70HDX58l85uOQGF6VQClB/JFOdCJkuvW6fbj6rxvwwoaDA36u5m4Xrnz0I3ywp0252i8rsKGmxAGTFAz+xAlWBB8lSt9HejMfavrSAxDOfIwN9Yaol9puFMHH2FJ8ff44AMF5HPFEZD48Yj+V8Os+ue4AfKGhWmKly/yJwZOrUfChDp6TKX8Iyvfu8kGWZc2cDyA4DdUkAR5/AC2q1zcaMJaIUTEaTveFSiwA8ObWJmWsen1ZPsoLgkt+2/s88PkDaFFlPrTBx8g4bY+M72IQqdedMxCh4Uh9RZupzIc4scXrY3B5/UpwpN9tNFPe2taEN7Y24aFVewb8XC9tPISVO4/injd3KMOiygttsJpNqNHtqyGWjaZzxYvROHAgfKIVAZ7L61dW40wJNWiqA8WNjcGehDljRynDu7pdvrirpSJ7PoLPqW5mbep2YcW2ZrT1uHGosx+SBGXSqFHPh/j9MJuklE68IrjzB2Q43eEmThGUWM0mpSylXvES7b2MpyxGw2lDazj4WLGtGQ2hYGRceT5G5VshScFse0efV1V2saOswIapoRVT7PnIEelaAkeULZqGU//gL7XtdfuUFHe8sd3q1HS2yi6i+a8lDdvaiyv3TY2dysqSstAVrX7/EaXskidmfQy87NIbNfMRKruE+h1EOSzPalZKQuJn1e3yYleobHZ8fSmKHRblpB+tJ0PQr3YR/UYi+FgY2gfld2/vwksbDwEIDmGbGFoNZPT8PaoemVQ2A3VYTUpZ53Bnv1JKV5dTRNPpQVXwkXLmIxR8dPV7lQyPoA4+Wns8+MfGwwCC2SeL2aRkTdp63WgONZyK/X9E3wfLLiPErNHFMb8eq+dj/b52LLl3Fdbujt+IRZQtmoZT78AzH15/AB81tEfNooiR3UD8sot6/wt1M2QmbdjfGXz9BK7s4xEnT/F3wyRBWU6r33lVNJoqmY90lF1cxn0K4ipf9F6IzFRdqUM5uYrA5dPG4AqU+rI8VBbZIUkSqooT231XZFNEsKKUXUKve/XCSSiwmbGjyYmfhVa+zB5TisrQHjdHDZ5f/P4mGwQIkiQpmR9R5rBbTJpBZOHltpG/u/rppvGIn7csRwbU+0LBx7TqYLZpZ2g/G1H6Kg8FLm09HiXzIXaiveykekyvKcIXj6tN6niGqpwPPgbiK3/6ALtaenD5n9dl+1CIotI0nPoHHnzc88YOfPVPH+A3bxkvvzykWsIZN/OhWhGQrszHuztbcNVf1yc008Tp8mKnar5IvCv7ePSPLyuwwRTa8Ey92Vm+zazcXpLGsktPlCWp4YbT4NcPKcFHnnLfntBJfuOBUMmlPrxhmggO1EOvjIjMh9JH4vbB5w8opZNpNUV4+dpTsXRmtfKYueNHKSPO23o9EdkCEcCk0mwqiO9fLKcVwYigDBprj8x8JNtwajGblFJPR5/291v0Af2/MyZqHiPeL7HRYGuPW+k/qQ69N8fUleCNm87AWTOqMRLkfPAxkNUsXAlDw4Gm4TQNmY+H1zQAAP60eq/h19VLOONmPgah7PLnNXvx5tZmvL29Oe59NzV2Qr2aviXB4KPb5cU5v12Nu17Tzq3QBzxlqmWf6rKLOjgQZZd0ZD6ijQPXN5weCZVd6kryUBga3CUyHxtD8z3E0k8gOCIeiD6HQxA9H2LlRq/Hr/kdKHJYMKW6CP/3zXl4+dpT8fOLZuHSefXBIC3U76DfDTZaKSkZIhgQZZViXUARnvVh0PORwuuOyo9c8SKyHlVFdiw7tkbTvyKm0ZYXBn8XWlWZj2pdr9BIkfPBRzI+3teelimERJmkXsXgTkPmQ4j2R/mIKviIt5+MekVAv9eflobYVmfiS3fVw54A47S/4eP2dWBnsxMvfnJI+/gYwYd64zP1HiWlyhyKNPR8eIybJPUNpyJArC11KIGQeKzoS5hRGy5JK2WXGJmPPo9PCXTHlhUEb3P7lHJantUMq2or+OPrgytpLGYTzCYJ5SK7ogsA1XvhpEoEH6KsEpH5MCq7uIzfy0QoU05Vv99ipcv4igLk2yxK/4vNYkJ1KLgTmY/9bb3Keyne+5Em54OPZPqX7vv3Ljz9cfyhSURDiXpjsIGe3NUrZ9RbmKtpyi5uX9SdSoHIq9x0LLcVqe1YPSS9bh92tzjx8b52ze2Jll3EFXJ7r1sZROjxBZTsxYnjgyULcUIF9GUXdeZjEHo+omY+gl8XV9W1JQ5V2SX4tVbVfAlB/DtWz4fIejisJlQUBU++vR6/8jONV74Qr6EP4PqUUlLqZZfIzIdx2eVIVz+8oQBd7OuSSubDaH8XEdRNKA8GZuccUwMAGF+er5TgRM+HWNZc5LAMKOgaynI++EjWc+sHPguAKJN6NRNOB9ZQKRrkAMAcJXJXl10CcuzNxfSDmAZaegkEZGVPlVjP9a3HPsbZ967G+6GR7nPHBYOFRMsuojcgoCoTiH4Hi0nC1QsnQZKABZPCkynV27yrT2gD7fnw+QPK6pV4PR/9Xj+8/oCykqKq2KEEKj2hhltRbqhQBR+VRcZZCTVRciovsGuaWJ0J9k6I19AHgNG+p2SIYEP83PSZj8pCO2wWEwIycEQ3oyalsovBclsl+KgMBh9fOr4ON5w1BcsvOEa5jwhWt4c2kRupJReAwUfSYl3FEQ1F/d70zfnYcSQcfIiJnPpS5GHVahcgdtNpROZjgMFHZ79X6eGIlkWRZRmbVPuWjC7Nw2mTKwAkkflQpefFY8R/KwrtOGtGNXb89FxlQBcAOKxm5QSbr7qKH2jPx60vbsHJd7+NLQe7ovZ8qD93unxKBqO6SFV2cfuU78FmMWmyJ0rPh+796fP4cO59q3HjMxuVzEdFoU25WldnPvQnfL3wihf9a6Sv7CJKOPqeD5NJUspiIqsV7b1MhNH+LqLnY3wo82Exm3DzkqlYMKlCuY/o+RDHWT1CSy4Ag4+kcaM5Gm5607i3i3plSFe/Fy9vPIQZ//MG3visCUAwEDmiG6kea9BYujMfbaqUfbRApqPPqwRh/7r+NLxy3amoDZWQEs58qBoTRZlACT5CJQejeQyi9KJpOFX1fKRycSNS9Ks+b1F+vvosg8VsUvpM2nvdypLY6mK7puwisheVhXbNTI1omY/PDnVjR5MT/9h0GCu2BRt8ywvtShNrnybzESf4iJL5UDaVG8BqlxJd4GMUCOl3t+1JccgYELm/iyzL4cxHRUHUx1UUavelEb0gIxGDjySlsV+PKCPSubfL9qZw5sPlDeBnr26H2xfA1X/bgEBARluvBx5fAJIUruF393uxu8Vp2Kwt/jiL89xAg4/WnvirZ0SJoqzAhlmjS1BeaE94joWgXpIpeiTUJ+5oxNW1UcOp1y9rViYlSmQWPtoXbp41KlGIE+7uluBJ0GqWMCrfFi6RePyqAEr7PYifZVuPW7PZpnqmy/OfBEvS5QXhzEeP26c0HSdcdokyon1AZZc84x4YNf2Kl2j9M4nQ7+/S0edVljmLlUBGKnS/O1Usu5DA1S403Gj3dkm950OWZew4ot3fw2oOXx2/u7NF+cNdW+xQrv4eXrMXZ9+7Go+83xDxnCItXSd2XY0zF0QcRzTqCZvRnqvZGbmEsbLQuKxgpKvfq3lufeajsih68CGuetU7r+ZZzcquqan0fYgMzyehlTvBnWgj/7SLE+6eo8HppVVFDphMktLI6Q/IyvyPSt0VeHmhHSYp2OOizi41q6bCiqCkvNCuPGefxx/eRTbFzIcYMpaOhlNBH4wA4VkbB0IltfRkPoK/3w2twfd8dGmeZriZXrku+GDZhRQBll1omOlN02qX1h4Pul0+SFJ4Oqf6RPHwmr1KRmBMWb7yR1s0dW5X9YsAwSBCNOSNrwj+4Y/X89HZ58Gpv3gHP3l5i+HXtRNTjZ+rOZT5qFH9YReZj9Yej+bK3kijbut1o56PaK5YMB63LJ2K/zx1gnKbJEmqFS/JLbcNhPYrAeI3SIoT7q5Q07D4ntXb1Iu+BP33EG0prL7EFnysTclS9HnCmQ99n4WeyBi16oKPbqX3IrlJo2r6MotRICT2uBGlxVTHqwOqno8+EXwEf2fE73k0BTazZv4HG05Jsaulh9kPGlb601R2ETXr0aV5yhWZT/X/wod727GjKTwuWvzRFuWPiH0/POG5HqIJL17ZZfPBLhzucuEfmw4bZkASKruErtbVS4XLC2yQpODVu9FW6Gr64EOUW8Rrx8p8VBTacd2ZUyJOKqmOWHe6fRHDDqMGH6ETrti3RfQTmEySUgZqCI0fNwqgqgwyEyLzsWhapXJbeaFNCWh63L7EG06jZD7E6iX1zJRkJdLzMbMuONdkz9Fe9Hv86IkyMyUR+jkf+mbTaCRJ0rz3zHyQxj1vGo+VJhqK0tVwKlLHEysLI/6Yi4273t3RAiDYvKf/o63f8VT8YbZbwju+xst8iBOR0+XTBBrh1wifuNy+gOFeLUaTIy1mkzJjId4IcVFaEiUnfeYjVvARTaorXozer2gnS3HCFWUX9YlNZCr2hwZhGX0PlQazPkTm49J5wX1HAGByZZEyCt3lDc8+SbTnw+n2aWbTiLkt5YWpBx/6TIdRFqaqyI7yAhv8ARkbD3SEN6BLIeMi5nw4XT54/YGEmk0F9fdZxYZTUvtjGrbeJsoU9ZyNgWQ+9h4N/gGdWFGAkvzwH0ibxaTMyRCZj/qyvIhGvTZdI6HIMJQX2JRZF/EyH+oARpxEo30d0G7lLjQpZRftH/bKIrHiJXbTqVhmO7OuBIAq+OiJX3aJJjzrI7myi9Fy4miZD3Hyd4VG7KubGcVjDob2PomV+VAHZ6KEVVuahye+fRKe/u7JOHZMiaY5tDn0/sQLPgrtFjiskbvntveEf09SJd5fwSjzIUmSkv1Y1xAcPmc2ScoxJaM4z4rQ3DC8v7tV+V1NKPhQfZ8jdbopwOCDaMjw+QN447MjESfpgVJPJR1I5mOv6upNnfmoLLRjanWh5r71qrKL0NqrXUoqyhWjCmzK88UNPlQ9HSIY0n5d+94ZPV+T2Kq8RB98GKf99UTmY059KQBV2WVAmY/Uyi5GU1yj9Ubor/7VmR8RLIh+F/2STyB8FS56PvwBWQksaoodqCpy4JRJYtv34Mh0AGgKrYiJ13AqSZJqD5lgUOP2hYeelRekfiIutFmUYACILMMIIvj4KBR8FNotmiXHiTKbJOX9vfLRj5WgfHxCmY/g9zkq32q4XHukyPng4/jQHxCibHtrWzOu/tsn+MXrO9L2nP6ArAk40tHzEQw+VAOoiu2YHNoiXBhbFll28fgCmk3GmrrCJy5l/Hec8ertPergwyDzkcC4dqXsoktpVyUwxRMI93yIbE9wGaVXOUmmFHwkmPnRE/dXZ5kKo6wK0a/w0JZdtI/RL7UFIoMzsezWbJIivmdJkpTSy1El8xG/fFGpy66I0pzFJBmuUEmUySRpsh3RsjAzQ/vZfBLa2Xcgm9n9/mtzcMHsOiXQqSi0KbNEYhFZp5HcbAoAI3NofBJuXTYDb3zWnND220SDSZQDmhMcdJUI9YwPIPWltv6ArPQDTKwsUHoUgOBJe2pVOPNhs5hQWWg3/MPd1uNRTkKi8bO6xKGcGMTJ1B+Q0evxRVwtqzMbscoudosJbl8goifC7fMrJzT93jSJZD5kWVZKE8eNKYHZJMEfkJXJr/rJoIkqNdgLJBEiuJpdX4qPGtrh8Qei93zEyHzosyVGAZR+fxfR71FZaFeyHGqFdgucLp8ycTaRremVKac9IsAJvh9lBbaUMhBqxQ4rOvu8cFhNUTMKx4QyH9GGtSVj3vgyzBtfBp8/gC2HulARGuEej8g6pRLEDic5n/kotFvwzi0Lk37crmZn/DsRJUH0Zrhj7IUiuH1+rN3dGjeY0A+tSqXs8vjafTj3vtXw+mXYLCbUleRpyy5FdkxRZT7GjMqDySQZ/uFWBw8iHV9b7AiXXUJlh+/9bQNO/Nm/NfvEBB+vyny0assuHl9ACV5EbV2fSRBX1DaLSdn2XKgO/bFvMlg+Khx1uuH2BWCSgnu1iBOF2ItDPxk0UeLErh9Nb2T9vnalLCCCq7ICGyaHAsCoZZc8/ferDj7CJ+NoAVR4EFvwPTRaNaSWr5tIGm+1i/q5RHZK/LwHstJFEL9jsco/EyoKNT0eA8l8CBazCXPGjlI2r4tn0bQqTKkqxCUnjBnwaw9lOR98AMFfxp9dOCupxyz57WrN5/tae5UdE4lSIVZmuBIIEH76r224/M/r8PNXt8e8nz748CQ5ojcQkPGzV7cpyzPLC2wwmSRNA19VkQNlBTblRCxSy0YnQfUKFXXvhTgxiJUOKz8/CrcvoJzUBXVDaWN7nyb4Eg2sJik8MEo/aEzJthRHBgli47cjMQIAZYhaSR6sZpOSIleCjxSvVieGNhtrMOhjUTvqdOPyh9fhm4+sQ6/bp3x/xXkWzK4PNsAa9WsA2pOu3WLSlDHUDaLRAih1z4csy1Ebd42eE0gsiyACHFGSE6ubUmni1VOCjxhBkNkkYXpNsfJ5KstsB2pyVSFW3LwQF84ZnfHXziQGHyFGacNkLPr1Spz2y3c5A4RSJpYXJpL5+NuHBwAAT3ywP+b9enX7qri9yQUfe1t74fWHf6fnjS8DoG3YE1ftYkiTGFNt9If7kwMdOO/+NXh9yxHVsC8HKgptKM23QpaBf24+rPSm6Hs41EPEAjJwoE015rxHzIOwKz0U+rKLuKI2OmGK4ONQZ/TMh1jpIr5HEWyIfU3GJnh1qyfmPxzuchkuDxb+9elhePwBuLwBNHW7lO+vJM+Km86eiv/+4kx89cR6w8eqT/7VxQ5NgKG+wo8WvIjv1eMLoNvlSyrzIUnBps94qnUrjtRll4ESwVa8YWei6RRIT+aDjDH4CIm2PXiyOAGV1Lz+gDJgKJ4+UXYZ4P4rmuccYOZjY6jxbnpNEe684Bj86NxpAMKrM4Dw1eqJE4KByewxpQC0f7hFKvux9/dh6+FuPLZ2n5JhqC0JngjF455cFw6o1JkOl9evNKyKssqtL27Bfz72Mfo9fs2uquot1M++dxV+/FJwIqq4Wjdq5hObvrX2uKMGAAdCzaYiuyN6FESQ9NV5xif+eMoKbMpJcV9b9N+XlzcdVv591OlWgo9ihxXVxQ58+7QJUcsK6it+/fAqTeYjSvbGYTUrAUxLtyuc+YgSfBRqmmAtMCVwgSd+Lvqyy0BmfAiJZD6AcNMpMLCeD4qNwUfIQDMfAne9JbUfPLcZi369UrkyjsUVChRiXfnqxYuZRcOpOPkbZVVanK6oq2A2hraeXzi1ElcsGI8xoZOuuuwi9kW5/szJeP3G05VatfoP94xabSPf1sPdSslALHkVK882H+xSHteu6hERWQ+rWcLsMcESw4b9HXhnRws27O9Qvl5eaFNOMK9tOYLdLT14+qMDaOpyxcx8lOZblbHx0fo+xEoXUb9XrwqZWFmAUyeXGz4uHkmSlIBKHawe7uzHlx9ai5/+axv2Hu3B5tDPAwiWPxKdHgpor/j1G5YVaDIf0Uscoq9k/f4O5T2qjZr5CD9nvGW2Qk2Jtu8mHTM+lGNIoOcDYOYjUxh8hKQp8YEAd70lFXGl+uDK3XHvKxpOkwk+8mJsUgWEp5uKja70mY8DbX1YcPc7uObJDYaP33igEwAwZ2yp5vYSg8yH1WzCjNpi5QpX/Yf72NElmseLDEa+zaw0Nxote1dnPkRwMSrfhotOGIOqIrsS4Bzu6ldWqZQV2JXjEwGOLAdLFrtDvStGV+uSJKGuNHi7vtFVED0foryi3sH2ilPGD2hFhpgBIfYB8Qdk3PTsJqzf34G/vNeAKx/9WHP/lm5Xwpu2AdqlrvplxkUJBh+Lp1UBAN7Z0aLqn4nW8xH+3Uw0gyCCom5XsPenrTf8Mx2oqaGy4OSqwpj3m1FTrMwEGch+MhQbg4+QpcfURHS/p4KZDzJiM9hlVK8/wbKLelBXvOCjxx28MhZpa7cvoHn8xsYO+AIyth3ujnhsr9unbLI1Z+wozdfKC4KjqMVIaiOl+VZYzRLsFpOyhFGvRtV7MNso+FD1eIRT8HYsnFqJj24/G1+YVQsAONLpUnZkHV2aZzgT4s9rGvDuzqOQJOD0KZURXwfUfR9Rgo8oPR8FNjMuPmFgDYITlOAjGCA9tHI3PmpoV5ZnipKPKJkcVWU+og3NUrNZTMrvS6yyS7SeDwA4c3ow+Hh/d6umbGakIIXMR5Hdohxji9OV1rLLxSeMxps3nYFrF0+Oeb88m1n5WWSj4TRXpD34WL58OSRJ0nzU1NSk+2XSrtBuwce3n41/XHvqgJ4n3o6YlDvU+1PY4wQJ6vu7vP6Y28arB3XF2p47eN/gc4rpkLIMvPjJIaV8IGZWGG3lvvVwNwJy8OSiv7q1WUx446Yz8PqNp8MSJbDKt1nwp2/Mxf99cx5Glxo3YqozEGUFtoiGTfXSXDH5VR3s1IYyFU3d/cpqszGj8gxPduJK/aLjR2NaTVHE14Fw38dhg6ZTrz+gnHBFz8eiaZVYOLUS/3P+zISGaMUSLrv0YWeTE7/99y4AwF0XHYvvL5kKIJgpEn0lR51uZSlxogO4xP30P091lqIyxn4ix9QVo7rYjj6PXxnTHi3zka8KaBLNfEiSpARGTV0uJfOVjrKLJEmYVlOUUIl9waQKAOFVSJR+gxLWHXPMMfj3v/+tfG42D48RsRazyfDqKxkX/eF9PHPVySN6QyBKzKHO8EqMRFawiHJLQEZopobxH0l1KSIgy/D4ApCkYNlDT2wLrv7j/f3nNuP0KRX467fnK6tF+jx+uH1+zfAlUcaINp8gkWWlZ06vBgDNkllJgrJpl773YnZ9KQ6098FhNcHlDWgmmrYbzHyoKwkHC6KfY8yoPE3JJ99mxpyxpXh/dxtsZhNuXjo16vHWKcFHZObjSKcLATm4TFV870UOKx7/z5PivAuJEcHH3tZe/H19I/wBGWdOr8IloYxKXWke6krzlGNr0TWcJqK62IHmbnfEzzSR1S5A8AS+eFoVnvm4EUBwBHi0ALjAlnzZRRzjvrY+NDvdqj6ezA7c+skXZ+Cbp4zTzK+h9BqUsovFYkFNTY3yUVlpnOIEALfbje7ubs3HcLa3tRd3/GNrtg+DhoDGjvAJLJEJuuoN4GIND1M/l9Plw3n3r8HS366G12Aliyi7jNJdOe5qDqb2D6i2h9cP5BJzM0oTSOnHo06bnxq6qgQi91c5c3rwb4Uop6j3gxEzQtTPJTIfR7r6lSzOmFH5mgbMWXUl+PZpEwAA1y6erDTNGlGCD4NZH42qzMpAp20aET0frT1uvLzxEADgshPrlQzyJXPH4JRJ5UqPzeGufvSGsmWJNJwCwSzKXRcdixN0PTyaskucoHJxqPQCxB4Brn7ORI9P/ZyN7X1Kli8dS22TYbeYGXgMskEJPnbt2oW6ujpMmDABl112Gfbu3Rv1vnfffTdKSkqUj/r61JaqDSWiqY1y20FV8BFvszJAuyzWFWMeh3pQV4/bh10tPWho7TXs2xBll5I8KyyqdHOz0wW3z68NPnSbmolgZFT+wP/wl6me48tzw5Mb9f0CFx4/Gq/dcDruuOAYAMGZEuIEK1a+aMouocxHQ2uvcqLSl12OHVOCM6dXY+ud5+DGs6fEPE7RcHqowyD40K10Sbdih1XJOrT1elDssGDhtMgLN5FVVc84iTe7Qpg1ugSXzx8bETwVJthwCgCnTa5Qepii9XsAqTWcAuF+lG2hbJnVLCX8/dHwkfbgY/78+XjiiSfw5ptv4uGHH0ZTUxMWLFiAtrY2w/vfdttt6OrqUj4aGxvTfUgZ52PfB0F7Aut2+eKuYlF/PdZ9o2VRth0xCj6CJ+QCuwV21b4ScmhAl3qap77vQ+wzUpqGRmyL2YSvzx+Ls6ZXYdmxNUoTpf7KWWxrXpIXXvYqSi9GKXgRLIhBaBWFdjisZk0PxHGhZbn6iZtGRqsaTrcf6ca9Kz7HXz/Yh+1HuiNmfAwGMWwMAM6dVWO4B4ko+Yi/MwU2c9S+m0RVFtlRVmDD+PL8uCf6ArsF8ycGZ7pEm/EBaJfaJtMPI34ntoeC6XTs60JDT9rDyWXLlin/PvbYY3HKKadg0qRJePzxx3HzzTdH3N9ut8NuH1kb6DS09mL150dxxtTo5SYa+fTj9lt73DFT/uoG1VgrXtQ9H2qfHuzC13TtBz2u8K6nNotJySIAwIcN7VDHyfrt3EUwUpKG4AMAfn7Rscq/T55YjrW7W6OuggGC5ZWDHf1o7XVjbHm+kvFRp+DzbRaU5FmVLM2YUcHgIc9qRqHdgh63L6mdq8XJ1O0L4Bt/Wae8pqQa2S5WugyG8RUFWL8/ONjtgtnGq2dGhVYRiYArmZJGNA6rGe9+fxEsZimhE/13T5+Iz5udWBYqjxlJZbULEF5u2xAatpaOZbY09Ax6LqugoADHHnssdu3aNdgvNaR885GPsO8X52X7MKJ64oN9cFjMUUcx08A16lL3R53a4EOWZeUPvSzLmp6PVDIfWw51Rtwm5nwUOiwRO2p+sKdV83lnn0f3efrKLnoPf3Muuvq9MRuzywuCwYfIfLQZlF2AYOpfH3xIkoT7Lj0eHX0ejCtPfMWC3WJGZZEdR51utPZ4gtugl+Vj44FO7G/TzvgYDKLptKLQjlMmGQ8skyQJlYV2HA4N4krmxB5LMkHmGVMrse7HZ8e8T6plF9GELJqSYzXA0vA16HM+3G43tm/fjtra6BFyLgsEZGw/0q0s0X19yxEsuXcVdjYN3q65Ld0u/M8/tuKHL3wKX5LjtilxB0JXbqLc0aLq+5BlGVc8+jEuevB9eP0BePwBTRYiVsOpevmp2s4mZ0TQ4tSUXbQp/LV7tKVQfcNpZxobTvXsFnPcFWHlyuhyN5q6XGhs74ckhRszBXXfgTq4O3tmNb6SwrhzUXoBgB+eMx1PfedkTFItuYyVvRqoc46pQXWxHdctnhRzSah6pVEiMz6yIfWGU22mI9PNppQZaQ8+brnlFqxatQoNDQ1Yt24dvvzlL6O7uxtXXHFFul9qRPj9O7ux7HdrsPyV4AqZ7z35CXa19OD6pz8ZtNd0quZEjKT+FFmW8dDKPfjXp4fj3znNHl69F8+tD/crdfV70RHKHMwdFxzQpW46dXkDWP35UWw80ImPG9rh8miDwFgbwLVGKbt4/TJ26IJWsdql0G6J2HcooswyyGWXZImTTluvB//eHhxPP6e+NKIhslYVLIjMx0CI4GNqdSEumTsGeTYzfnfZHFhMEhxWE8aVD17wMbmqEOt+fDauPHVCzPupZ3EkOuMj0/JTXGqrD0rLWXYZkdIefBw8eBBf+9rXMG3aNFx88cWw2Wz48MMPMW7cuHS/1JDX0Nobd5fb3/77cwDAXz/U7k7q1G0Fnk7qAVYjaSO8D/e245dv7MB1T23M6OvuaOrGz1/bjh88/6ny3oqVCBWFduVKXR18qLMMWw93a0ouAOCKkfnQ79Sq9tmhLpx732r87z+3AQiXXYoclojVLILIHHT268su4XHm2SCW1Lb1hIOPs2dWR9yvTpX5GJ2G4OPCOaMxqbIAP7/oWCX7MGt0CV743gI8+Z2TBzxMLB2qVNmBdJVd0k29giaZ1Sp5NrPm/umYbkpDT9pD5meeeSbdTzlsLf71Slx2Yj1+cclxST92MIMCdTw0kjIfnx0Kb0im7qcYbJ83h5dWu30BOKxmZWfS8eX5yv4fR1W9GmIsNgCs398ecVKNtdRWBKZ5VnNE0PLCJwexo8mJHU1O/PDcacqQsQK7RZPxEoodFvzHyePwqzd3ajIfsiwrn6djtUsqRG/HgfY+rN0dLBEtNQg+xHJbAKhPQ/CxZGY1lhi8zkAHEKZTlarsko6G08GQysZyQk2JA92u4P9X6ZhuSkMP93YZZGISIBDcgdNoFoORwWzFUAc28TIzw4l6Pw79VvLptH5fO1q6w+O3m7oiX1csyxxbnq/U56NlPtbv60CvLjCI1fMhAhd1r4NYlqqeLfLxvnZlI7lou3NeMneMslxVHNNnh7rw6cEuJTDNVuZDrHJYsa0ZHn8A48vzMakyclMwMWgMQNQx7iNN5TAIPmwWE757+gRcdmJ9QtNw1dRLsNnzMTINzWLhCNTe68ElD60FALzz/YWYaPBHVC1a5qOr34uHVu7BhXPqML0m+jLFWOQRmvlQD8zqcfsSmuuQrA37O/DlP36AIrsFW+48BwCwTzXsqdftQ1mBTdkWfXx5gWHwoS6dtPV6NOPHgeiZj0BAVmZ31JQ4sDf0OlOrC7H5YJfmNd7dcVT5tz74mFZdhGanC1edMUl57c4+L7r6vbjkobXKUl+7xRR3/5jBok+3nzur1jCbNbmqEFazhPqyfOTZhsdWDgOl7osYygO4bj9vZkqPU39/LLuMTMx8GBiMNF+LM3ylfP3T8XsSom1Q9/NXt+GPq/bg3PvWpHwsPn/4uUfSRnifN4ebLXsMSgyp6Oj1YPGvV+Jn/wr2UKz+PHhCV5cw9h4Nl11E5kMsyxyXQOYDALYf0TaKRltq2+vxGe6LYjQKeuXOFgDBrIh65USh3YIXr1mAd76/CDUlDqWhtLPfgz1HezQzRrJVcgG0w7wuOWEMrj/TeDfSqiIH/nX96Xj6uydn6tCybjiUXQZCveKFDacjE4MPA6/deDpOmlCW1ueUoBpt3W28VFLds+D2+XH7S1vw1tYmzX02N3bpH5Y0byB8cslW8NHZ58HDq/dqyhfJkGVZs5eJPyBrSg49aWrYfWztPjS09uLP7zUAgGZEuSh/7D3aq9zW6wm+rhgwVl+m7fkQDan6ptG9rdqR/NGGjIl+D4tJ0lwRTq2OzKSJrIjYFlyMxF4wqRwFdouSzhZLaTv7vJqR3UD2Si5AMKPx8Dfn4ZXrTsVvvjo7ZiZrWk1RzH1GRprhsNR2IDS7HTPzMSIx+DBQXezAN04Or86ZXlOEC4+vS/n5bntxizIaGgD8AeMTyxd//57yb5c3gCfXHcD/++sGzX3S0Yjq9WU/+Lj1hS34+Wvb8a3HPk7p8dc/vRGn3P22MgJcn+lIV+ZDHdC4fX7N8x7pdMHp8mrmd/S5/ZBlWWkurS52KCcKjy+AbpcPmxo7NaUaQBvAANEzH+L1ixwWzck41iZYRaH7vXTtAlxxyriIBujSUIDhdPmUgEXI9oltycxqHDemNKvHMBSplxsP1dUuAyHKLjazSfn9pZGFP9Uo1Kfk1288HZIk4eVNqc2PePqjA/ioITzQaSB9FrEe6fb50dwVHEUdi/r1sxF8/PD5zXgjlNHZmmADrt6/Pj0CILi64zunT4TTpc0kpBJ8dPZ5EJC1DW7qEenNXW5l23YguO16t+51ez0+dPZ5VXuN2GC3mFHksMDp8mHV50dxg0HZTd2vAkT2fHS7vLjsTx8qwUCRw6oZXz1VF3xYTJLycxaZj2PqSnDnl0oiXlvdM7DlYKfma9nMfFB0NosJ1cV2NHe7R+QEUDGvpbrEzn1dRihmPhIgfvm/dlLqo8j3qK5sAwEZgYCMVzYnH8zIUTIf7+5swbSfvIEzfvUu1u013sRPUJcrstFw+vf1Bwf0ePVUVrHte0Tmw+VDS7cLK7Y1J7Six+ML4Lz738OSe1ehLZS1CARkzeqkw139mpLZoc5+bAjtwyH0eXxK1qM036pMFRXZj5U7WjT3nxYlY6Ff7fLUugPYdqQbH4R+turMR57VjNpih6avY5FqN1R1kGLEYjYpQ6C2HNKW9bLZ80Gx/eKS43D7F2ZgclXs5vXh6Ji6YvzkvBn4xcXJjymg4YHBRxRGJ/m7LjoWV50xccDP7Zdl/PPTw4ZXwPGPy/j2bz0aLl88tyH2yd2rajgdjkPGOlTzKNp7g//WD2Xrcfvwhfvfw3efWJ9QkLf5YCcOdfajrdeDR94P9nccaO/TNJYe6epHs1Ob+dAHH71uv9JYWqlKjYt/bzigvf/0WuPgQ5/5aOrS9sYEg49gYDMq3wqTSdJcAas3NSxMYDWEOL5o01Np6Fk8rQrfPWPiiMwMSJKE75w+EadOrsj2odAgYfARhdFum5Ik4cazpwz4uQMBYF1De0qPTUeooM4ciAbDHU3dERuLJcvjC2DjgY6YpZxomZtkdKiOszFUrjAqu4gN2N7RZRuMvLcrvMnaXz/Yj0BAxhHdCf9wpwstuszHJ6HgY3yo1NXn8Skrm9RTKEXmY7+u12NaTZTMh67nQ1/eKbRblZKIeG7x39J8q2Yn12gzPtQWTDbexKwpxYZgIqJYGHxEMbmqCM9ffQpW/2Cx5nZTGq4yfIEAYuwZFWH8ra/i5r9vgizLaNA1BKbCowo+vvPEetz12nace98anPbLdwf0vHe88hkuenAtfhcaGW9EnXURku07UTfvivfDKPMhOKzxf83XqnZ47Xb54HT7Iko5e1p6NLe9v7sNbb0e2MwmZXVUtMxHtE3UplYVQf0rJTah0692adT1hBQ7LDh5YjmuWjgRP1o2XfN61UUOTQ+IfoCZkSUza5R/FzksmBjaSO2sGZGTPomIBorBRwzzxpfFbd5MRUBOPoh58ZNDmHDbawndVzzzyxsP4f3drRFfv/GZTZrP/2/1XgDBE3av24fz7l+De97YEfX5Nzd24it/XBtRcnj6o+A01/vf2R31sfpx4IA2k5GIDlXwcbirHz5/ICL4OKKadmq3mCHLMv76wT5s1JU9gGA2ZvNBba9Dd783IpuyqbFT87nIrMwdN0rJQvR5fOHgQ7UccmyZ8djviiI7zKrfhRPHB4MY/WoX/WqYIocFNosJty2bgQWTKjSvV1Vs1wwG0zezGjl5YnhpudPlw9+vOgUPff0EXHZi6n1ORETRMPhIUjoyH+l8nmh2t/Tgpmc34et/Xqe53RNlfoTw0sZD2Hq4Gw+u3KPc36eb9f6D5zfj430dysTWZBgtIVVnMhLRrgpWZDmUqdAFH7uPqvdb8WP9/g789z+24qIH12rmqYjXF+/LqFCDZVe/V8lyiNHlYhnquPJ8zZCnM6dXKftY9Hr8ytJbdbYjWu262GHRNP1efMJoANqN5br6vGjTvUdGm5uJ1xPDx8TKmOPGRK5w0bNbzMoMk0K7BRWFdiw7thZWM/9EEFH68S9LktIVM6RjDsX//nNb1BP3EdV+I7Is42BHHzp6PXFfV70SZuvhLkz9yes4577Vml4N9QCv5m4XHnu/ISJLEE2/wZ4rrT3qreb9+OofP8A1T26I2h/SrmuKDAYKwdcXg7T2tIQzBR19XjSoMge/e3uX5vFiBUtFoQ3lodJFt8urBDT6bdpL8204c3qV8vni6VVK82ef2zjzEW1FQkmeFT84ZxpK8qx44XunKNuQu1UNp/oBZIDxFuUXnTAaZ8+oxtdDM2peue5UXH/mZNy6bIbha+u98L0FmFJViAcun5PQ/YmIUsU5H0lKV8bi+TgrUhLxyPsNONLVj4f+Y67mdknS7lzb3O3Gab98F5IEzKyNvR+M+vs77/7g0LM9R3vR7/UrV/cTKwtxONSMefGDa3Gosx87m52wmiXDng7B7fPjPx+PHComTvKyLON3b+/CR/uCzbgtTnfE1Mo+jy8iC9DVHw4Uaksd2N/WpynvdPV5cVBVhhGDwz492Im3tjZj1uhgZqCqyKHsDdKtynzUlDiwqyUcABTazfiPk8fh2fWNmFpVhEmVBVjXEHxcr8dvGHxIkoTyAlvEsRfnWXHt4sn43sJJMJkkvBtqjnX5/Pj1mzuxZncrzj+uNuI9M1rBMqmyEH++Yp7y+bjyAnx/6bSI+0Uzu74UK25emPD9iYhSxeAjSUNtUdvrnzVp9o0BgqPc1VkD0Zshy/GHekVr/nxs7T5cftJYlObbNJt3iZ1k397egiKH1TATc/tLW/DBnjbMri+N6F0Awg2Rf1/fiIdC5R4gOG5eHXw0tvdh6W9XR/SNqIOP0aV5EStKOvo8OKSaVCrmeFzwwPsAwqWWmhKHavy5T8nmqHePBYJliVmjS/DP605DZVFwCJKYpdHr9ikrRKp0O3n+7rI5+MYj6zCnvhSfHOgEAKWsYQqVPOyh5tg+tx8PvBvsndms6zUBjMsuRETDBcsuSRqKS+q/+ZePIm5Tz++INqrbSLQ9Re55YydOv+ddyLJsWDopsFs0pYA9R3twxSMfYdXnR/HkugPY29qLlzYeMnxuEXw8te6A5vZvP75esxnbff/eZdiw2tnnUYIPoy3XO/u9ONQZDkjaej2awWNibkh1sUPpk+jq9yrlpRpd9kUM95o1ukQJjkS55EB7H5wuH0xScF8XtdOmVGDdbWfh2atOwQ1nTcGvvzI74ljFqOyGtsgg7Vunjlf+bVR2ISIaLhh8JEk/0Gco7Duwo8kZcdtuVZlAv4NqLPtiLOV1unzYdqRb2TxNLd9m1syT+I8/r8Oqz4/iikciAyO9Hrcfhzv7sflgFyQJ+N6iScrX1AHJPt0JWSxLVa9MmWKwwVpXn1fJ0ADB7M5ja/dF3K+m2KHsENrtCpddqoojMx96IiARJZ2xZfmGW9FXFTtgNZtw85Kp+PLcMRFfn15ThCKHJWKY3LjyfJytWvY6lLdRJyKKh8HHAJ01oyr+nTLM6w/grtfCS2XVG5/F8+z6xphf//Rgl3Hmw2bR9JnoB3TF8ss3duB7T34CADhudAm+eUp4U789qlUr+3XBx4SK4CwKddmlviwfVrM2QPT4A2hs79fc9r//2hZxHDUldk3mQzxnSZ5VyWwAxsGH+utAcE5MKixmE06dFLky5oLZdZoyDssuRDScMfgYgJ9eOCstE0fTTT8NU4wLT4fbXtximGn5aF97xDbxavq+CT3R1zBrdAlqS/Lwf98INtGKIWLdLm/E6O/x5eHgQ+ynUllojzrQy2KSlIDFSFWxQyl7dKuCD/0OskZbu+tvG8h+G+rR6D85bwZuXjIV31s0SbOTqY1LYIloGONfsAG48Pi6bB+CocOd2qxDvNke6aIubaidNL4MlyY4rGpGaDWOmLDZ0NoLWZaxqzky4JkQuk9bj0dZrlut22BN7b+WTI1oAlWbXFmo7flQbV+vLq8Z9VvoMx9TBhR8hDMfF8yuww1nTUG+zYLSfCsmVRZgdGkeRo8yHlpGRDQcsHCcgi3Ll8LjC6DIYY260Vs23HT2FNz371043GUcBGRLcZ4lYslsNDNCG63Vl+XDJAXnoRztcWNnU+Ssi7rS4An400NdkGXAbAouZ1UHW7+77HhsauzEj86dDofVjJU7I/d5+fVXZmNCRQHqy/Kx9XBwAFm3KzxevdBu1WY+DHaJ1d82kMzHmFH5uPviYwFo+00kScIbN50Bf0Dm8C8iGtb4FywFRQ6rMoxKHXvcsnQqls5MfS8Mo+3LbWYTTplovOmXnsgadPbFbzA9LYXdIk+NsvmYnn5FULHDGrFiBABmjdbOHKktcWBmbXDmht1iVlaLfPux9fjbh/sjHl8aylKI5tqqIjtMJkkzKO1Lx4/GHecfozR/HtX1v0yrLsKX547B3HGjgseq6fkIvo/qHWQB47JLab4Vp0+pUI5DvbdKKr520lh87aSxEbdbzSbDRlYiouGEwUcaXXfmFPzfN+dF/Xq8FQqih0HNL8sRPRzRGF2RR6NvykzEzy48NqK8YGSqrtmyOM+q2eFVuG5xeIfgB79+At69ZZFmhsixoeFfWw51YduRyPkkdaXagEZkCZaEAsCJBv0dJ4SCDEFfQhE9H0edbmVgWqHDgkK7NepjgGBW4q/fno/1PzkbK3+g/T6IiEiLwccAGY0AF3tkjC7V1uVvP28Gdv18mfJ5ZZEdW5Yvxc1LpsJhNeFnF86KGOXtD8i4YsH4hI4lmRNetL4I4TzdVE1JCl7R+xLYgbZa11xqt5giyi5/+sZczaqR0aV5EVf0c8bGDhROGDsKN5w5Wfm8oiC4uduPz5uB25ZNx1+/Mz/i2G7/wgxcdcZE5XP991Oq2ttFKLBZUBgn86EcQ6FdmQRLRETGGHwMkNGpeO2tZ+KJ/zxJuQIX+j1+Ta3+lInlKHJYccNZU7Bl+TmYNboE73x/UcTzfWXuGLx6w2lKM2Q08bIS6rJOvF6VfKsZk0INnXlWM9648QwU2C1KQCVmbADAslk1msfW6LIckiShLLTrKwD89tLZOOeYGk0po6zABr3j60uVf//usuPx4W1nab4HSZJw09lTlc9FwFDssOKqhZMigj8AKC+047YvhPc68eo2zasryUO56lgKbGaYTZIm4FAHIkRElDwGHwNlcBKvKnZolksKLt2qE3XyQQQlNov2R/LluWMgSRKOqSuBwxr7x6UPPn715eOUf4/Kt6JStVTTHyf6+P7SaXjyOyfjJ+fNwIc/PgvTaoKllJ9+aRbOnlGFFf+1EE9/92Rcs2gSfv+1OZit2jlV399hkoLjw8eVB3s4xA6v6oFt5YWRwcfsMSVYMrMal86rx5eOH40CuwUPfO0E2C0mpSHTpHoTY2UkotGvBDKZJJwyKdzbInp7CjXBB2dsEBENBPPDAyTHmPShb7zUD6dKZJO6n35pVsL316f71aWOceUFmjHrsaonP7twFmpCpZPvnD5R87XTplTgtFBj5djyfOVErR56pS+7iMN+86Yz0OP2KfMq1CUmo1KFxWzCw7oemtOmVGDrnefAosog/d835uKBd3fjJ+cltnurmlEvyqmTK/CvT48AAC47qT50LOogh5kPIqKBYPAxQBcePxqvbWmKO9fhgtl1+Mo87TjtEoPVLUCwH0Ns8Kbu41AHH5ecMAaTqwrx5zV7lZ1S9ZkP9a6q1cV2zRyOQIzoI5V9Q9SP0Q/5mlARfG8cVrOmr6Oi0I7Xbjg96dez6JaZLj2mBkuPqYlyb2OPXDkPD63cg59feGzE1xZOrYTNYkJ5gQ1XGvTbJNPYS0REkfhXdICWzKzGazecjvEV+THvd//X5ij/vueS4/D8hoO44cwphvd95MoT8d3H1+POLx2juf3SE+tx74rPceL4UfjNV4Obkv3lvb3K1/N0DZvq3oVCuxVmU3iZqX6/l6vOmIhn1zdicmUhTp8SWTKKRx1AqDMD3z5tAi6aMzrq42bWFUf92mA6c3o1zpxuvCy6rjQPr994OorsFiUjI6n2MzbFadYlIqLYGHwMkCRJUU+gYqmo3ldPrMdXY0z8XDi1Ep/deU5E/8c1iybh+PpSzBlbqtx22Ylj8cC7uzF/QhlMJgmzx5Rg88HgoKziPO3yUIvqpDm2LB9bDnUpn9/2hRm4ddn0iI3zEqUuu6hLKLd/YcawPFnrd8eNVV4jIqLkMPgYRBcePxr9Xr8ywCoZ+sADCJYb9I2sN5w1BXPGluLECWUAgMXTq5TgQ70ipcBu1iyvvWbxJLi8fry9o0UZHpZq4AFoMx+z6ooxd9woVBfbh2XgYWRUfmRDLBERpYbBxyAymSR8ff64+HccAJvFhLNUW62rAx11MFFgt8Cs+vyYuhL85coT4fL6NUFKqtQrXCxmE1743oIBP+dQ8vX54/Dh3vYhuYsxEdFww+BjhDltcgXuOH+mUjb44nG1WLnzKL4ytx6yDHywt02zxDddo7ovOmE03tzahPkJjoIfbvJsZvz5iujTa4mIKHGSbDSiM4u6u7tRUlKCrq4uFBdnpxlxJJFlGW5fAA6rGR5fAH9f34jTp1RgnMEodyIiolQlc/5m5mOEkyRJyW7YLCb8x8mDWwYiIiKKhxNOiYiIKKMYfBAREVFGMfggIiKijGLwQURERBnF4IOIiIgyisEHERERZRSDDyIiIsooBh9ERESUUQw+iIiIKKMYfBAREVFGMfggIiKijGLwQURERBnF4IOIiIgyasjtaivLMoDg1rxEREQ0PIjztjiPxzLkgg+n0wkAqK+vz/KREBERUbKcTidKSkpi3keSEwlRMigQCODw4cMoKiqCJElpfe7u7m7U19ejsbERxcXFaX1uCuP7nBl8nzOD73Pm8L3OjMF6n2VZhtPpRF1dHUym2F0dQy7zYTKZMGbMmEF9jeLiYv5iZwDf58zg+5wZfJ8zh+91ZgzG+xwv4yGw4ZSIiIgyisEHERERZVROBR92ux133HEH7HZ7tg9lROP7nBl8nzOD73Pm8L3OjKHwPg+5hlMiIiIa2XIq80FERETZx+CDiIiIMorBBxEREWUUgw8iIiLKKAYfRERElFEjKvh48MEHMWHCBDgcDsydOxdr1qyJef9Vq1Zh7ty5cDgcmDhxIv74xz9m6EiHv2Te6xdffBFLlixBZWUliouLccopp+DNN9/M4NEOX8n+Tgvvv/8+LBYLjj/++ME9wBEi2ffZ7Xbj9ttvx7hx42C32zFp0iQ88sgjGTra4SvZ9/nJJ5/E7NmzkZ+fj9raWnzrW99CW1tbho52eFq9ejXOP/981NXVQZIkvPzyy3Efk5VzoTxCPPPMM7LVapUffvhhedu2bfKNN94oFxQUyPv37ze8/969e+X8/Hz5xhtvlLdt2yY//PDDstVqlZ9//vkMH/nwk+x7feONN8q//OUv5Y8++kj+/PPP5dtuu022Wq3yJ598kuEjH16SfZ+Fzs5OeeLEifLSpUvl2bNnZ+Zgh7FU3ucLLrhAnj9/vrxixQq5oaFBXrdunfz+++9n8KiHn2Tf5zVr1sgmk0n+3e9+J+/du1des2aNfMwxx8gXXnhhho98eHnttdfk22+/XX7hhRdkAPJLL70U8/7ZOheOmODjpJNOkq+++mrNbdOnT5dvvfVWw/v/8Ic/lKdPn6657aqrrpJPPvnkQTvGkSLZ99rIzJkz5TvvvDPdhzaipPo+X3rppfJPfvIT+Y477mDwkYBk3+fXX39dLikpkdva2jJxeCNGsu/zr371K3nixIma2+6//355zJgxg3aMI00iwUe2zoUjouzi8XiwYcMGLF26VHP70qVLsXbtWsPHfPDBBxH3P+ecc7B+/Xp4vd5BO9bhLpX3Wi8QCMDpdKKsrGwwDnFESPV9fvTRR7Fnzx7ccccdg32II0Iq7/Mrr7yCefPm4Z577sHo0aMxdepU3HLLLejv78/EIQ9LqbzPCxYswMGDB/Haa69BlmU0Nzfj+eefx3nnnZeJQ84Z2ToXDrldbVPR2toKv9+P6upqze3V1dVoamoyfExTU5Ph/X0+H1pbW1FbWztoxzucpfJe6/3mN79Bb28vvvrVrw7GIY4IqbzPu3btwq233oo1a9bAYhkR/2sPulTe57179+K9996Dw+HASy+9hNbWVlxzzTVob29n30cUqbzPCxYswJNPPolLL70ULpcLPp8PF1xwAX7/+99n4pBzRrbOhSMi8yFIkqT5XJbliNvi3d/odoqU7HstPP3001i+fDmeffZZVFVVDdbhjRiJvs9+vx+XX3457rzzTkydOjVThzdiJPP7HAgEIEkSnnzySZx00kn4whe+gHvvvRePPfYYsx9xJPM+b9u2DTfccAP+53/+Bxs2bMAbb7yBhoYGXH311Zk41JySjXPhiLg8qqiogNlsjoigW1paIiI6oaamxvD+FosF5eXlg3asw10q77Xw7LPP4tvf/jaee+45nH322YN5mMNesu+z0+nE+vXrsXHjRlx33XUAgidJWZZhsVjw1ltv4cwzz8zIsQ8nqfw+19bWYvTo0SgpKVFumzFjBmRZxsGDBzFlypRBPebhKJX3+e6778app56KH/zgBwCA4447DgUFBTj99NPxs5/9jNnpNMnWuXBEZD5sNhvmzp2LFStWaG5fsWIFFixYYPiYU045JeL+b731FubNmwer1TpoxzrcpfJeA8GMx5VXXomnnnqKNdsEJPs+FxcXY8uWLdi0aZPycfXVV2PatGnYtGkT5s+fn6lDH1ZS+X0+9dRTcfjwYfT09Ci3ff755zCZTBgzZsygHu9wlcr73NfXB5NJe4oym80AwlfmNHBZOxcOajtrBollXH/5y1/kbdu2yTfddJNcUFAg79u3T5ZlWb711lvlb3zjG8r9xfKi//qv/5K3bdsm/+Uvf+FS2wQl+14/9dRTssVikf/whz/IR44cUT46Ozuz9S0MC8m+z3pc7ZKYZN9np9MpjxkzRv7yl78sb926VV61apU8ZcoU+Tvf+U62voVhIdn3+dFHH5UtFov84IMPynv27JHfe+89ed68efJJJ52UrW9hWHA6nfLGjRvljRs3ygDke++9V964caOypHmonAtHTPAhy7L8hz/8QR43bpxss9nkE044QV61apXytSuuuEJeuHCh5v4rV66U58yZI9tsNnn8+PHyQw89lOEjHr6Sea8XLlwoA4j4uOKKKzJ/4MNMsr/Tagw+Epfs+7x9+3b57LPPlvPy8uQxY8bIN998s9zX15fhox5+kn2f77//fnnmzJlyXl6eXFtbK3/961+XDx48mOGjHl7efffdmH9vh8q5UJJl5q+IiIgoc0ZEzwcRERENHww+iIiIKKMYfBAREVFGMfggIiKijGLwQURERBnF4IOIiIgyisEHERERZRSDDyIiIsooBh9ERESUUQw+iIiIKKMYfBAREVFG/X+B2h+Yo8JrWAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, we have very nice decreases but at some point it increases again and starts going nuts at the end. Looks like 0.1 is a good learning rate.\n",
    "\n",
    "Can also look at the exponent $10^x$ of the learning rate, rather than the learning rate itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e6cdbf5bd0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lre, lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation here is $10^{-1} = 0.1$ is again a good learning rate. We can just use that as the learning rate, and crank up the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset parameters\n",
    "g, C, W1, b1, W2, b2, parameters = make_parameters()\n",
    "lr = 0.1 # Optimized\n",
    "\n",
    "for _ in range(20000):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.502794027328491\n"
     ]
    }
   ],
   "source": [
    "printExactLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In late stages of training, you can further reduce the learning rate to try to fine tune. The best bigram model was around 2.45; so we're already on par."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01 # Step down learning rate\n",
    "\n",
    "for _ in range(20000):\n",
    "\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # For randomly selecting 32 rows of data\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2); only grab ix rows\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Only grab ix rows\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3687963485717773\n"
     ]
    }
   ],
   "source": [
    "printExactLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/validation/test splits\n",
    "\n",
    "So this is a \"better\" model because it has a lower loss, right? Not exactly - there's a balance between loss function and overfitting. Be cautious of overfit models. As usual, do training/validation/test splits. (The training set can then be cross-validated, etc.) Idea is to withhold parts of the data for training models, fitting hyperparameters, and final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
